
> malloy@0.0.1 test
> jest --runInBand

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
        group_set,
        CASE WHEN group_set IN (2,1) THEN
          base.`popular_name`
          END as `popular_name__2`,
        CASE WHEN group_set=2 THEN
          base.`state`
          END as `state__2`,
        CASE WHEN group_set=2 THEN
          COALESCE(SUM(base.`births`),0)
          END as `total_births__2`,
        MAX((CASE WHEN group_set=0 THEN
          COALESCE(SUM(base.`births`),0)
          END)) OVER () as `all_births__2`,
        MAX((CASE WHEN group_set=1 THEN
          COALESCE(SUM(base.`births`),0)
          END)) OVER (PARTITION BY CASE WHEN group_set IN (2,1) THEN
          base.`popular_name`
          END) as `all_name__2`
      FROM malloytest.state_facts as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3
    )
    SELECT
      `popular_name__2` as `popular_name`,
      `state__2` as `state`,
      GET((ARRAY_AGG(`total_births__2`) FILTER (WHERE group_set=2 AND `total_births__2` IS NOT NULL)),0) as `total_births`,
      GET((ARRAY_AGG(`all_births__2`) FILTER (WHERE group_set=2 AND `all_births__2` IS NOT NULL)),0) as `all_births`,
      GET((ARRAY_AGG(`all_name__2`) FILTER (WHERE group_set=2 AND `all_name__2` IS NOT NULL)),0) as `all_name`
    FROM __stage0
    WHERE group_set NOT IN (0,1)
    GROUP BY 1,2
    ORDER BY 3 desc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [MISSING_AGGREGATION] The non-aggregating expression "popular_name" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(popular_name)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
FAIL test/src/databases/all/nomodel.spec.ts (79.41 s)
  ✓ parenthesize output field values - databricks (3150 ms)
  ✓ bug 151 which used to throw unknown dialect is still fixed- databricks (2462 ms)
  ✓ refine query from query - databricks (2558 ms)
  ✓ source- not -found  - databricks (25 ms)
  ✓ join_many - databricks (2596 ms)
  ✓ join_many condition no primary key - databricks (2139 ms)
  ✓ join_many filter multiple values - databricks (1666 ms)
  ✓ join_one condition no primary key - databricks (1614 ms)
  ✓ join_one filter multiple values - databricks (1551 ms)
  ✓ join_many cross from  - databricks (1683 ms)
  ✓ join_one only  - databricks (1445 ms)
  ✓ join_many cross ON  - databricks (1193 ms)
  ✓ limit - provided - databricks (1187 ms)
  ✓ join inner- databricks (1786 ms)
  ✓ join left - databricks (1411 ms)
  ✓ join right - databricks (1845 ms)
  ✓ join full - databricks (1352 ms)
  ✓ leafy count - databricks (1533 ms)
  ✓ nest/unnest -basic - databricks (1 ms)
  ✓ count at root should not use distinct key - databricks (1462 ms)
  ✓ leafy nested count - databricks
  ✓ basic index - databricks (3028 ms)
  ✓ sql block- databricks (1971 ms)
  ✓ avg ignore null- databricks (2448 ms)
  ✓ limit - not provided - databricks (833 ms)
  ✓ ungrouped top level - databricks (1227 ms)
  ✓ ungrouped - eliminate rows  - databricks (1055 ms)
  ✓ run simple sql - databricks (2173 ms)
  ✓ simple sql is exactly as written - databricks (909 ms)
  ✓ source from query defined as sql query - databricks (877 ms)
  ✓ source from query defined as other query - databricks (1205 ms)
  ✕ all with parameters - basic  - databricks (784 ms)
  ✓ sql as source - databricks (1928 ms)
  ✓ sql directly - databricks (683 ms)
  ✓ sql with turducken- databricks (2108 ms)
  ✓ local declarations external query - databricks (786 ms)
  ✓ local declarations named query - databricks (770 ms)
  ✓ local declarations refined named query - databricks (1108 ms)
  ✓ regexp match- databricks (2087 ms)
  ✓ substitution precedence- databricks (1730 ms)
  ✓ removes surpuflous order_by - solo aggregates - databricks (781 ms)
  ✓ removes surpuflous order_by - pipeline - databricks (673 ms)
  ✓ removes surpuflous order_by - joined_query - databricks (978 ms)
  ✓ removes surpuflous order_by - joined_query pipeline - databricks (1015 ms)
  ○ skipped number as null 2 - databricks
  ○ skipped ungrouped top level with nested  - databricks
  ○ skipped ungrouped nested with no grouping above - databricks
  ○ skipped ungrouped - partial grouping - databricks
  ○ skipped ungrouped - all nested - databricks
  ○ skipped ungrouped nested  - databricks
  ○ skipped ungrouped nested expression  - databricks
  ○ skipped ungrouped nested group by float  - databricks
  ○ skipped all with parameters - nest  - databricks
  ○ skipped single value to udf - databricks
  ○ skipped Multi value to udf - databricks
  ○ skipped Multi value to udf group by - databricks
  ○ skipped array unnest - databricks
  ○ skipped array unnest x 2 - databricks
  ○ skipped can unnest simply from file - databricks
  ○ skipped can unnest from file - databricks
  ○ skipped can double unnest - databricks
  ○ skipped nest null - databricks
  ○ skipped Nested pipelines sort properly - databricks
  ○ skipped number as null- databricks
  quoting and strings
    ✓ backslash quote (1697 ms)
    ✓ backslash backslash (862 ms)
    ✓ source with reserve word (746 ms)
    ○ skipped spaces in names

  ● all with parameters - basic  - databricks

    query.run failed: [MISSING_AGGREGATION] The non-aggregating expression "popular_name" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(popular_name)" if you do not care which of the values within a group is returned. SQLSTATE: 42803
    SQL: WITH __stage0 AS (
      SELECT
        group_set,
        CASE WHEN group_set IN (2,1) THEN
          base.`popular_name`
          END as `popular_name__2`,
        CASE WHEN group_set=2 THEN
          base.`state`
          END as `state__2`,
        CASE WHEN group_set=2 THEN
          COALESCE(SUM(base.`births`),0)
          END as `total_births__2`,
        MAX((CASE WHEN group_set=0 THEN
          COALESCE(SUM(base.`births`),0)
          END)) OVER () as `all_births__2`,
        MAX((CASE WHEN group_set=1 THEN
          COALESCE(SUM(base.`births`),0)
          END)) OVER (PARTITION BY CASE WHEN group_set IN (2,1) THEN
          base.`popular_name`
          END) as `all_name__2`
      FROM malloytest.state_facts as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3
    )
    SELECT
      `popular_name__2` as `popular_name`,
      `state__2` as `state`,
      GET((ARRAY_AGG(`total_births__2`) FILTER (WHERE group_set=2 AND `total_births__2` IS NOT NULL)),0) as `total_births`,
      GET((ARRAY_AGG(`all_births__2`) FILTER (WHERE group_set=2 AND `all_births__2` IS NOT NULL)),0) as `all_births`,
      GET((ARRAY_AGG(`all_name__2`) FILTER (WHERE group_set=2 AND `all_name__2` IS NOT NULL)),0) as `all_name`
    FROM __stage0
    WHERE group_set NOT IN (0,1)
    GROUP BY 1,2
    ORDER BY 3 desc NULLS LAST

    Error: [MISSING_AGGREGATION] The non-aggregating expression "popular_name" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(popular_name)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      841 |           all_name is exclude(total_births, state)
      842 |       }
    > 843 |     `).malloyResultMatches(runtime, {
          |        ^
      844 |       all_births: 295727065,
      845 |       all_name: 197260594,
      846 |     });

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/nomodel.spec.ts:843:8)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
        group_set,
        base.`state` as `state__0`,
        CASE WHEN group_set=1 THEN
          airports_0.`county`
          END as `county__1`,
        CASE WHEN group_set=1 THEN ROW_NUMBER() OVER(PARTITION BY group_set, base.`state`  ORDER BY  CASE WHEN group_set=1 THEN
          airports_0.`county`
          END asc NULLS LAST ) END as `row_num__1`
      FROM malloytest.state_facts as base
       LEFT JOIN malloytest.airports AS airports_0
        ON airports_0.`state`=base.`state`
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,1,1)) as group_set)
      GROUP BY 1,2,3
    )
    SELECT
      `state__0` as `state`,
      SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=1 THEN STRUCT(
        `county__1` as `county`,
        `row_num__1`::BIGINT as `row_num`) END), ARRAY()), true) as `q`
    FROM __stage0
    GROUP BY 1
    ORDER BY 1 asc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [MISSING_AGGREGATION] The non-aggregating expression "county" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(county)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       base.`state` as `state`,
       (CEIL(base.`births`*1.0/1000000))*1000000 as `births_ballpark`,
       RANK() OVER(  ORDER BY  (CEIL(base.`births`*1.0/1000000))*1000000 desc NULLS LAST ) as `births_ballpark_rank`
    FROM malloytest.state_facts as base
    GROUP BY 1,2
    ORDER BY 2 desc NULLS LAST
    LIMIT 20

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [MISSING_AGGREGATION] The non-aggregating expression "births" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(births)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
        group_set,
        base.`faa_region` as `faa_region__0`,
        CASE WHEN group_set=0 THEN
          COUNT(1)
          END as `airport_count__0`,
        CASE WHEN group_set=0 THEN ROW_NUMBER() OVER(PARTITION BY group_set  ORDER BY  CASE WHEN group_set=0 THEN
          COUNT(1)
          END desc NULLS LAST ) END as `id__0`,
        CASE WHEN group_set IN (1,2) THEN
          base.`fac_type`
          END as `fac_type__1`,
        CASE WHEN group_set=1 THEN
          COUNT(1)
          END as `airport_count__1`,
        CASE WHEN group_set=1 THEN ROW_NUMBER() OVER(PARTITION BY group_set, base.`faa_region`  ORDER BY  CASE WHEN group_set=1 THEN
          COUNT(1)
          END desc NULLS LAST ) END as `id2__1`,
        CASE WHEN group_set=2 THEN
          AVG(base.`elevation`)
          END as `avg_elevation__2`
      FROM malloytest.airports as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,5
    )
    , __stage1 AS (
      SELECT
        CASE WHEN group_set=2 THEN 1 ELSE group_set END as group_set,
        `faa_region__0` as `faa_region__0`,
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count__0`,
        GET((ARRAY_AGG(`id__0`) FILTER (WHERE group_set=0 AND `id__0` IS NOT NULL)),0) as `id__0`,
        CASE WHEN group_set IN (1,2) THEN
          `fac_type__1`
          END as `fac_type__1`,
        GET((ARRAY_AGG(`airport_count__1`) FILTER (WHERE group_set=1 AND `airport_count__1` IS NOT NULL)),0) as `airport_count__1`,
        GET((ARRAY_AGG(`id2__1`) FILTER (WHERE group_set=1 AND `id2__1` IS NOT NULL)),0) as `id2__1`,
        TO_JSONB((ARRAY_AGG((SELECT __x FROM (SELECT
          `avg_elevation__2`::BIGINT as `avg_elevation`) as __x)) FILTER (WHERE group_set=2))[1]) as `elevation__1`
      FROM __stage0
      GROUP BY 1,2,5
    )
    , __stage2 AS (
      SELECT
        `faa_region__0` as `faa_region`,
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count`,
        GET((ARRAY_AGG(`id__0`) FILTER (WHERE group_set=0 AND `id__0` IS NOT NULL)),0) as `id`,
        SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=1 THEN STRUCT(
          `airport_count__1`::BIGINT as `airport_count`,
          `fac_type__1` as `fac_type`,
          `id2__1`::BIGINT as `id2`,
          `elevation__1` as `elevation`) END), ARRAY()), false), 1, 2) as `by_fac_type`
      FROM __stage1
      GROUP BY 1
    )
    SELECT
       CAST(get_json_object(by_fac_type_0, '$.id2') AS DOUBLE) as `id2`
    FROM __stage2 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`by_fac_type`)) as value) as by_fac_type_0 ON true
    GROUP BY 1
    ORDER BY 1 desc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `TO_JSONB` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 38 pos 4

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       LOWER(base.`state`) as `lower_state`,
       LAG((LOWER(base.`state`))) OVER(  ORDER BY  LOWER(base.`state`) asc NULLS LAST ) as `prev_state`
    FROM malloytest.state_facts as base
    GROUP BY 1
    ORDER BY 1 asc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [MISSING_AGGREGATION] The non-aggregating expression "state" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(state)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       LOWER(base.`state`) as `lower_state`,
       COUNT(1) as `c`,
       LAG((COUNT(1))) OVER(  ORDER BY  LOWER(base.`state`) ASC NULLS LAST ) as `prev_count`
    FROM malloytest.state_facts as base
    GROUP BY 1
    ORDER BY 1 ASC NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [MISSING_AGGREGATION] The non-aggregating expression "state" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(state)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       TRUNC(1.9::NUMERIC) as `f0`,
       TRUNC(-1.9::NUMERIC) as `f1`,
       TRUNC((12.29::NUMERIC), 1) as `f2`,
       TRUNC((19.2::NUMERIC), -1) as `f3`,
       TRUNC(NULL::NUMERIC) as `f4`,
       TRUNC((1::NUMERIC), NULL) as `f5`
    FROM malloytest.state_facts as base
    GROUP BY 1,2,3,4,5,6
    ORDER BY 1 asc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [WRONG_NUM_ARGS.WITHOUT_SUGGESTION] The `trunc` requires 2 parameters but the actual number is 1. Please, refer to 'https://spark.apache.org/docs/latest/sql-ref-functions.html' for a fix. SQLSTATE: 42605; line 2 pos 3

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       COALESCE(CAST('+inf' AS double) = DOUBLE 'Infinity' OR CAST('+inf' AS double) = DOUBLE '-Infinity', false) as `f0`,
       COALESCE(100 = DOUBLE 'Infinity' OR 100 = DOUBLE '-Infinity', false) as `f1`,
       COALESCE(NULL = DOUBLE 'Infinity' OR NULL = DOUBLE '-Infinity', false) as `f2`
    FROM malloytest.state_facts as base
    GROUP BY 1,2,3
    ORDER BY 1 asc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error:
    [UNSUPPORTED_TYPED_LITERAL] Literals of the type "DOUBLE" are not supported. Supported types are "DATE", "TIMESTAMP_NTZ", "TIMESTAMP_LTZ", "TIMESTAMP", "INTERVAL", "X". SQLSTATE: 0A000
    == SQL (line 2, position 38) ==
    ...ALESCE(CAST('+inf' AS double) = DOUBLE 'Infinity' OR CAST('+inf' AS double) = DOU...
                                       ^^^^^^^^^^^^^^^^^

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       COALESCE(CAST('NaN' AS double) = NUMERIC 'NaN', false) as `f0`,
       COALESCE(100 = NUMERIC 'NaN', false) as `f1`,
       COALESCE(NULL = NUMERIC 'NaN', false) as `f2`
    FROM malloytest.state_facts as base
    GROUP BY 1,2,3
    ORDER BY 1 asc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error:
    [UNSUPPORTED_TYPED_LITERAL] Literals of the type "NUMERIC" are not supported. Supported types are "DATE", "TIMESTAMP_NTZ", "TIMESTAMP_LTZ", "TIMESTAMP", "INTERVAL", "X". SQLSTATE: 0A000
    == SQL (line 2, position 37) ==
    ...OALESCE(CAST('NaN' AS double) = NUMERIC 'NaN', false) as `f0`,
                                       ^^^^^^^^^^^^^

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       CASE WHEN NUM_NULLS(1,10,-100) > 0 THEN NULL ELSE GREATEST(1,10,-100) END as `f0`,
       ((CASE WHEN NUM_NULLS(DATE '2003-01-01',DATE '2004-01-01',DATE '1994-01-01') > 0 THEN NULL ELSE GREATEST(DATE '2003-01-01',DATE '2004-01-01',DATE '1994-01-01') END)>=DATE '2004-01-01') and ((CASE WHEN NUM_NULLS(DATE '2003-01-01',DATE '2004-01-01',DATE '1994-01-01') > 0 THEN NULL ELSE GREATEST(DATE '2003-01-01',DATE '2004-01-01',DATE '1994-01-01') END)<DATE '2005-01-01') as `f1`,
       (CASE WHEN NUM_NULLS(timestamp '2023-05-26 11:58:00',timestamp '2023-05-26 11:59:00') > 0 THEN NULL ELSE GREATEST(timestamp '2023-05-26 11:58:00',timestamp '2023-05-26 11:59:00') END)=timestamp '2023-05-26 11:59:00' as `f2`,
       CASE WHEN NUM_NULLS('a','b') > 0 THEN NULL ELSE GREATEST('a','b') END as `f3`,
       CASE WHEN NUM_NULLS(1,NULL,0) > 0 THEN NULL ELSE GREATEST(1,NULL,0) END as `f4`,
       CASE WHEN NUM_NULLS(NULL,NULL) > 0 THEN NULL ELSE GREATEST(NULL,NULL) END as `f5`
    FROM malloytest.state_facts as base
    GROUP BY 1,2,3,4,5,6
    ORDER BY 1 asc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `NUM_NULLS` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 13

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       CASE WHEN NUM_NULLS(1,10,-100) > 0 THEN NULL ELSE LEAST(1,10,-100) END as `f0`,
       ((CASE WHEN NUM_NULLS(DATE '2003-01-01',DATE '2004-01-01',DATE '1994-01-01') > 0 THEN NULL ELSE LEAST(DATE '2003-01-01',DATE '2004-01-01',DATE '1994-01-01') END)>=DATE '1994-01-01') and ((CASE WHEN NUM_NULLS(DATE '2003-01-01',DATE '2004-01-01',DATE '1994-01-01') > 0 THEN NULL ELSE LEAST(DATE '2003-01-01',DATE '2004-01-01',DATE '1994-01-01') END)<DATE '1995-01-01') as `f1`,
       (CASE WHEN NUM_NULLS(timestamp '2023-05-26 11:58:00',timestamp '2023-05-26 11:59:00') > 0 THEN NULL ELSE LEAST(timestamp '2023-05-26 11:58:00',timestamp '2023-05-26 11:59:00') END)=timestamp '2023-05-26 11:58:00' as `f2`,
       CASE WHEN NUM_NULLS('a','b') > 0 THEN NULL ELSE LEAST('a','b') END as `f3`,
       CASE WHEN NUM_NULLS(1,NULL,0) > 0 THEN NULL ELSE LEAST(1,NULL,0) END as `f4`,
       CASE WHEN NUM_NULLS(NULL,NULL) > 0 THEN NULL ELSE LEAST(NULL,NULL) END as `f5`
    FROM malloytest.state_facts as base
    GROUP BY 1,2,3,4,5,6
    ORDER BY 1 asc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `NUM_NULLS` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 13

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       STRPOS('123456789','3') as `f0`,
       STRPOS('123456789','0') as `f1`,
       STRPOS(NULL,'0') as `f2`,
       STRPOS('123456789',NULL) as `f3`
    FROM malloytest.state_facts as base
    GROUP BY 1,2,3,4
    ORDER BY 1 asc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `STRPOS` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       COALESCE(STARTS_WITH('hello world', 'hello'), false) as `f0`,
       COALESCE(STARTS_WITH('hello world', 'world'), false) as `f1`,
       COALESCE(STARTS_WITH(NULL, 'world'), false) as `f2`,
       COALESCE(STARTS_WITH('hello world', NULL), false) as `f3`
    FROM malloytest.state_facts as base
    GROUP BY 1,2,3,4
    ORDER BY 1 asc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `STARTS_WITH` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 12

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,base.`state`,base.`popular_name`,base.`state`))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error:
    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,base.`state`,base.`popular_name`,base.`state`))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o'))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error:
    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o'))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), '') as value
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o',''))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error:
    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), '') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o',''))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       EXTRACT(year FROM base.`dep_time`) as `yr`,
       EXTRACT(quarter FROM base.`dep_time`) as `qtr`,
       COUNT(1) as `qtr_flights`,
       LAG((COUNT(1))) OVER(PARTITION BY (EXTRACT(quarter FROM base.`dep_time`)) ORDER BY (EXTRACT(year FROM base.`dep_time`)) ASC ) as `last_yr_qtr_flights`
    FROM malloytest.flights as base
    WHERE base.`dep_time`<timestamp '2002-01-01 00:00:00'
    GROUP BY 1,2
    ORDER BY 1 ASC NULLS LAST,2 ASC NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [MISSING_AGGREGATION] The non-aggregating expression "dep_time" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(dep_time)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       COUNT(1) as `c`,
       SUBSTR(base.`state`, CASE WHEN 1 < 0 THEN LENGTH(base.`state`) + 1 + 1 ELSE 1 END, 1) as `l`,
       LAG((SUBSTR(base.`state`, CASE WHEN 1 < 0 THEN LENGTH(base.`state`) + 1 + 1 ELSE 1 END, 1))) OVER(PARTITION BY (COUNT(1))  ORDER BY  SUBSTR(base.`state`, CASE WHEN 1 < 0 THEN LENGTH(base.`state`) + 1 + 1 ELSE 1 END, 1) ASC NULLS LAST ) as `prev`
    FROM malloytest.state_facts as base
    GROUP BY 2
    ORDER BY 2 ASC NULLS LAST
    LIMIT 5

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [MISSING_AGGREGATION] The non-aggregating expression "state" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(state)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
FAIL test/src/databases/all/functions.spec.ts (122.273 s)
  concat
    ✕ works - databricks (9649 ms)
  round
    ✓ works - databricks (1279 ms)
  floor
    ✓ works - databricks (2111 ms)
  ceil
    ✓ works - databricks (1191 ms)
  length
    ✓ works - databricks (907 ms)
  lower
    ✓ works - databricks (930 ms)
  upper
    ✓ works - databricks (1402 ms)
  regexp_extract
    ✓ works - databricks (1357 ms)
  replace
    ✓ works - databricks (1156 ms)
  substr
    ✓ works - databricks (1043 ms)
  raw function call
    ✓ works - databricks (1072 ms)
  row_number
    ✓ works when the order by is a dimension  - databricks (1071 ms)
    ✓ works when the order by is a dimension in the other order  - databricks (1074 ms)
    ✓ works when the order by is a measure - databricks (1062 ms)
    ✓ works when the order by is a measure but there is no group by - databricks (1572 ms)
    ✕ works inside nest - databricks (980 ms)
    ✓ works outside nest, but with a nest nearby - databricks (1690 ms)
  rank
    ✕ works ordered by dimension - databricks (910 ms)
    ✓ works ordered by aggregate - databricks (1056 ms)
    ✓ works using unary minus in calculate block - databricks (1065 ms)
    ✕ properly isolated nested calculations - databricks (1183 ms)
  lag
    ✓ works with one param - databricks (1275 ms)
    ✕ works with expression field - databricks (1203 ms)
    ✓ works with expression - databricks (1361 ms)
    ✕ works with field, ordering by expression field - databricks (579 ms)
    ✓ works with offset - databricks (926 ms)
    ✓ works with default value - databricks (937 ms)
    ✓ works with now as the default value - databricks (1357 ms)
  output field in calculate
    ✓ output field referenceable in calculate - databricks (1175 ms)
  first_value
    ✓ works in nest - databricks (1617 ms)
    ✓ works outside nest - databricks (1105 ms)
    ✓ works with an aggregate which is not in the query - databricks (1062 ms)
    ✓ works with a localized aggregate - databricks (1509 ms)
  trunc
    ✕ works - databricks (718 ms)
  log
    ✓ works - databricks (1053 ms)
  ln
    ✓ works - databricks (976 ms)
  exp
    ✓ works - databricks (894 ms)
  cos
    ✓ works - databricks (993 ms)
  acos
    ✓ works - databricks (991 ms)
  sin
    ✓ works - databricks (1216 ms)
  asin
    ✓ works - databricks (791 ms)
  tan
    ✓ works - databricks (1158 ms)
  atan
    ✓ works - databricks (782 ms)
  atan2
    ✓ works - databricks (801 ms)
  sqrt
    ✓ works - databricks (939 ms)
  pow
    ✓ works - databricks (780 ms)
  abs
    ✓ works - databricks (982 ms)
  sign
    ✓ works - databricks (1046 ms)
  is_inf
    ✕ works - databricks (729 ms)
  is_nan
    ✕ works - databricks (542 ms)
  greatest
    ✕ works - databricks (794 ms)
  least
    ✕ works - databricks (666 ms)
  div
    ✓ works - databricks (896 ms)
  strpos
    ✕ works - databricks (725 ms)
  starts_with
    ✕ works - databricks (818 ms)
  ends_with
    ✓ works - databricks (1010 ms)
  trim
    ✕ trim works - databricks (996 ms)
  ltrim
    ✕ ltrim works - databricks (1048 ms)
  rtrim
    ✕ rtrim works - databricks (971 ms)
  rand
    ✓ is usually not the same value - databricks (818 ms)
  pi
    ✓ is pi - databricks (932 ms)
  byte_length
    ✓ works - databricks (998 ms)
  ifnull
    ✓ works - databricks (917 ms)
  coalesce
    ✓ works - databricks (941 ms)
  nullif
    ✓ works - databricks (861 ms)
  chr
    ✓ works - databricks (1023 ms)
  ascii
    ✓ works - databricks (1080 ms)
  unicode
    ✓ works - databricks (1137 ms)
  string_repeat
    ✓ works - databricks (918 ms)
    ○ skipped works floor decimal - databricks
  reverse
    ✓ works - databricks (832 ms)
  lead
    ✓ works with one param - databricks (1114 ms)
    ✓ works with offset - databricks (850 ms)
    ✓ works with default value - databricks (1230 ms)
  count_approx
    ○ skipped works generally
    ○ skipped works with fanout
  last_value
    ✓ works - databricks (1215 ms)
  avg_moving
    ✓ works - databricks (1531 ms)
    ✓ works forward - databricks (1066 ms)
  sum_moving
    ✓ works - databricks (1117 ms)
    ✓ works forward - databricks (947 ms)
  min, max, sum / window, cumulative
    ✓ works - databricks (1036 ms)
  hll_functions
    ○ skipped hyperloglog basic - databricks
    ○ skipped hyperloglog combine - databricks
    ○ skipped hyperloglog import/export - databricks
  dialect functions
    duckdb
      ○ skipped to_timestamp
      ○ skipped list_extract
      ○ skipped date_part,to_seconds
    trino
      ○ skipped from_unixtime
  databricks
    string_agg
      ✓ works no order by - databricks (1206 ms)
      ✓ works with dotted shortcut - databricks (878 ms)
      ✓ works with order by field - databricks (1238 ms)
      ✓ works with order by direction - databricks (28 ms)
      ✕ works with multiple order_bys - databricks (956 ms)
      ✕ works with order by expression - databricks (1091 ms)
      ✕ works with order by join expression - databricks (1156 ms)
      ✓ works with order asc - databricks (970 ms)
      ✕ works with order desc - databricks (682 ms)
      ✕ works with fanout and order_by - databricks (637 ms)
      ✕ works with fanout - databricks (647 ms)
      ✕ works with fanout and separator - databricks (569 ms)
      ✓ works with limit - databricks (31 ms)
    string_agg_distinct
      ✕ actually distincts - databricks (1253 ms)
      ✓ works no order by - databricks (880 ms)
      ✓ works with dotted shortcut - databricks (721 ms)
      ✓ works with order by direction - databricks (975 ms)
      ✓ works with order asc - databricks (934 ms)
      ✕ works with order desc - databricks (942 ms)
      ✓ works with limit - databricks (16 ms)
    partition_by
      ✕ works - databricks (783 ms)
      ✕ works with aggregate - databricks (678 ms)
      ✓ works with multiple order_bys - databricks (1193 ms)
      ✓ can be used in a select (1015 ms)

  ● concat › works - databricks

    expect(received).toBe(expected) // Object.is equality

    Expected: "foo2003-01-01 00:00:00"
    Received: "foo2003-01-01 12:00:00"

      119 |       // console.log(databaseName, result.sql);
      120 |       // console.log(result.data);
    > 121 |       expect(result.data.path(0, `f${i}`).value).toBe(testCase[1]);
          |                                                  ^
      122 |     });
      123 |   };
      124 |

      at test/src/databases/all/functions.spec.ts:121:50
          at Array.forEach (<anonymous>)
      at funcTestMultiple (test/src/databases/all/functions.spec.ts:118:15)
      at async Object.<anonymous> (test/src/databases/all/functions.spec.ts:137:7)

  ● row_number › works inside nest - databricks

    [MISSING_AGGREGATION] The non-aggregating expression "county" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(county)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● rank › works ordered by dimension - databricks

    [MISSING_AGGREGATION] The non-aggregating expression "births" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(births)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● rank › properly isolated nested calculations - databricks

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `TO_JSONB` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 38 pos 4
    SQL: WITH __stage0 AS (
      SELECT
        group_set,
        base.`faa_region` as `faa_region__0`,
        CASE WHEN group_set=0 THEN
          COUNT(1)
          END as `airport_count__0`,
        CASE WHEN group_set=0 THEN ROW_NUMBER() OVER(PARTITION BY group_set  ORDER BY  CASE WHEN group_set=0 THEN
          COUNT(1)
          END desc NULLS LAST ) END as `id__0`,
        CASE WHEN group_set IN (1,2) THEN
          base.`fac_type`
          END as `fac_type__1`,
        CASE WHEN group_set=1 THEN
          COUNT(1)
          END as `airport_count__1`,
        CASE WHEN group_set=1 THEN ROW_NUMBER() OVER(PARTITION BY group_set, base.`faa_region`  ORDER BY  CASE WHEN group_set=1 THEN
          COUNT(1)
          END desc NULLS LAST ) END as `id2__1`,
        CASE WHEN group_set=2 THEN
          AVG(base.`elevation`)
          END as `avg_elevation__2`
      FROM malloytest.airports as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,5
    )
    , __stage1 AS (
      SELECT
        CASE WHEN group_set=2 THEN 1 ELSE group_set END as group_set,
        `faa_region__0` as `faa_region__0`,
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count__0`,
        GET((ARRAY_AGG(`id__0`) FILTER (WHERE group_set=0 AND `id__0` IS NOT NULL)),0) as `id__0`,
        CASE WHEN group_set IN (1,2) THEN
          `fac_type__1`
          END as `fac_type__1`,
        GET((ARRAY_AGG(`airport_count__1`) FILTER (WHERE group_set=1 AND `airport_count__1` IS NOT NULL)),0) as `airport_count__1`,
        GET((ARRAY_AGG(`id2__1`) FILTER (WHERE group_set=1 AND `id2__1` IS NOT NULL)),0) as `id2__1`,
        TO_JSONB((ARRAY_AGG((SELECT __x FROM (SELECT
          `avg_elevation__2`::BIGINT as `avg_elevation`) as __x)) FILTER (WHERE group_set=2))[1]) as `elevation__1`
      FROM __stage0
      GROUP BY 1,2,5
    )
    , __stage2 AS (
      SELECT
        `faa_region__0` as `faa_region`,
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count`,
        GET((ARRAY_AGG(`id__0`) FILTER (WHERE group_set=0 AND `id__0` IS NOT NULL)),0) as `id`,
        SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=1 THEN STRUCT(
          `airport_count__1`::BIGINT as `airport_count`,
          `fac_type__1` as `fac_type`,
          `id2__1`::BIGINT as `id2`,
          `elevation__1` as `elevation`) END), ARRAY()), false), 1, 2) as `by_fac_type`
      FROM __stage1
      GROUP BY 1
    )
    SELECT
       CAST(get_json_object(by_fac_type_0, '$.id2') AS DOUBLE) as `id2`
    FROM __stage2 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`by_fac_type`)) as value) as by_fac_type_0 ON true
    GROUP BY 1
    ORDER BY 1 desc NULLS LAST

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `TO_JSONB` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 38 pos 4

      502 |             order_by: id2 desc
      503 |           }
    > 504 |       `).malloyResultMatches(expressionModel, {
          |          ^
      505 |         id2: 2,
      506 |       });
      507 |     });

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:504:10)

  ● lag › works with expression field - databricks

    [MISSING_AGGREGATION] The non-aggregating expression "state" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(state)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● lag › works with field, ordering by expression field - databricks

    [MISSING_AGGREGATION] The non-aggregating expression "state" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(state)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● trunc › works - databricks

    [WRONG_NUM_ARGS.WITHOUT_SUGGESTION] The `trunc` requires 2 parameters but the actual number is 1. Please, refer to 'https://spark.apache.org/docs/latest/sql-ref-functions.html' for a fix. SQLSTATE: 42605; line 2 pos 3

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● is_inf › works - databricks


    [UNSUPPORTED_TYPED_LITERAL] Literals of the type "DOUBLE" are not supported. Supported types are "DATE", "TIMESTAMP_NTZ", "TIMESTAMP_LTZ", "TIMESTAMP", "INTERVAL", "X". SQLSTATE: 0A000
    == SQL (line 2, position 38) ==
    ...ALESCE(CAST('+inf' AS double) = DOUBLE 'Infinity' OR CAST('+inf' AS double) = DOU...
                                       ^^^^^^^^^^^^^^^^^

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● is_nan › works - databricks


    [UNSUPPORTED_TYPED_LITERAL] Literals of the type "NUMERIC" are not supported. Supported types are "DATE", "TIMESTAMP_NTZ", "TIMESTAMP_LTZ", "TIMESTAMP", "INTERVAL", "X". SQLSTATE: 0A000
    == SQL (line 2, position 37) ==
    ...OALESCE(CAST('NaN' AS double) = NUMERIC 'NaN', false) as `f0`,
                                       ^^^^^^^^^^^^^

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● greatest › works - databricks

    [UNRESOLVED_ROUTINE] Cannot resolve routine `NUM_NULLS` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 13

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● least › works - databricks

    [UNRESOLVED_ROUTINE] Cannot resolve routine `NUM_NULLS` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 13

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● strpos › works - databricks

    [UNRESOLVED_ROUTINE] Cannot resolve routine `STRPOS` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● starts_with › works - databricks

    [UNRESOLVED_ROUTINE] Cannot resolve routine `STARTS_WITH` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 12

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● trim › trim works - databricks

    expect(received).toBe(expected) // Object.is equality

    Expected: "keep_this"
    Received: ""

      119 |       // console.log(databaseName, result.sql);
      120 |       // console.log(result.data);
    > 121 |       expect(result.data.path(0, `f${i}`).value).toBe(testCase[1]);
          |                                                  ^
      122 |     });
      123 |   };
      124 |

      at test/src/databases/all/functions.spec.ts:121:50
          at Array.forEach (<anonymous>)
      at funcTestMultiple (test/src/databases/all/functions.spec.ts:118:15)
      at async Object.<anonymous> (test/src/databases/all/functions.spec.ts:947:7)

  ● ltrim › ltrim works - databricks

    expect(received).toBe(expected) // Object.is equality

    Expected: "keep_this -> __"
    Received: ""

      119 |       // console.log(databaseName, result.sql);
      120 |       // console.log(result.data);
    > 121 |       expect(result.data.path(0, `f${i}`).value).toBe(testCase[1]);
          |                                                  ^
      122 |     });
      123 |   };
      124 |

      at test/src/databases/all/functions.spec.ts:121:50
          at Array.forEach (<anonymous>)
      at funcTestMultiple (test/src/databases/all/functions.spec.ts:118:15)
      at async Object.<anonymous> (test/src/databases/all/functions.spec.ts:959:7)

  ● rtrim › rtrim works - databricks

    expect(received).toBe(expected) // Object.is equality

    Expected: "__ <- keep_this"
    Received: ""

      119 |       // console.log(databaseName, result.sql);
      120 |       // console.log(result.data);
    > 121 |       expect(result.data.path(0, `f${i}`).value).toBe(testCase[1]);
          |                                                  ^
      122 |     });
      123 |   };
      124 |

      at test/src/databases/all/functions.spec.ts:121:50
          at Array.forEach (<anonymous>)
      at funcTestMultiple (test/src/databases/all/functions.spec.ts:118:15)
      at async Object.<anonymous> (test/src/databases/all/functions.spec.ts:971:7)

  ● databricks › string_agg › works with multiple order_bys - databricks

    SQL Generated:
      SELECT
         ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST(base.`name`)), ',') as `f`
      FROM malloytest.aircraft as base
      WHERE base.`name` RLIKE '.*RUTHERFORD.*'

    Expected {f: "RUTHERFORD PAT R JR,RUTHERFORD JAMES C"} Got: "RUTHERFORD JAMES C,RUTHERFORD PAT R JR"

      1425 |           order_by: city, name
      1426 |         }
    > 1427 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1428 |         f: 'RUTHERFORD PAT R JR,RUTHERFORD JAMES C',
      1429 |       });
      1430 |     });

      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1427:11)

  ● databricks › string_agg › works with order by expression - databricks

    SQL Generated:
      WITH __stage0 AS (
        SELECT
           base.`name` as `name`
        FROM malloytest.aircraft as base
        WHERE base.`name` RLIKE '.*FLY.*'
        GROUP BY 1
        ORDER BY 1 desc NULLS LAST
        LIMIT 3
      )
      SELECT
         ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST(base.`name`)), ',') as `f`
      FROM __stage0 as base

    Expected {f: "YANKEE FLYING CLUB INC,WESTCHESTER FLYING CLUB,WILSON FLYING SERVICE INC"} Got: "WESTCHESTER FLYING CLUB,WILSON FLYING SERVICE INC,YANKEE FLYING CLUB INC"

      1441 |           order_by: length(name)
      1442 |         }
    > 1443 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1444 |         f: 'YANKEE FLYING CLUB INC,WESTCHESTER FLYING CLUB,WILSON FLYING SERVICE INC',
      1445 |       });
      1446 |     });

      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1443:11)

  ● databricks › string_agg › works with order by join expression - databricks

    SQL Generated:
      SELECT
         ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST(base.`name`)), ',') as `f`
      FROM malloytest.aircraft as base
       LEFT JOIN malloytest.aircraft_models AS aircraft_models_0
        ON aircraft_models_0.`aircraft_model_code`=base.`aircraft_model_code`
      WHERE base.`name` RLIKE '.*ADVENTURE.*'

    Expected {f: "ADVENTURE INC,SEA PLANE ADVENTURE INC,A BALLOON ADVENTURES ALOFT,A AERONAUTICAL ADVENTURE INC"} Got: "A AERONAUTICAL ADVENTURE INC,A BALLOON ADVENTURES ALOFT,ADVENTURE INC,SEA PLANE ADVENTURE INC"

      1451 |         where: name ~ r'.*ADVENTURE.*'
      1452 |         aggregate: f is string_agg(name, ',') { order_by: aircraft_models.model }
    > 1453 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1454 |         f: 'ADVENTURE INC,SEA PLANE ADVENTURE INC,A BALLOON ADVENTURES ALOFT,A AERONAUTICAL ADVENTURE INC',
      1455 |       });
      1456 |     });

      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1453:11)

  ● databricks › string_agg › works with order desc - databricks

    SQL Generated:
      WITH __stage0 AS (
        SELECT
           base.`name` as `name`
        FROM malloytest.aircraft as base
        WHERE base.`name` RLIKE '.*FLY.*'
        GROUP BY 1
        ORDER BY 1 desc NULLS LAST
        LIMIT 3
      )
      SELECT
         ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST(base.`name`)), ',') as `f`
      FROM __stage0 as base

    Expected {f: "YANKEE FLYING CLUB INC,WILSON FLYING SERVICE INC,WESTCHESTER FLYING CLUB"} Got: "WESTCHESTER FLYING CLUB,WILSON FLYING SERVICE INC,YANKEE FLYING CLUB INC"

      1479 |       } -> {
      1480 |         aggregate: f is string_agg(name, ',') { order_by: name desc }
    > 1481 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1482 |         f: 'YANKEE FLYING CLUB INC,WILSON FLYING SERVICE INC,WESTCHESTER FLYING CLUB',
      1483 |       });
      1484 |     });

      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1481:11)

  ● databricks › string_agg › works with fanout and order_by - databricks

    query.run failed:
    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,base.`state`,base.`popular_name`,base.`state`))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

    SQL: SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,base.`state`,base.`popular_name`,base.`state`))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,base.`state`,base.`popular_name`,base.`state`))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

      1501 |           order_by: popular_name, state
      1502 |         }
    > 1503 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1504 |         s: 'IA,LA,MN,AL,AR,IN,ME,MT,NC,AZ,CA,CO,CT,FL,GA,HI,IL,KS,KY,MA,MO,NJ,NM,NV,NY,OH,OK,PA,RI,TN,TX,WV,WY,DC,MS,SC,ID,NE,UT,VA,AK,DE,MD,MI,ND,NH,OR,SD,VT,WA,WI',
      1505 |         c: 51,
      1506 |       });

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1503:11)

  ● databricks › string_agg › works with fanout - databricks

    query.run failed:
    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o'))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

    SQL: SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o'))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o'))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

      1517 |         aggregate: c is state_facts2.count()
      1518 |         aggregate: s is string_agg('o')
    > 1519 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1520 |         s: 'o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o',
      1521 |         c: 51,
      1522 |       });

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1519:11)

  ● databricks › string_agg › works with fanout and separator - databricks

    query.run failed:
    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), '') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o',''))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

    SQL: SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), '') as value
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o',''))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), '') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o',''))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

      1533 |         aggregate: c is state_facts2.count()
      1534 |         aggregate: s is string_agg('o', '')
    > 1535 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1536 |         s: 'ooooooooooooooooooooooooooooooooooooooooooooooooooo',
      1537 |         c: 51,
      1538 |       });

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1535:11)

  ● databricks › string_agg_distinct › actually distincts - databricks

    SQL Generated:
      SELECT
         ARRAY_JOIN(ARRAY_SORT(COLLECT_SET(aircraft_0.`name`)), ', ') as `f_dist`,
         ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST(aircraft_0.`name`)), ', ') as `f_all`
      FROM malloytest.aircraft_models as base
       LEFT JOIN malloytest.aircraft AS aircraft_0
        ON base.`aircraft_model_code`=aircraft_0.`aircraft_model_code`
      WHERE aircraft_0.`name` IN ('RAYTHEON AIRCRAFT COMPANY','FOWLER IRA R DBA')

    Expected {f_dist: "FOWLER IRA R DBA,RAYTHEON AIRCRAFT COMPANY"} Got: "FOWLER IRA R DBA, RAYTHEON AIRCRAFT COMPANY"
    Expected {f_all: "FOWLER IRA R DBA,FOWLER IRA R DBA,RAYTHEON AIRCRAFT COMPANY,RAYTHEON AIRCRAFT COMPANY"} Got: "FOWLER IRA R DBA, FOWLER IRA R DBA, RAYTHEON AIRCRAFT COMPANY, RAYTHEON AIRCRAFT COMPANY"

      1580 |           aggregate: f_dist is aircraft.name.string_agg_distinct() { order_by: asc }
      1581 |           aggregate: f_all is aircraft.name.string_agg() { order_by: aircraft.name }
    > 1582 |       }`).malloyResultMatches(runtime, {
           |           ^
      1583 |         f_dist: 'FOWLER IRA R DBA,RAYTHEON AIRCRAFT COMPANY',
      1584 |         f_all:
      1585 |           'FOWLER IRA R DBA,FOWLER IRA R DBA,RAYTHEON AIRCRAFT COMPANY,RAYTHEON AIRCRAFT COMPANY',

      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1582:11)

  ● databricks › string_agg_distinct › works with order desc - databricks

    SQL Generated:
      WITH __stage0 AS (
        SELECT
           base.`name` as `name`
        FROM malloytest.aircraft as base
        WHERE base.`name` RLIKE '.*FLY.*'
        GROUP BY 1
        ORDER BY 1 desc NULLS LAST
        LIMIT 3
      )
      SELECT
         ARRAY_JOIN(ARRAY_SORT(COLLECT_SET(base.`name`)), ',') as `f`
      FROM __stage0 as base

    Expected {f: "YANKEE FLYING CLUB INC,WILSON FLYING SERVICE INC,WESTCHESTER FLYING CLUB"} Got: "WESTCHESTER FLYING CLUB,WILSON FLYING SERVICE INC,YANKEE FLYING CLUB INC"

      1640 |       } -> {
      1641 |         aggregate: f is string_agg_distinct(name, ',') { order_by: desc }
    > 1642 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1643 |         f: 'YANKEE FLYING CLUB INC,WILSON FLYING SERVICE INC,WESTCHESTER FLYING CLUB',
      1644 |       });
      1645 |     });

      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1642:11)

  ● databricks › partition_by › works - databricks

    query.run failed: [MISSING_AGGREGATION] The non-aggregating expression "dep_time" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(dep_time)" if you do not care which of the values within a group is returned. SQLSTATE: 42803
    SQL: SELECT
       EXTRACT(year FROM base.`dep_time`) as `yr`,
       EXTRACT(quarter FROM base.`dep_time`) as `qtr`,
       COUNT(1) as `qtr_flights`,
       LAG((COUNT(1))) OVER(PARTITION BY (EXTRACT(quarter FROM base.`dep_time`)) ORDER BY (EXTRACT(year FROM base.`dep_time`)) ASC ) as `last_yr_qtr_flights`
    FROM malloytest.flights as base
    WHERE base.`dep_time`<timestamp '2002-01-01 00:00:00'
    GROUP BY 1,2
    ORDER BY 1 ASC NULLS LAST,2 ASC NULLS LAST

    Error: [MISSING_AGGREGATION] The non-aggregating expression "dep_time" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(dep_time)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      1688 |         order_by: yr, qtr
      1689 |         where: dep_time < @2002
    > 1690 |       }`).malloyResultMatches(expressionModel, [
           |           ^
      1691 |         {yr: 2000, qtr: 1, qtr_flights: 12148, last_yr_qtr_flights: null},
      1692 |         {yr: 2000, qtr: 2, qtr_flights: 11599, last_yr_qtr_flights: null},
      1693 |         {yr: 2000, qtr: 3, qtr_flights: 12075, last_yr_qtr_flights: null},

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1690:11)

  ● databricks › partition_by › works with aggregate - databricks

    query.run failed: [MISSING_AGGREGATION] The non-aggregating expression "state" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(state)" if you do not care which of the values within a group is returned. SQLSTATE: 42803
    SQL: SELECT
       COUNT(1) as `c`,
       SUBSTR(base.`state`, CASE WHEN 1 < 0 THEN LENGTH(base.`state`) + 1 + 1 ELSE 1 END, 1) as `l`,
       LAG((SUBSTR(base.`state`, CASE WHEN 1 < 0 THEN LENGTH(base.`state`) + 1 + 1 ELSE 1 END, 1))) OVER(PARTITION BY (COUNT(1))  ORDER BY  SUBSTR(base.`state`, CASE WHEN 1 < 0 THEN LENGTH(base.`state`) + 1 + 1 ELSE 1 END, 1) ASC NULLS LAST ) as `prev`
    FROM malloytest.state_facts as base
    GROUP BY 2
    ORDER BY 2 ASC NULLS LAST
    LIMIT 5

    Error: [MISSING_AGGREGATION] The non-aggregating expression "state" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(state)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      1712 |         order_by: l
      1713 |         limit: 5
    > 1714 |       }`).malloyResultMatches(expressionModel, [
           |           ^
      1715 |         {l: 'A', c: 4, prev: null},
      1716 |         {l: 'C', c: 3, prev: null},
      1717 |         {l: 'D', c: 2, prev: null},

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1714:11)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
        group_set,
        CASE WHEN group_set=0 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__0`,
        CASE WHEN group_set IN (1,2,3) THEN
          base.`popular_name`
          END as `popular_name__1`,
        CASE WHEN group_set=1 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__1`,
        CASE WHEN group_set=2 THEN
          base.`state`
          END as `state__2`,
        CASE WHEN group_set=2 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__2`,
        CASE WHEN group_set=3 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `inline_sum__3`
      FROM malloytest.state_facts as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,3,1)) as group_set)
      GROUP BY 1,3,5
    )
    , __stage1 AS (
      SELECT
        CASE WHEN group_set=2 THEN 1 WHEN group_set=3 THEN 1 ELSE group_set END as group_set,
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count__0`,
        CASE WHEN group_set IN (1,2,3) THEN
          `popular_name__1`
          END as `popular_name__1`,
        GET((ARRAY_AGG(`airport_count__1`) FILTER (WHERE group_set=1 AND `airport_count__1` IS NOT NULL)),0) as `airport_count__1`,
        SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=2 THEN STRUCT(
          `airport_count__2`::BIGINT as `airport_count`,
          `state__2` as `state`) END), ARRAY()), false), 1, 2) as `by_state__1`,
        TO_JSONB((ARRAY_AGG((SELECT __x FROM (SELECT
          `inline_sum__3`::BIGINT as `inline_sum`) as __x)) FILTER (WHERE group_set=3))[1]) as `inline__1`
      FROM __stage0
      GROUP BY 1,3
    )
    SELECT
      GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count`,
      SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=1 THEN STRUCT(
        `airport_count__1`::BIGINT as `airport_count`,
        `popular_name__1` as `popular_name`,
        `by_state__1` as `by_state`,
        `inline__1` as `inline`) END), ARRAY()), false), 1, 3) as `o`
    FROM __stage1

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `TO_JSONB` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 37 pos 4

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
        group_set,
        CASE WHEN group_set=0 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__0`,
        CASE WHEN group_set IN (1,2) THEN
          base.`popular_name`
          END as `popular_name__1`,
        CASE WHEN group_set=1 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__1`,
        CASE WHEN group_set=2 THEN
          base.`state`
          END as `state__2`,
        CASE WHEN group_set=2 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__2`
      FROM malloytest.state_facts as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,3,5
    )
    , __stage1 AS (
      SELECT
        CASE WHEN group_set=2 THEN 1 ELSE group_set END as group_set,
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count__0`,
        CASE WHEN group_set IN (1,2) THEN
          `popular_name__1`
          END as `popular_name__1`,
        GET((ARRAY_AGG(`airport_count__1`) FILTER (WHERE group_set=1 AND `airport_count__1` IS NOT NULL)),0) as `airport_count__1`,
        SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=2 THEN STRUCT(
          `airport_count__2`::BIGINT as `airport_count`,
          `state__2` as `state`) END), ARRAY()), false), 1, 2) as `by_state__1`
      FROM __stage0
      GROUP BY 1,3
    )
    , __stage2 AS (
      SELECT
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count`,
        SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=1 THEN STRUCT(
          `airport_count__1`::BIGINT as `airport_count`,
          `popular_name__1` as `popular_name`,
          `by_state__1` as `by_state`) END), ARRAY()), false), 1, 3) as `o`
      FROM __stage1
    )
    SELECT
       COALESCE(SUM(CAST(get_json_object(by_state_0, '$.airport_count') AS DOUBLE)),0) as `airport_count`
    FROM __stage2 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`o`)) as value) as o_0 ON true
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(to_json(o_0.by_state))) as value) as by_state_0 ON true

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve "explode(to_json(outer(base.o)))" due to data type mismatch: The first parameter requires the ("ARRAY" or "MAP") type, however "to_json(outer(base.o))" has the type "STRING". SQLSTATE: 42K09; line 49 pos 37

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
FAIL test/src/databases/all/expr.spec.ts (54.917 s)
  databricks
    ✓ basic calculations (4702 ms)
    ✓ join dependencies tracked from annotated references (1102 ms)
    ✓ Floor() -or any function bustage with aggregates (970 ms)
    ✓ computes mod correctly (1708 ms)
    ✓ model: expression fixups. (1223 ms)
    ✓ simple turtle (1901 ms)
    ✕ double turtle (1111 ms)
    ✕ double turtle - pipeline (1102 ms)
    ✓ model: turtle (1308 ms)
    ✓ model: simple having (1034 ms)
    ✓ model: aggregate functions distinct min max (1477 ms)
    ✓ model: dates named (2522 ms)
    ✓ named query metadata undefined (1011 ms)
    ✓ named query metadata named (782 ms)
    ✓ named query metadata named head of pipeline (1107 ms)
    ✓ filtered explores basic (933 ms)
    ✓ sql cast (733 ms)
    ✓ case expressions (845 ms)
    ✓ sql safe cast (865 ms)
    ✓ many_field.sum() has correct locality (1032 ms)
    ✓ joined filtered sources (828 ms)
    ✓ joined filtered explores with NO dependencies (937 ms)
    ✓ nullish ?? operator (1364 ms)
    ✓ dimension expressions expanded with parens properly (532 ms)
    ○ skipped model: filtered turtle
    ○ skipped model: having in a nest
    ○ skipped model: turtle having on main
    ○ skipped model: having float group by partition
    ○ skipped query with aliasname used twice
    ○ skipped joined filtered explores with dependencies
    sql expr functions
      ✓ sql_string (748 ms)
      ✓ sql_number (759 ms)
      ✓ sql_number can be sum()med (808 ms)
      ✓ sql_boolean (783 ms)
      ✓ sql_date (1024 ms)
      ✓ sql_timestamp (626 ms)
      ✓ with ${TABLE}.field (587 ms)
      ✓ with ${field} (640 ms)
      [not yet supported]
        ✓ ${view_name.dimension_name} - one path (32 ms)
        ✓ ${view_name.dimension_name} - multiple paths (13 ms)
        ✓ ${view_name.SQL_TABLE_NAME} (11 ms)
    alternations with not-eq
      ○ skipped x not-eq y or z : x eq y
      ○ skipped x not-eq y or z : x eq z
      ○ skipped x not-eq y or z : else
      ○ skipped x not-eq y and not-eq z : x eq y
      ○ skipped x not-eq y and not-eq z : x eq z
      ○ skipped x not-eq y and not-eq z : else
    string literal quoting
      ✓ quote single character (572 ms)
      ✓ quote single quote (511 ms)
      ✓ quote double quote (467 ms)
      ✓ quote backslash (510 ms)
    null safe booleans
      ✓ select boolean (1289 ms)
      ✓ not boolean (708 ms)
      ✓ numeric != non-null to null (492 ms)
      ✓ string !~ non-null to null (488 ms)
      ✓ regex !~ non-null to null (499 ms)
      ✓ numeric != null-to-null (538 ms)
      ✓ string !~ null-to-null (531 ms)

  ● databricks › double turtle

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `TO_JSONB` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 37 pos 4
    SQL: WITH __stage0 AS (
      SELECT
        group_set,
        CASE WHEN group_set=0 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__0`,
        CASE WHEN group_set IN (1,2,3) THEN
          base.`popular_name`
          END as `popular_name__1`,
        CASE WHEN group_set=1 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__1`,
        CASE WHEN group_set=2 THEN
          base.`state`
          END as `state__2`,
        CASE WHEN group_set=2 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__2`,
        CASE WHEN group_set=3 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `inline_sum__3`
      FROM malloytest.state_facts as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,3,1)) as group_set)
      GROUP BY 1,3,5
    )
    , __stage1 AS (
      SELECT
        CASE WHEN group_set=2 THEN 1 WHEN group_set=3 THEN 1 ELSE group_set END as group_set,
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count__0`,
        CASE WHEN group_set IN (1,2,3) THEN
          `popular_name__1`
          END as `popular_name__1`,
        GET((ARRAY_AGG(`airport_count__1`) FILTER (WHERE group_set=1 AND `airport_count__1` IS NOT NULL)),0) as `airport_count__1`,
        SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=2 THEN STRUCT(
          `airport_count__2`::BIGINT as `airport_count`,
          `state__2` as `state`) END), ARRAY()), false), 1, 2) as `by_state__1`,
        TO_JSONB((ARRAY_AGG((SELECT __x FROM (SELECT
          `inline_sum__3`::BIGINT as `inline_sum`) as __x)) FILTER (WHERE group_set=3))[1]) as `inline__1`
      FROM __stage0
      GROUP BY 1,3
    )
    SELECT
      GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count`,
      SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=1 THEN STRUCT(
        `airport_count__1`::BIGINT as `airport_count`,
        `popular_name__1` as `popular_name`,
        `by_state__1` as `by_state`,
        `inline__1` as `inline`) END), ARRAY()), false), 1, 3) as `o`
    FROM __stage1

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `TO_JSONB` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 37 pos 4

      169 |         }
      170 |       }
    > 171 |     `).malloyResultMatches(expressionModel, {
          |        ^
      172 |       'o.by_state.state': 'TX',
      173 |       'o.by_state.airport_count': 1845,
      174 |       'o.airport_count': 11146,

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/expr.spec.ts:171:8)

  ● databricks › double turtle - pipeline

    query.run failed: [DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve "explode(to_json(outer(base.o)))" due to data type mismatch: The first parameter requires the ("ARRAY" or "MAP") type, however "to_json(outer(base.o))" has the type "STRING". SQLSTATE: 42K09; line 49 pos 37
    SQL: WITH __stage0 AS (
      SELECT
        group_set,
        CASE WHEN group_set=0 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__0`,
        CASE WHEN group_set IN (1,2) THEN
          base.`popular_name`
          END as `popular_name__1`,
        CASE WHEN group_set=1 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__1`,
        CASE WHEN group_set=2 THEN
          base.`state`
          END as `state__2`,
        CASE WHEN group_set=2 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__2`
      FROM malloytest.state_facts as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,3,5
    )
    , __stage1 AS (
      SELECT
        CASE WHEN group_set=2 THEN 1 ELSE group_set END as group_set,
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count__0`,
        CASE WHEN group_set IN (1,2) THEN
          `popular_name__1`
          END as `popular_name__1`,
        GET((ARRAY_AGG(`airport_count__1`) FILTER (WHERE group_set=1 AND `airport_count__1` IS NOT NULL)),0) as `airport_count__1`,
        SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=2 THEN STRUCT(
          `airport_count__2`::BIGINT as `airport_count`,
          `state__2` as `state`) END), ARRAY()), false), 1, 2) as `by_state__1`
      FROM __stage0
      GROUP BY 1,3
    )
    , __stage2 AS (
      SELECT
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count`,
        SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=1 THEN STRUCT(
          `airport_count__1`::BIGINT as `airport_count`,
          `popular_name__1` as `popular_name`,
          `by_state__1` as `by_state`) END), ARRAY()), false), 1, 3) as `o`
      FROM __stage1
    )
    SELECT
       COALESCE(SUM(CAST(get_json_object(by_state_0, '$.airport_count') AS DOUBLE)),0) as `airport_count`
    FROM __stage2 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`o`)) as value) as o_0 ON true
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(to_json(o_0.by_state))) as value) as by_state_0 ON true

    Error: [DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve "explode(to_json(outer(base.o)))" due to data type mismatch: The first parameter requires the ("ARRAY" or "MAP") type, however "to_json(outer(base.o))" has the type "STRING". SQLSTATE: 42K09; line 49 pos 37

      195 |         aggregate: o.by_state.airport_count.sum()
      196 |       }
    > 197 |     `).malloyResultMatches(expressionModel, {
          |        ^
      198 |       'airport_count': 5023,
      199 |     });
      200 |   });

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/expr.spec.ts:197:8)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       COALESCE((SUM(DISTINCT (CAST(conv(substring(md5(concat(base.`__distinct_key`, '')), 1, 16), 16, 10) AS DECIMAL(38,0)) * 4294967296 + CAST(conv(substring(md5(concat(base.`__distinct_key`, '')), 16, 8), 16, 10) AS DECIMAL(38,0))) + COALESCE(0, 0)) - SUM(DISTINCT (CAST(conv(substring(md5(concat(base.`__distinct_key`, '')), 1, 16), 16, 10) AS DECIMAL(38,0)) * 4294967296 + CAST(conv(substring(md5(concat(base.`__distinct_key`, '')), 16, 8), 16, 10) AS DECIMAL(38,0))))),0) as `foo`,
       1 as `bar`,
       CAST(get_json_object(arr_0, '$.value') AS DOUBLE) as `each`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(JSONB_BUILD_ARRAY(1,2,3)) as value) as arr_0 ON true
    GROUP BY 2,3
    ORDER BY 1 desc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 6 pos 45

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
FAIL test/src/databases/all/composite_sources.spec.ts (34.808 s)
  databricks
    ✓ basic composite usage (2469 ms)
    ✓ composite usage multistage (825 ms)
    ✓ composite view multistage (649 ms)
    ✓ composite source used in join (753 ms)
    ✓ composite field from joined source used in join on (862 ms)
    ✓ composite field from joining source used in join on (893 ms)
    ✓ query against composite resolves nested composite source even when no composite fields (617 ms)
    ✓ composite field used in view (619 ms)
    ✓ composite field used in view refined with scalar (745 ms)
    ✓ composite field used in view refined with literal view (621 ms)
    ✓ composite field used in refined query (592 ms)
    ✓ composite of a composite (794 ms)
    ✓ definitions from composite extension carry through (857 ms)
    ✓ filters from composite extension carry through (996 ms)
    ✓ composite of a composite where greedy is bad- databricks (1025 ms)
    ✓ composite with parameters (849 ms)
    ✓ issue where measure defined on composite source has the wrong structPath (957 ms)
    ✓ issue where query against composite source with no composite field usage does not resolve the source (916 ms)
    ✓ reference composite field in nest
    ✓ composite with select * (699 ms)
    ✕ composite with each (858 ms)
    ✓ complex nesting composite without join (742 ms)
    ✓ complex nesting composite with join -- literal view (756 ms)
    ✓ complex nesting composite with join -- double extend to define view (925 ms)
    ✓ complex nesting composite with join -- defined view (775 ms)
    index queries against composite sources
      ✓ index query selects second input (1100 ms)
      ✓ index query selects first input (953 ms)
      ✓ index query resolves when two stages (900 ms)

  ● databricks › composite with each

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 6 pos 45
    SQL: SELECT
       COALESCE((SUM(DISTINCT (CAST(conv(substring(md5(concat(base.`__distinct_key`, '')), 1, 16), 16, 10) AS DECIMAL(38,0)) * 4294967296 + CAST(conv(substring(md5(concat(base.`__distinct_key`, '')), 16, 8), 16, 10) AS DECIMAL(38,0))) + COALESCE(0, 0)) - SUM(DISTINCT (CAST(conv(substring(md5(concat(base.`__distinct_key`, '')), 1, 16), 16, 10) AS DECIMAL(38,0)) * 4294967296 + CAST(conv(substring(md5(concat(base.`__distinct_key`, '')), 16, 8), 16, 10) AS DECIMAL(38,0))))),0) as `foo`,
       1 as `bar`,
       CAST(get_json_object(arr_0, '$.value') AS DOUBLE) as `each`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(JSONB_BUILD_ARRAY(1,2,3)) as value) as arr_0 ON true
    GROUP BY 2,3
    ORDER BY 1 desc NULLS LAST

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 6 pos 45

      283 |       }
      284 |       run: x -> { aggregate: foo; group_by: bar, arr.each }
    > 285 |     `).malloyResultMatches(runtime, {foo: 0});
          |        ^
      286 |   });
      287 |   it('complex nesting composite without join', async () => {
      288 |     await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/composite_sources.spec.ts:285:8)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
PASS test/src/databases/all/join.spec.ts (30.007 s)
  databricks
    ✓ model source refine join (3832 ms)
    ✓ model source refine in query join (900 ms)
    ✓ model: join fact table query (1058 ms)
    ✓ model: source based on query (892 ms)
    ✓ model: funnel - merge two queries (1513 ms)
    ✓ model: modeled funnel (999 ms)
    ✓ model: modeled funnel2 (854 ms)
    ✓ model: double_pipe (840 ms)
    ✓ All joins at the same level (2234 ms)
    ✓ join issue440 (1039 ms)
    ✓ join issue1092 (2324 ms)
    ✓ always join in query (820 ms)
    ✓ not always join in extend (923 ms)
    ✓ always inner join has side effects (in group_by) (1115 ms)
    ○ skipped model: unnest is left join

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
PASS test/src/databases/all/parameters.spec.ts (24.872 s)
  ✓ number param used in dimension - databricks (2789 ms)
  ✓ number param used in sql function - databricks (680 ms)
  ✓ can pass param into joined source correctly - databricks (1359 ms)
  ✓ can pass param into extended source - databricks (787 ms)
  ✓ can shadow field that is excepted - databricks (978 ms)
  ✓ default value propagates - databricks (824 ms)
  ✓ default value can be overridden - databricks (856 ms)
  ✓ default value passed through extension propagates - databricks (752 ms)
  ✓ use parameter in nested view - databricks (1 ms)
  ✓ can use param in join on - databricks (1144 ms)
  ✓ can use param in join with - databricks (1039 ms)
  ✓ source arguments in query propagate when turned into source - databricks (823 ms)
  ✓ date parameters keep granularity when passing in - databricks (732 ms)
  ✓ can use parameter in null check - databricks (777 ms)
  ✓ default value not passed through extension propagates - databricks (737 ms)
  ○ skipped string param used in group_by - databricks
  ○ skipped reference field in source in argument - databricks
  ○ skipped can use dimension that uses field that is excepted - databricks
  ○ skipped can shadow field that is excepted, using dimension that uses field that is excepted - databricks
  ○ skipped can pass param into joined source from query - databricks
  ○ skipped can pass param into query definition - databricks

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
PASS test/src/databases/all/orderby.spec.ts (21.437 s)
  databricks
    ✓ boolean type - databricks (2869 ms)
    ✓ boolean in pipeline - databricks (967 ms)
    ✓ filtered measures in model are aggregates #352 - databricks (1157 ms)
    ✓ reserved words are quoted - databricks (868 ms)
    ✓ aggregate and scalar conditions - databricks (1009 ms)
    ✓ modeled having simple - databricks (1023 ms)
    ✓ turtle references joined element - databricks (2931 ms)
    ○ skipped reserved words are quoted in turtles - databricks
    ○ skipped reserved words in structure definitions
    ○ skipped modeled having complex - databricks

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     CREATE TEMPORARY TABLE IF NOT EXISTS tt3ad65bcab16b5342b4b7de06835adfe4 AS (WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.airports TABLESAMPLE SYSTEM_ROWS(50000)) as x limit 100000 )
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'act_date'
          WHEN 1 THEN 'aero_cht'
          WHEN 2 THEN 'c_ldg_rts'
          WHEN 3 THEN 'cbd_dir'
          WHEN 4 THEN 'cbd_dist'
          WHEN 5 THEN 'cert'
          WHEN 6 THEN 'city'
          WHEN 7 THEN 'cntl_twr'
          WHEN 8 THEN 'code'
          WHEN 9 THEN 'county'
          WHEN 10 THEN 'cust_intl'
          WHEN 11 THEN 'elevation'
          WHEN 12 THEN 'faa_dist'
          WHEN 13 THEN 'faa_region'
          WHEN 14 THEN 'fac_type'
          WHEN 15 THEN 'fac_use'
          WHEN 16 THEN 'fed_agree'
          WHEN 17 THEN 'full_name'
          WHEN 18 THEN 'id'
          WHEN 19 THEN 'joint_use'
          WHEN 20 THEN 'latitude'
          WHEN 21 THEN 'longitude'
          WHEN 22 THEN 'major'
          WHEN 23 THEN 'mil_rts'
          WHEN 24 THEN 'own_type'
          WHEN 25 THEN 'site_number'
          WHEN 26 THEN 'state'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'act_date'
          WHEN 1 THEN 'aero_cht'
          WHEN 2 THEN 'c_ldg_rts'
          WHEN 3 THEN 'cbd_dir'
          WHEN 4 THEN 'cbd_dist'
          WHEN 5 THEN 'cert'
          WHEN 6 THEN 'city'
          WHEN 7 THEN 'cntl_twr'
          WHEN 8 THEN 'code'
          WHEN 9 THEN 'county'
          WHEN 10 THEN 'cust_intl'
          WHEN 11 THEN 'elevation'
          WHEN 12 THEN 'faa_dist'
          WHEN 13 THEN 'faa_region'
          WHEN 14 THEN 'fac_type'
          WHEN 15 THEN 'fac_use'
          WHEN 16 THEN 'fed_agree'
          WHEN 17 THEN 'full_name'
          WHEN 18 THEN 'id'
          WHEN 19 THEN 'joint_use'
          WHEN 20 THEN 'latitude'
          WHEN 21 THEN 'longitude'
          WHEN 22 THEN 'major'
          WHEN 23 THEN 'mil_rts'
          WHEN 24 THEN 'own_type'
          WHEN 25 THEN 'site_number'
          WHEN 26 THEN 'state'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
          WHEN 2 THEN 'string'
          WHEN 3 THEN 'string'
          WHEN 4 THEN 'number'
          WHEN 5 THEN 'string'
          WHEN 6 THEN 'string'
          WHEN 7 THEN 'string'
          WHEN 8 THEN 'string'
          WHEN 9 THEN 'string'
          WHEN 10 THEN 'string'
          WHEN 11 THEN 'number'
          WHEN 12 THEN 'string'
          WHEN 13 THEN 'string'
          WHEN 14 THEN 'string'
          WHEN 15 THEN 'string'
          WHEN 16 THEN 'string'
          WHEN 17 THEN 'string'
          WHEN 18 THEN 'number'
          WHEN 19 THEN 'string'
          WHEN 20 THEN 'number'
          WHEN 21 THEN 'number'
          WHEN 22 THEN 'string'
          WHEN 23 THEN 'string'
          WHEN 24 THEN 'string'
          WHEN 25 THEN 'string'
          WHEN 26 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN base.`act_date`
          WHEN 1 THEN base.`aero_cht`
          WHEN 2 THEN base.`c_ldg_rts`
          WHEN 3 THEN base.`cbd_dir`
          WHEN 5 THEN base.`cert`
          WHEN 6 THEN base.`city`
          WHEN 7 THEN base.`cntl_twr`
          WHEN 8 THEN base.`code`
          WHEN 9 THEN base.`county`
          WHEN 10 THEN base.`cust_intl`
          WHEN 12 THEN base.`faa_dist`
          WHEN 13 THEN base.`faa_region`
          WHEN 14 THEN base.`fac_type`
          WHEN 15 THEN base.`fac_use`
          WHEN 16 THEN base.`fed_agree`
          WHEN 17 THEN base.`full_name`
          WHEN 19 THEN base.`joint_use`
          WHEN 22 THEN base.`major`
          WHEN 23 THEN base.`mil_rts`
          WHEN 24 THEN base.`own_type`
          WHEN 25 THEN base.`site_number`
          WHEN 26 THEN base.`state`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''    WHEN 4 THEN CONCAT(MIN(CAST(base.`cbd_dist` as STRING)),' to ',CAST(MAX(base.`cbd_dist`) as STRING))
          WHEN 11 THEN CONCAT(MIN(CAST(base.`elevation` as STRING)),' to ',CAST(MAX(base.`elevation`) as STRING))
          WHEN 18 THEN CONCAT(MIN(CAST(base.`id` as STRING)),' to ',CAST(MAX(base.`id`) as STRING))
          WHEN 20 THEN CONCAT(MIN(CAST(base.`latitude` as STRING)),' to ',CAST(MAX(base.`latitude`) as STRING))
          WHEN 21 THEN CONCAT(MIN(CAST(base.`longitude` as STRING)),' to ',CAST(MAX(base.`longitude`) as STRING))
        END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,27,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    SELECT
      `fieldName`,
      `fieldPath`,
      `fieldType`,
      COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
      `weight`
    FROM __stage1
    )

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error:
    [PARSE_SYNTAX_ERROR] Syntax error at or near 'SYSTEM_ROWS': missing ')'. SQLSTATE: 42601 (line 2, pos 63)

    == SQL ==
    CREATE TEMPORARY TABLE IF NOT EXISTS tt3ad65bcab16b5342b4b7de06835adfe4 AS (WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.airports TABLESAMPLE SYSTEM_ROWS(50000)) as x limit 100000 )
    ---------------------------------------------------------------^^^
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'act_date'
          WHEN 1 THEN 'aero_cht'
          WHEN 2 THEN 'c_ldg_rts'
          WHEN 3 THEN 'cbd_dir'
          WHEN 4 THEN 'cbd_dist'
          WHEN 5 THEN 'cert'
          WHEN 6 THEN 'city'
          WHEN 7 THEN 'cntl_twr'
          WHEN 8 THEN 'code'
          WHEN 9 THEN 'county'
          WHEN 10 THEN 'cust_intl'
          WHEN 11 THEN 'elevation'
          WHEN 12 THEN 'faa_dist'
          WHEN 13 THEN 'faa_region'
          WHEN 14 THEN 'fac_type'
          WHEN 15 THEN 'fac_use'
          WHEN 16 THEN 'fed_agree'
          WHEN 17 THEN 'full_name'
          WHEN 18 THEN 'id'
          WHEN 19 THEN 'joint_use'
          WHEN 20 THEN 'latitude'
          WHEN 21 THEN 'longitude'
          WHEN 22 THEN 'major'
          WHEN 23 THEN 'mil_rts'
          WHEN 24 THEN 'own_type'
          WHEN 25 THEN 'site_number'
          WHEN 26 THEN 'state'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'act_date'
          WHEN 1 THEN 'aero_cht'
          WHEN 2 THEN 'c_ldg_rts'
          WHEN 3 THEN 'cbd_dir'
          WHEN 4 THEN 'cbd_dist'
          WHEN 5 THEN 'cert'
          WHEN 6 THEN 'city'
          WHEN 7 THEN 'cntl_twr'
          WHEN 8 THEN 'code'
          WHEN 9 THEN 'county'
          WHEN 10 THEN 'cust_intl'
          WHEN 11 THEN 'elevation'
          WHEN 12 THEN 'faa_dist'
          WHEN 13 THEN 'faa_region'
          WHEN 14 THEN 'fac_type'
          WHEN 15 THEN 'fac_use'
          WHEN 16 THEN 'fed_agree'
          WHEN 17 THEN 'full_name'
          WHEN 18 THEN 'id'
          WHEN 19 THEN 'joint_use'
          WHEN 20 THEN 'latitude'
          WHEN 21 THEN 'longitude'
          WHEN 22 THEN 'major'
          WHEN 23 THEN 'mil_rts'
          WHEN 24 THEN 'own_type'
          WHEN 25 THEN 'site_number'
          WHEN 26 THEN 'state'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
          WHEN 2 THEN 'string'
          WHEN 3 THEN 'string'
          WHEN 4 THEN 'number'
          WHEN 5 THEN 'string'
          WHEN 6 THEN 'string'
          WHEN 7 THEN 'string'
          WHEN 8 THEN 'string'
          WHEN 9 THEN 'string'
          WHEN 10 THEN 'string'
          WHEN 11 THEN 'number'
          WHEN 12 THEN 'string'
          WHEN 13 THEN 'string'
          WHEN 14 THEN 'string'
          WHEN 15 THEN 'string'
          WHEN 16 THEN 'string'
          WHEN 17 THEN 'string'
          WHEN 18 THEN 'number'
          WHEN 19 THEN 'string'
          WHEN 20 THEN 'number'
          WHEN 21 THEN 'number'
          WHEN 22 THEN 'string'
          WHEN 23 THEN 'string'
          WHEN 24 THEN 'string'
          WHEN 25 THEN 'string'
          WHEN 26 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN base.`act_date`
          WHEN 1 THEN base.`aero_cht`
          WHEN 2 THEN base.`c_ldg_rts`
          WHEN 3 THEN base.`cbd_dir`
          WHEN 5 THEN base.`cert`
          WHEN 6 THEN base.`city`
          WHEN 7 THEN base.`cntl_twr`
          WHEN 8 THEN base.`code`
          WHEN 9 THEN base.`county`
          WHEN 10 THEN base.`cust_intl`
          WHEN 12 THEN base.`faa_dist`
          WHEN 13 THEN base.`faa_region`
          WHEN 14 THEN base.`fac_type`
          WHEN 15 THEN base.`fac_use`
          WHEN 16 THEN base.`fed_agree`
          WHEN 17 THEN base.`full_name`
          WHEN 19 THEN base.`joint_use`
          WHEN 22 THEN base.`major`
          WHEN 23 THEN base.`mil_rts`
          WHEN 24 THEN base.`own_type`
          WHEN 25 THEN base.`site_number`
          WHEN 26 THEN base.`state`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''    WHEN 4 THEN CONCAT(MIN(CAST(base.`cbd_dist` as STRING)),' to ',CAST(MAX(base.`cbd_dist`) as STRING))
          WHEN 11 THEN CONCAT(MIN(CAST(base.`elevation` as STRING)),' to ',CAST(MAX(base.`elevation`) as STRING))
          WHEN 18 THEN CONCAT(MIN(CAST(base.`id` as STRING)),' to ',CAST(MAX(base.`id`) as STRING))
          WHEN 20 THEN CONCAT(MIN(CAST(base.`latitude` as STRING)),' to ',CAST(MAX(base.`latitude`) as STRING))
          WHEN 21 THEN CONCAT(MIN(CAST(base.`longitude` as STRING)),' to ',CAST(MAX(base.`longitude`) as STRING))
        END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,27,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    SELECT
      `fieldName`,
      `fieldPath`,
      `fieldType`,
      COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
      `weight`
    FROM __stage1
    )

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.state_facts TABLESAMPLE SYSTEM_ROWS(10)) as x limit 100000 )
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`state`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error:
    [PARSE_SYNTAX_ERROR] Syntax error at or near 'SYSTEM_ROWS'. SQLSTATE: 42601 (line 2, pos 66)

    == SQL ==
    WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.state_facts TABLESAMPLE SYSTEM_ROWS(10)) as x limit 100000 )
    ------------------------------------------------------------------^^^
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`state`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.flights TABLESAMPLE SYSTEM (50)) as x limit 100000 )
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`tail_num`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error:
    [PARSE_SYNTAX_ERROR] Syntax error at or near 'SYSTEM'. SQLSTATE: 42601 (line 2, pos 62)

    == SQL ==
    WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.flights TABLESAMPLE SYSTEM (50)) as x limit 100000 )
    --------------------------------------------------------------^^^
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`tail_num`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

FAIL test/src/databases/all/db_index.spec.ts (22.04 s)
  ✕ basic index  - databricks (2257 ms)
  ✕ index value map  - databricks (4301 ms)
  ✓ index no sample rows - databricks (2554 ms)
  ✕ index rows count - databricks (578 ms)
  ✕ index rows count - databricks (1966 ms)

  ● basic index  - databricks


    [PARSE_SYNTAX_ERROR] Syntax error at or near 'SYSTEM_ROWS': missing ')'. SQLSTATE: 42601 (line 2, pos 63)

    == SQL ==
    CREATE TEMPORARY TABLE IF NOT EXISTS tt3ad65bcab16b5342b4b7de06835adfe4 AS (WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.airports TABLESAMPLE SYSTEM_ROWS(50000)) as x limit 100000 )
    ---------------------------------------------------------------^^^
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'act_date'
          WHEN 1 THEN 'aero_cht'
          WHEN 2 THEN 'c_ldg_rts'
          WHEN 3 THEN 'cbd_dir'
          WHEN 4 THEN 'cbd_dist'
          WHEN 5 THEN 'cert'
          WHEN 6 THEN 'city'
          WHEN 7 THEN 'cntl_twr'
          WHEN 8 THEN 'code'
          WHEN 9 THEN 'county'
          WHEN 10 THEN 'cust_intl'
          WHEN 11 THEN 'elevation'
          WHEN 12 THEN 'faa_dist'
          WHEN 13 THEN 'faa_region'
          WHEN 14 THEN 'fac_type'
          WHEN 15 THEN 'fac_use'
          WHEN 16 THEN 'fed_agree'
          WHEN 17 THEN 'full_name'
          WHEN 18 THEN 'id'
          WHEN 19 THEN 'joint_use'
          WHEN 20 THEN 'latitude'
          WHEN 21 THEN 'longitude'
          WHEN 22 THEN 'major'
          WHEN 23 THEN 'mil_rts'
          WHEN 24 THEN 'own_type'
          WHEN 25 THEN 'site_number'
          WHEN 26 THEN 'state'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'act_date'
          WHEN 1 THEN 'aero_cht'
          WHEN 2 THEN 'c_ldg_rts'
          WHEN 3 THEN 'cbd_dir'
          WHEN 4 THEN 'cbd_dist'
          WHEN 5 THEN 'cert'
          WHEN 6 THEN 'city'
          WHEN 7 THEN 'cntl_twr'
          WHEN 8 THEN 'code'
          WHEN 9 THEN 'county'
          WHEN 10 THEN 'cust_intl'
          WHEN 11 THEN 'elevation'
          WHEN 12 THEN 'faa_dist'
          WHEN 13 THEN 'faa_region'
          WHEN 14 THEN 'fac_type'
          WHEN 15 THEN 'fac_use'
          WHEN 16 THEN 'fed_agree'
          WHEN 17 THEN 'full_name'
          WHEN 18 THEN 'id'
          WHEN 19 THEN 'joint_use'
          WHEN 20 THEN 'latitude'
          WHEN 21 THEN 'longitude'
          WHEN 22 THEN 'major'
          WHEN 23 THEN 'mil_rts'
          WHEN 24 THEN 'own_type'
          WHEN 25 THEN 'site_number'
          WHEN 26 THEN 'state'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
          WHEN 2 THEN 'string'
          WHEN 3 THEN 'string'
          WHEN 4 THEN 'number'
          WHEN 5 THEN 'string'
          WHEN 6 THEN 'string'
          WHEN 7 THEN 'string'
          WHEN 8 THEN 'string'
          WHEN 9 THEN 'string'
          WHEN 10 THEN 'string'
          WHEN 11 THEN 'number'
          WHEN 12 THEN 'string'
          WHEN 13 THEN 'string'
          WHEN 14 THEN 'string'
          WHEN 15 THEN 'string'
          WHEN 16 THEN 'string'
          WHEN 17 THEN 'string'
          WHEN 18 THEN 'number'
          WHEN 19 THEN 'string'
          WHEN 20 THEN 'number'
          WHEN 21 THEN 'number'
          WHEN 22 THEN 'string'
          WHEN 23 THEN 'string'
          WHEN 24 THEN 'string'
          WHEN 25 THEN 'string'
          WHEN 26 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN base.`act_date`
          WHEN 1 THEN base.`aero_cht`
          WHEN 2 THEN base.`c_ldg_rts`
          WHEN 3 THEN base.`cbd_dir`
          WHEN 5 THEN base.`cert`
          WHEN 6 THEN base.`city`
          WHEN 7 THEN base.`cntl_twr`
          WHEN 8 THEN base.`code`
          WHEN 9 THEN base.`county`
          WHEN 10 THEN base.`cust_intl`
          WHEN 12 THEN base.`faa_dist`
          WHEN 13 THEN base.`faa_region`
          WHEN 14 THEN base.`fac_type`
          WHEN 15 THEN base.`fac_use`
          WHEN 16 THEN base.`fed_agree`
          WHEN 17 THEN base.`full_name`
          WHEN 19 THEN base.`joint_use`
          WHEN 22 THEN base.`major`
          WHEN 23 THEN base.`mil_rts`
          WHEN 24 THEN base.`own_type`
          WHEN 25 THEN base.`site_number`
          WHEN 26 THEN base.`state`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''    WHEN 4 THEN CONCAT(MIN(CAST(base.`cbd_dist` as STRING)),' to ',CAST(MAX(base.`cbd_dist`) as STRING))
          WHEN 11 THEN CONCAT(MIN(CAST(base.`elevation` as STRING)),' to ',CAST(MAX(base.`elevation`) as STRING))
          WHEN 18 THEN CONCAT(MIN(CAST(base.`id` as STRING)),' to ',CAST(MAX(base.`id`) as STRING))
          WHEN 20 THEN CONCAT(MIN(CAST(base.`latitude` as STRING)),' to ',CAST(MAX(base.`latitude`) as STRING))
          WHEN 21 THEN CONCAT(MIN(CAST(base.`longitude` as STRING)),' to ',CAST(MAX(base.`longitude`) as STRING))
        END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,27,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    SELECT
      `fieldName`,
      `fieldPath`,
      `fieldType`,
      COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
      `weight`
    FROM __stage1
    )

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● index value map  - databricks

    expect(received).toBe(expected) // Object.is equality

    Expected: "WASHINGTON"
    Received: "--PUERTO RICO"

      83 |     expect(result).toBeDefined();
      84 |     if (result !== undefined) {
    > 85 |       expect(result[4].values[0].fieldValue).toBe('WASHINGTON');
         |                                              ^
      86 |       expect(result[4].values[0].weight).toBe(214);
      87 |     }
      88 |   });

      at Object.<anonymous> (test/src/databases/all/db_index.spec.ts:85:46)

  ● index rows count - databricks

    query.run failed:
    [PARSE_SYNTAX_ERROR] Syntax error at or near 'SYSTEM_ROWS'. SQLSTATE: 42601 (line 2, pos 66)

    == SQL ==
    WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.state_facts TABLESAMPLE SYSTEM_ROWS(10)) as x limit 100000 )
    ------------------------------------------------------------------^^^
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`state`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

    SQL: WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.state_facts TABLESAMPLE SYSTEM_ROWS(10)) as x limit 100000 )
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`state`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

    [PARSE_SYNTAX_ERROR] Syntax error at or near 'SYSTEM_ROWS'. SQLSTATE: 42601 (line 2, pos 66)

    == SQL ==
    WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.state_facts TABLESAMPLE SYSTEM_ROWS(10)) as x limit 100000 )
    ------------------------------------------------------------------^^^
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`state`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

      108 |         } -> {index:one, state; sample: 10 }
      109 |             -> {select: fieldName, weight, fieldValue; order_by: 2 desc; where: fieldName = 'one'}
    > 110 |       `).malloyResultMatches(runtime, {fieldName: 'one', weight: 10});
          |          ^
      111 |   });
      112 |
      113 |   it.when(databaseName !== 'trino' && databaseName !== 'presto')(

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/db_index.spec.ts:110:10)

  ● index rows count - databricks

    query.run failed:
    [PARSE_SYNTAX_ERROR] Syntax error at or near 'SYSTEM'. SQLSTATE: 42601 (line 2, pos 62)

    == SQL ==
    WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.flights TABLESAMPLE SYSTEM (50)) as x limit 100000 )
    --------------------------------------------------------------^^^
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`tail_num`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

    SQL: WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.flights TABLESAMPLE SYSTEM (50)) as x limit 100000 )
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`tail_num`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

    [PARSE_SYNTAX_ERROR] Syntax error at or near 'SYSTEM'. SQLSTATE: 42601 (line 2, pos 62)

    == SQL ==
    WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.flights TABLESAMPLE SYSTEM (50)) as x limit 100000 )
    --------------------------------------------------------------^^^
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`tail_num`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

      119 |       } -> {index:one, tail_num; sample: 50% }
      120 |         -> {select: fieldName, weight, fieldValue; order_by: 2 desc; where: fieldName = 'one'}
    > 121 |     `).malloyResultMatches(runtime, {fieldName: 'one'});
          |        ^
      122 |       // Hard to get consistent results here so just check that we get a value back.
      123 |     }
      124 |   );

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/db_index.spec.ts:121:8)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
PASS test/src/databases/all/sql_expressions.spec.ts (19.75 s)
  ✓ sql expression with turducken - databricks (3980 ms)
  ✓ sql expression in second of two queries in same block, dependent on first query - databricks (2003 ms)
  ✓ sql expression in other sql expression - databricks (2717 ms)
  ✓ run sql expression as query - databricks (724 ms)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       (CAST(get_json_object(d4_0, '$.value') AS DOUBLE)) as `die_roll`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(JSONB_BUILD_ARRAY(1,2,3,4)) as value) as d4_0 ON true

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       (CAST(get_json_object(d4_0, '$.value') AS DOUBLE)) as `die_roll`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(JSONB_BUILD_ARRAY(1,2,3,4)) as value) as d4_0 ON true

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
         JSONB_BUILD_ARRAY(1) as `_'_`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       (CAST(get_json_object(__o___0, '$.value') AS DOUBLE)) as `num`
    FROM __stage0 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(base.`_'_`) as value) as __o___0 ON true

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       JSONB_BUILD_ARRAY((JSONB_BUILD_ARRAY(1,2))) as `aoa`
    FROM (SELECT 0 as z) as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       CAST(get_json_object(each_0, '$.value') AS DOUBLE) as `each`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(JSONB_BUILD_ARRAY((JSONB_BUILD_ARRAY(1,2)))) as value) as aoa_0 ON true
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(aoa_0.value)) as value) as each_0 ON true

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
    FROM (select 0 as o) as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       'ok' as `_`_`
    FROM (SELECT 0 as z) as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error:
    [PARSE_SYNTAX_ERROR] Syntax error at or near '_'. SQLSTATE: 42601 (line 2, pos 14)

    == SQL ==
    SELECT
       'ok' as `_`_`
    --------------^^^
    FROM (SELECT 0 as z) as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('rnum',1) as `_'_`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       CAST(get_json_object(base.`_'_`, '$.rnum') AS DOUBLE) as `num`
    FROM __stage0 as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
      FROM (SELECT 0 AS O) as base
    )
    SELECT
       CAST(get_json_object(base.`sizes`, '$.s') AS DOUBLE) as `small`
    FROM __stage0 as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
      FROM (SELECT 0 AS O) as base
    )
    SELECT
       base.`sizes` as `sizes`
    FROM __stage0 as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
      FROM (SELECT 0 AS O) as base
    )
    SELECT
       base.`sizes` as `record`
    FROM __stage0 as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
    FROM (SELECT 0 as z) as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       CAST(get_json_object(JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3), '$.s') AS DOUBLE) as `small`
    FROM (SELECT 0 as z) as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 24

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       CAST(get_json_object(JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3), '$.s') AS DOUBLE) as `small`
    FROM (SELECT 0 as z) as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 24

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('odds',(JSONB_BUILD_ARRAY(1,3)), 'evens',(JSONB_BUILD_ARRAY(2,4))) as `nums`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       CAST(get_json_object(odds_0, '$.value') AS DOUBLE) as `odd`
    FROM __stage0 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`nums`.odds)) as value) as odds_0 ON true

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       (CAST(get_json_object(odds_0, '$.value') AS DOUBLE)) as `odd`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(JSONB_BUILD_OBJECT('odds',(JSONB_BUILD_ARRAY(1,3)), 'evens',(JSONB_BUILD_ARRAY(2,4))).odds)) as value) as odds_0 ON true

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 53

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))) as `rec`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       get_json_object(base.`rec`, '$.a') as `a`,
       get_json_object(to_json(base.`rec`.bc), '$.b') as `b`,
       get_json_object(to_json(base.`rec`.bc), '$.c') as `c`
    FROM __stage0 as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       get_json_object(JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))), '$.a') as `a`,
       get_json_object(to_json(JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))).bc), '$.b') as `b`,
       get_json_object(to_json(JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))).bc), '$.c') as `c`
    FROM (SELECT 0 as z) as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 19

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       CASE WHEN true THEN get_json_object(to_json(JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))).bc), '$.b') ELSE 'b' END as `b`
    FROM (SELECT 0 as z) as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 47

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21))) as `ab`
    FROM (SELECT 0 as z) as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
         JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21))) as `pipeAb`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       base.`pipeAb` as `ab`
    FROM __stage0 as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
         JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21))) as `pipeAb`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       CAST(get_json_object(pipeAb_0, '$.a') AS DOUBLE) as `a`,
       CAST(get_json_object(pipeAb_0, '$.b') AS DOUBLE) as `b`
    FROM __stage0 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`pipeAb`)) as value) as pipeAb_0 ON true

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       (JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21)))) as `ab`
    FROM (SELECT 0 as z) as base

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 4

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       CAST(get_json_object(ab_0, '$.a') AS DOUBLE) as `a`,
       CAST(get_json_object(ab_0, '$.b') AS DOUBLE) as `b`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21))))) as value) as ab_0 ON true

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 5 pos 53

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       get_json_object(to_json(rec_0.bc), '$.b') as `b`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('bc',(JSONB_BUILD_OBJECT('b','b'))))))) as value) as rec_0 ON true

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 53

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     WITH __stage0 AS (
      SELECT
         JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('val',1, 'names',(JSONB_BUILD_ARRAY('uno','one')))),(JSONB_BUILD_OBJECT('val',2, 'names',(JSONB_BUILD_ARRAY('due','two'))))) as `rrec`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       CAST(get_json_object(rrec_0, '$.val') AS DOUBLE) as `val`,
       (get_json_object(names_0, '$.value')) as `name`
    FROM __stage0 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`rrec`)) as value) as rrec_0 ON true
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(rrec_0.names)) as value) as names_0 ON true
    ORDER BY 1 desc NULLS LAST,2 asc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
  console.log
    Exeption when running SQL:
     SELECT
       CAST(get_json_object(rrec_0, '$.val') AS DOUBLE) as `val`,
       (get_json_object(names_0, '$.value')) as `name`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('val',1, 'names',(JSONB_BUILD_ARRAY('uno','one')))),(JSONB_BUILD_OBJECT('val',2, 'names',(JSONB_BUILD_ARRAY('due','two'))))))) as value) as rrec_0 ON true
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(rrec_0.names)) as value) as names_0 ON true
    ORDER BY 1 desc NULLS LAST,2 asc NULLS LAST

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:128:15)

  console.log
    Exception: Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 5 pos 53

      at DatabricksTestConnection.runSQL (test/src/runtimes.ts:130:15)

FAIL test/src/databases/all/compound-atomic.spec.ts (38.722 s)
  compound atomic datatypes databricks
    simple arrays
      ✕ array literal dialect function (939 ms)
      ✕ select array (468 ms)
      ✕ array can be passed to !function (1 ms)
      ✕ array.each in source (2137 ms)
      ✕ array.each in extend block (998 ms)
      ✕ array stored field with special chars in name (699 ms)
      ✕ bare array of array (759 ms)
      ✕ each.each array of array (899 ms)
      ○ skipped schema read allows array-un-nest on each
      ○ skipped cross join arrays
      ○ skipped Can read schema for array of arrays
    record
      ✕ record literal object (1782 ms)
      ✕ special character in record property name (2473 ms)
      ✕ record stored in field with special chars in name (689 ms)
      ✕ simple record.property access (1619 ms)
      ✓ nested data looks like a record (1 ms)
      ✕ record can be selected (575 ms)
      ✕ record literal can be selected (689 ms)
      ✕ select record literal from a source (690 ms)
      ✕ computed record.property from a source (597 ms)
      ✕ record.property from an extend block (587 ms)
      ✕ simple each on array property inside record (689 ms)
      ✕ each on array property inside record from source (919 ms)
      ✕ record with a record property (611 ms)
      ✕ record in source with a record property (688 ms)
      ✕ record dref in source with a record property (583 ms)
      ○ skipped can read schema of record object
      ✎ todo array or record where first entries are null
    repeated record
      ✓ repeated record from nest (1 ms)
      ✕ select repeated record from literal dialect functions (554 ms)
      ✕ repeat record from malloy literal (530 ms)
      ✕ repeated record can be selected and renamed (712 ms)
      ✕ select repeated record passed down pipeline (530 ms)
      ✕ deref repeat record passed down pipeline (887 ms)
      ✕ select array of records from source (688 ms)
      ✕ deref array of records from source (977 ms)
      ✕ repeated record in source wth record property (1005 ms)
      ✕ piped repeated record containing an array (995 ms)
      ✕ source repeated record containing an array (1346 ms)

  ● compound atomic datatypes databricks › simple arrays › array literal dialect function

    Could not prepare query to run: Error(s) compiling model:
    FILE: internal://internal.malloy
    line 2: Invalid SQL, BRIAN SELECT Error fetching schema for
              SELECT JSONB_BUILD_ARRAY(2,4,6,8) AS `evens`
            : Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 13
      |           run: databricks.sql("""
      |                               ^

      94 |       test('array literal dialect function', async () => {
      95 |         await expect(`
    > 96 |           run: ${evens}`).malloyResultMatches(runtime, {
         |                           ^
      97 |           evens: evensObj,
      98 |         });
      99 |       });

      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:96:27)

  ● compound atomic datatypes databricks › simple arrays › select array

    Could not prepare query to run: Error(s) compiling model:
    FILE: internal://internal.malloy
    line 3: Invalid SQL, BRIAN SELECT Error fetching schema for
              SELECT JSONB_BUILD_ARRAY(2,4,6,8) AS `evens`
            : Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 13
      |           run: databricks.sql("""
      |                               ^
    line 5: 'evens' is not defined
      |     """)->{select: nn is evens}
      |                          ^

      102 |           # test.verbose
      103 |           run: ${evens}->{select: nn is evens}
    > 104 |           `).malloyResultMatches(runtime, {nn: evensObj});
          |              ^
      105 |       });
      106 |       test.when(canReadCompoundSchema)(
      107 |         'schema read allows array-un-nest on each',

      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:104:14)

  ● compound atomic datatypes databricks › simple arrays › array can be passed to !function

    expect(received).not.toEqual(expected) // deep equality

    Expected: not "Dialect 'databricks' missing array length function in nameOfArrayLenFunction"

      129 |         const missing = `Dialect '${dialect}' missing array length function in nameOfArrayLenFunction`;
      130 |         const fn = nameOfArrayLenFunction[dialect] ?? missing;
    > 131 |         expect(fn).not.toEqual(missing);
          |                        ^
      132 |         await expect(
      133 |           `run: ${evens}->{ select: nby2 is ${fn}!number(evens); } `
      134 |         ).malloyResultMatches(runtime, {nby2: evensObj.length});

      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:131:24)

  ● compound atomic datatypes databricks › simple arrays › array.each in source

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45
    SQL: SELECT
       (CAST(get_json_object(d4_0, '$.value') AS DOUBLE)) as `die_roll`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(JSONB_BUILD_ARRAY(1,2,3,4)) as value) as d4_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45

      139 |           extend { dimension: d4 is [1,2,3,4] }
      140 |           -> { select: die_roll is d4.each }
    > 141 |         `).malloyResultMatches(runtime, [
          |            ^
      142 |           {die_roll: 1},
      143 |           {die_roll: 2},
      144 |           {die_roll: 3},

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:141:12)

  ● compound atomic datatypes databricks › simple arrays › array.each in extend block

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45
    SQL: SELECT
       (CAST(get_json_object(d4_0, '$.value') AS DOUBLE)) as `die_roll`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(JSONB_BUILD_ARRAY(1,2,3,4)) as value) as d4_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45

      152 |             select: die_roll is d4.each
      153 |           }
    > 154 |         `).malloyResultMatches(runtime, [
          |            ^
      155 |           {die_roll: 1},
      156 |           {die_roll: 2},
      157 |           {die_roll: 3},

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:154:12)

  ● compound atomic datatypes databricks › simple arrays › array stored field with special chars in name

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_ARRAY(1) as `_'_`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       (CAST(get_json_object(__o___0, '$.value') AS DOUBLE)) as `num`
    FROM __stage0 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(base.`_'_`) as value) as __o___0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      190 |             ->{ select: ${qname} is [1]}
      191 |             -> { select: num is ${qname}.each }`;
    > 192 |             await expect(malloySrc).malloyResultMatches(runtime, {});
          |                                     ^
      193 |             const result = await runtime.loadQuery(malloySrc).run();
      194 |             const ok =
      195 |               result.data.path(0, 'num').value === 1

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:192:37)

  ● compound atomic datatypes databricks › simple arrays › bare array of array

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3
    SQL: SELECT
       JSONB_BUILD_ARRAY((JSONB_BUILD_ARRAY(1,2))) as `aoa`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      241 |         await expect(`
      242 |           run: ${empty} -> { select: aoa is [[1,2]] }
    > 243 |         `).malloyResultMatches(runtime, {aoa: [[1, 2]]});
          |            ^
      244 |       });
      245 |       test.when(supportsNestedArrays)('each.each array of array', async () => {
      246 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:243:12)

  ● compound atomic datatypes databricks › simple arrays › each.each array of array

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45
    SQL: SELECT
       CAST(get_json_object(each_0, '$.value') AS DOUBLE) as `each`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(JSONB_BUILD_ARRAY((JSONB_BUILD_ARRAY(1,2)))) as value) as aoa_0 ON true
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(aoa_0.value)) as value) as each_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45

      246 |         await expect(`
      247 |           run: ${empty} extend { dimension: aoa is [[1,2]] } -> { select: aoa.each.each }
    > 248 |         `).malloyResultMatches(runtime, [{each: 1}, {each: 2}]);
          |            ^
      249 |       });
      250 |     });
      251 |     describe('record', () => {

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:248:12)

  ● compound atomic datatypes databricks › record › record literal object

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3
    SQL: SELECT
       JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
    FROM (select 0 as o) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      263 |           run: ${conName}.sql("select 0 as o")
      264 |           -> { select: ${malloySizes}}
    > 265 |         `).malloyResultMatches(runtime, rec_eq());
          |            ^
      266 |       });
      267 |       // can't use special chars in column names in bq
      268 |       test.when(conName !== 'bigquery')(

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:265:12)

  ● compound atomic datatypes databricks › record › special character in record property name


    [PARSE_SYNTAX_ERROR] Syntax error at or near '_'. SQLSTATE: 42601 (line 2, pos 14)

    == SQL ==
    SELECT
       'ok' as `_`_`
    --------------^^^
    FROM (SELECT 0 as z) as base

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● compound atomic datatypes databricks › record › record stored in field with special chars in name

    [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● compound atomic datatypes databricks › record › simple record.property access

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
      FROM (SELECT 0 AS O) as base
    )
    SELECT
       CAST(get_json_object(base.`sizes`, '$.s') AS DOUBLE) as `small`
    FROM __stage0 as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      315 |       test('simple record.property access', async () => {
      316 |         await expect(`
    > 317 |           run: ${sizes} -> { select: small is sizes.s }`).malloyResultMatches(
          |                                                           ^
      318 |           runtime,
      319 |           {small: 0}
      320 |         );

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:317:59)

  ● compound atomic datatypes databricks › record › record can be selected

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
      FROM (SELECT 0 AS O) as base
    )
    SELECT
       base.`sizes` as `sizes`
    FROM __stage0 as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      339 |           `
      340 |           run: ${sizes} -> { select: sizes }`
    > 341 |         ).malloyResultMatches(runtime, rec_eq());
          |           ^
      342 |       });
      343 |       test('record literal can be selected', async () => {
      344 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:341:11)

  ● compound atomic datatypes databricks › record › record literal can be selected

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
      FROM (SELECT 0 AS O) as base
    )
    SELECT
       base.`sizes` as `record`
    FROM __stage0 as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      344 |         await expect(`
      345 |           run: ${sizes} -> { select: record is sizes }
    > 346 |         `).malloyResultMatches(runtime, rec_eq('record'));
          |            ^
      347 |       });
      348 |       test('select record literal from a source', async () => {
      349 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:346:12)

  ● compound atomic datatypes databricks › record › select record literal from a source

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3
    SQL: SELECT
       JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      352 |             select: sizes
      353 |           }
    > 354 |         `).malloyResultMatches(runtime, rec_eq());
          |            ^
      355 |       });
      356 |       test('computed record.property from a source', async () => {
      357 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:354:12)

  ● compound atomic datatypes databricks › record › computed record.property from a source

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 24
    SQL: SELECT
       CAST(get_json_object(JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3), '$.s') AS DOUBLE) as `small`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 24

      359 |             extend { dimension: record is {s is 0, m is 1, l is 2, xl is 3} }
      360 |             -> { select: small is record.s }
    > 361 |         `).malloyResultMatches(runtime, {small: 0});
          |            ^
      362 |       });
      363 |       test('record.property from an extend block', async () => {
      364 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:361:12)

  ● compound atomic datatypes databricks › record › record.property from an extend block

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 24
    SQL: SELECT
       CAST(get_json_object(JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3), '$.s') AS DOUBLE) as `small`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 24

      367 |             select: small is record.s
      368 |           }
    > 369 |         `).malloyResultMatches(runtime, {small: 0});
          |            ^
      370 |       });
      371 |       test('simple each on array property inside record', async () => {
      372 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:369:12)

  ● compound atomic datatypes databricks › record › simple each on array property inside record

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('odds',(JSONB_BUILD_ARRAY(1,3)), 'evens',(JSONB_BUILD_ARRAY(2,4))) as `nums`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       CAST(get_json_object(odds_0, '$.value') AS DOUBLE) as `odd`
    FROM __stage0 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`nums`.odds)) as value) as odds_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      373 |           run: ${empty} -> { select: nums is { odds is [1,3], evens is [2,4]} }
      374 |           -> { select: odd is nums.odds.value }
    > 375 |         `).malloyResultMatches(runtime, [{odd: 1}, {odd: 3}]);
          |            ^
      376 |       });
      377 |       test('each on array property inside record from source', async () => {
      378 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:375:12)

  ● compound atomic datatypes databricks › record › each on array property inside record from source

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 53
    SQL: SELECT
       (CAST(get_json_object(odds_0, '$.value') AS DOUBLE)) as `odd`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(JSONB_BUILD_OBJECT('odds',(JSONB_BUILD_ARRAY(1,3)), 'evens',(JSONB_BUILD_ARRAY(2,4))).odds)) as value) as odds_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 53

      379 |           run: ${empty} extend { dimension: nums is { odds is [1,3], evens is [2,4]} }
      380 |           -> { select: odd is nums.odds.each }
    > 381 |         `).malloyResultMatches(runtime, [{odd: 1}, {odd: 3}]);
          |            ^
      382 |       });
      383 |       const abc = "rec is {a is 'a', bc is {b is 'b', c is 'c'}}";
      384 |       test('record with a record property', async () => {

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:381:12)

  ● compound atomic datatypes databricks › record › record with a record property

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))) as `rec`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       get_json_object(base.`rec`, '$.a') as `a`,
       get_json_object(to_json(base.`rec`.bc), '$.b') as `b`,
       get_json_object(to_json(base.`rec`.bc), '$.c') as `c`
    FROM __stage0 as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      386 |           run: ${empty} -> { select: ${abc} }
      387 |           -> { select: rec.a, rec.bc.b, rec.bc.c }
    > 388 |         `).malloyResultMatches(runtime, {a: 'a', b: 'b', c: 'c'});
          |            ^
      389 |       });
      390 |       test('record in source with a record property', async () => {
      391 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:388:12)

  ● compound atomic datatypes databricks › record › record in source with a record property

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 19
    SQL: SELECT
       get_json_object(JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))), '$.a') as `a`,
       get_json_object(to_json(JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))).bc), '$.b') as `b`,
       get_json_object(to_json(JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))).bc), '$.c') as `c`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 19

      392 |           run: ${empty} extend { dimension: ${abc} }
      393 |           -> { select: rec.a, rec.bc.b, rec.bc.c }
    > 394 |         `).malloyResultMatches(runtime, {a: 'a', b: 'b', c: 'c'});
          |            ^
      395 |       });
      396 |       test('record dref in source with a record property', async () => {
      397 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:394:12)

  ● compound atomic datatypes databricks › record › record dref in source with a record property

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 47
    SQL: SELECT
       CASE WHEN true THEN get_json_object(to_json(JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))).bc), '$.b') ELSE 'b' END as `b`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 47

      398 |           run: ${empty} extend { dimension: ${abc} }
      399 |           -> { select: b is pick rec.bc.b when true else 'b' }
    > 400 |         `).malloyResultMatches(runtime, {b: 'b'});
          |            ^
      401 |       });
      402 |       test.todo('array or record where first entries are null');
      403 |     });

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:400:12)

  ● compound atomic datatypes databricks › repeated record › select repeated record from literal dialect functions

    Could not prepare query to run: Error(s) compiling model:
    FILE: internal://internal.malloy
    line 2: Invalid SQL, BRIAN SELECT Error fetching schema for  SELECT JSONB_BUILD_ARRAY(JSONB_BUILD_OBJECT('a',10, 'b',11),JSONB_BUILD_OBJECT('a',20, 'b',21)) AS `ab` : Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 14
      |           run: databricks.sql(""" SELECT JSONB_BUILD_ARRAY(JSONB_BUILD_OBJECT('a',10, 'b',11),JSONB_BUILD_OBJECT('a',20, 'b',21)) AS `ab` """)
      |                               ^

      444 |         await expect(`
      445 |           run: ${conName}.sql(""" ${selectAB('ab')} """)
    > 446 |         `).malloyResultMatches(runtime, {ab: ab_eq});
          |            ^
      447 |       });
      448 |       test('repeat record from malloy literal', async () => {
      449 |         await expect(`

      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:446:12)

  ● compound atomic datatypes databricks › repeated record › repeat record from malloy literal

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3
    SQL: SELECT
       JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21))) as `ab`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      450 |           run: ${empty}
      451 |           -> { select: ab is ${abMalloy} }
    > 452 |         `).malloyResultMatches(runtime, {ab: ab_eq});
          |            ^
      453 |       });
      454 |       test('repeated record can be selected and renamed', async () => {
      455 |         const src = `

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:452:12)

  ● compound atomic datatypes databricks › repeated record › repeated record can be selected and renamed

    Could not prepare query to run: Error(s) compiling model:
    FILE: internal://internal.malloy
    line 2: Invalid SQL, BRIAN SELECT Error fetching schema for
                    SELECT JSONB_BUILD_ARRAY(JSONB_BUILD_OBJECT('a',10, 'b',11),JSONB_BUILD_OBJECT('a',20, 'b',21)) AS `sqlAB`
                  : Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 19
      |           run: databricks.sql("""
      |                               ^
    line 4: 'sqlAB' is not defined
      |           """) -> { select: ab is sqlAB }
      |                                   ^

      458 |           """) -> { select: ab is sqlAB }
      459 |       `;
    > 460 |         await expect(src).malloyResultMatches(runtime, {ab: ab_eq});
          |                           ^
      461 |       });
      462 |       test('select repeated record passed down pipeline', async () => {
      463 |         await expect(`

      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:460:27)

  ● compound atomic datatypes databricks › repeated record › select repeated record passed down pipeline

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21))) as `pipeAb`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       base.`pipeAb` as `ab`
    FROM __stage0 as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      465 |           -> { select: pipeAb is ${abMalloy} }
      466 |           -> { select: ab is pipeAb }
    > 467 |         `).malloyResultMatches(runtime, {ab: ab_eq});
          |            ^
      468 |       });
      469 |       test('deref repeat record passed down pipeline', async () => {
      470 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:467:12)

  ● compound atomic datatypes databricks › repeated record › deref repeat record passed down pipeline

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21))) as `pipeAb`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       CAST(get_json_object(pipeAb_0, '$.a') AS DOUBLE) as `a`,
       CAST(get_json_object(pipeAb_0, '$.b') AS DOUBLE) as `b`
    FROM __stage0 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`pipeAb`)) as value) as pipeAb_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      472 |           -> { select: pipeAb is ${abMalloy} }
      473 |           -> { select: pipeAb.a, pipeAb.b }
    > 474 |         `).malloyResultMatches(runtime, ab_eq);
          |            ^
      475 |       });
      476 |       test('select array of records from source', async () => {
      477 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:474:12)

  ● compound atomic datatypes databricks › repeated record › select array of records from source

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 4
    SQL: SELECT
       (JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21)))) as `ab`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 4

      479 |           extend { dimension: abSrc is ${abMalloy} }
      480 |           -> { select: ab is abSrc }
    > 481 |         `).malloyResultMatches(runtime, {ab: ab_eq});
          |            ^
      482 |       });
      483 |       test('deref array of records from source', async () => {
      484 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:481:12)

  ● compound atomic datatypes databricks › repeated record › deref array of records from source

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 5 pos 53
    SQL: SELECT
       CAST(get_json_object(ab_0, '$.a') AS DOUBLE) as `a`,
       CAST(get_json_object(ab_0, '$.b') AS DOUBLE) as `b`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21))))) as value) as ab_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 5 pos 53

      486 |           extend { dimension: ab is ${abMalloy} }
      487 |           -> { select: ab.a, ab.b }
    > 488 |         `).malloyResultMatches(runtime, ab_eq);
          |            ^
      489 |       });
      490 |       test('repeated record in source wth record property', async () => {
      491 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:488:12)

  ● compound atomic datatypes databricks › repeated record › repeated record in source wth record property

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 53
    SQL: SELECT
       get_json_object(to_json(rec_0.bc), '$.b') as `b`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('bc',(JSONB_BUILD_OBJECT('b','b'))))))) as value) as rec_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 53

      492 |           run: ${empty} extend { dimension: rec is [ {bc is  {b is 'b'}} ] }
      493 |           -> { select: rec.bc.b }
    > 494 |         `).malloyResultMatches(runtime, {b: 'b'});
          |            ^
      495 |       });
      496 |       test('piped repeated record containing an array', async () => {
      497 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:494:12)

  ● compound atomic datatypes databricks › repeated record › piped repeated record containing an array

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('val',1, 'names',(JSONB_BUILD_ARRAY('uno','one')))),(JSONB_BUILD_OBJECT('val',2, 'names',(JSONB_BUILD_ARRAY('due','two'))))) as `rrec`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       CAST(get_json_object(rrec_0, '$.val') AS DOUBLE) as `val`,
       (get_json_object(names_0, '$.value')) as `name`
    FROM __stage0 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`rrec`)) as value) as rrec_0 ON true
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(rrec_0.names)) as value) as names_0 ON true
    ORDER BY 1 desc NULLS LAST,2 asc NULLS LAST

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      505 |             order_by: val desc, name asc
      506 |           }
    > 507 |         `).malloyResultMatches(runtime, [
          |            ^
      508 |           {val: 2, name: 'due'},
      509 |           {val: 2, name: 'two'},
      510 |           {val: 1, name: 'one'},

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:507:12)

  ● compound atomic datatypes databricks › repeated record › source repeated record containing an array

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 5 pos 53
    SQL: SELECT
       CAST(get_json_object(rrec_0, '$.val') AS DOUBLE) as `val`,
       (get_json_object(names_0, '$.value')) as `name`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('val',1, 'names',(JSONB_BUILD_ARRAY('uno','one')))),(JSONB_BUILD_OBJECT('val',2, 'names',(JSONB_BUILD_ARRAY('due','two'))))))) as value) as rrec_0 ON true
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(rrec_0.names)) as value) as names_0 ON true
    ORDER BY 1 desc NULLS LAST,2 asc NULLS LAST

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 5 pos 53

      523 |             order_by: val desc, name asc
      524 |           }
    > 525 |         `).malloyResultMatches(runtime, [
          |            ^
      526 |           {val: 2, name: 'due'},
      527 |           {val: 2, name: 'two'},
      528 |           {val: 1, name: 'one'},

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:525:12)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
FAIL test/src/databases/all/time.spec.ts (68.17 s)
  databricks date and time
    ✓ date in sql_block no explore (490 ms)
    ✓ timestamp in sql_block no explore (481 ms)
    ✓ valid timestamp without seconds (493 ms)
    ✓ dependant join dialect fragments (624 ms)
    interval measurement
      ✓ forwards is positive (2532 ms)
      ✓ reverse is negative (651 ms)
      ✕ seconds (3769 ms)
      ✓ minutes (2536 ms)
      ✓ hours (2637 ms)
      ✓ days (2508 ms)
      ✓ timeDiff passed to a function preserves rhs (1255 ms)
    timestamp truncation
      ✓ trunc second (515 ms)
      ✓ trunc minute (531 ms)
      ✓ trunc hour (490 ms)
      ✓ trunc day (510 ms)
      ✓ trunc week (564 ms)
      ✓ trunc month (499 ms)
      ✓ trunc quarter (510 ms)
      ✓ trunc year (515 ms)
    timestamp extraction
      ✓ extract second (558 ms)
      ✓ extract minute (497 ms)
      ✓ extract hour (565 ms)
      ✓ extract day (496 ms)
      ✓ extract day_of_week (514 ms)
      ✓ first week day is one  (491 ms)
      ✓ extract day_of_year (491 ms)
      ✓ extract week (524 ms)
      ✓ extract month (499 ms)
      ✓ extract quarter (538 ms)
      ✓ extract year (514 ms)
    date truncation
      ✓ date trunc day (522 ms)
      ✓ date trunc week (502 ms)
      ✓ date trunc month (533 ms)
      ✓ date trunc quarter (486 ms)
      ✓ date trunc year (607 ms)
    date extraction
      ✓ date extract day (507 ms)
      ✓ date extract day_of_week (512 ms)
      ✓ date extract day_of_year (490 ms)
      ✓ date extract week (521 ms)
      ✓ date extract month (586 ms)
      ✓ date extract quarter (523 ms)
      ✓ date extract year (496 ms)
    delta computations
      ✓ timestamp delta second (535 ms)
      ✓ timestamp delta negative second (480 ms)
      ✓ timestamp delta minute (528 ms)
      ✓ timestamp delta hours (593 ms)
      ✓ timestamp delta week (505 ms)
      ✓ timestamp delta month (521 ms)
      ✓ timestamp delta quarter (511 ms)
      ✓ timestamp delta year (511 ms)
      ✓ date delta week (499 ms)
      ✓ date delta month (496 ms)
      ✓ date delta quarter (500 ms)
      ✓ date delta year (477 ms)
    for range edge tests
      date
        ✓ before for-range is outside (495 ms)
        ✓ first for-range is inside (487 ms)
        ✓ last for-range is outside (471 ms)
      timestamp
        ✓ before for-range is outside (456 ms)
        ✓ first for-range is inside (473 ms)
        ✓ last for-range is outside (477 ms)
    to range edge tests
      date
        ✓ before to is outside (501 ms)
        ✓ first to is inside (479 ms)
        ✓ last to is outside (472 ms)
      timestamp
        ✓ before to is outside (496 ms)
        ✓ first to is inside (495 ms)
        ✓ last to is outside (482 ms)
    granular time range checks
      ✓ minute implied truncated range (979 ms)
      ✓ day implied truncated range (497 ms)
      ✓ year implied truncated range (499 ms)
      ✓ timestamp in literal minute (495 ms)
      ✓ timestamp in literal day (521 ms)
      ✓ date in literal month (519 ms)
      ✓ timestamp in literal month (516 ms)
      ✓ timestamp in literal year (472 ms)
    timezone set correctly
      ✓ timezone set in source used by query (1725 ms)
      ○ skipped timezone set in view inside source
      ○ skipped timezone set in query using source
      ○ skipped multiple timezones
  databricks: tz literals
    ✓ databricks - default timezone is UTC (497 ms)
    ✕ literal with zone name (484 ms)
  databricks: query tz
    ✕ literal timestamps (486 ms)
    ✕ extract (523 ms)
    ✕ truncate day (1220 ms)
    ✕ cast timestamp to date (483 ms)
    ✕ cast date to timestamp (1480 ms)

  ● databricks date and time › interval measurement › seconds

    Got 'sqlEq failed
        Expected: seconds(@2001-01-01 00:00:00.999 to @2001-01-01 00:00:01) == 0
        Received: 1' [object String] instead of '='
    SQL:
        SELECT
           CASE WHEN ((0)=(FLOOR(UNIX_TIMESTAMP(timestamp '2001-01-01 00:00:01')-UNIX_TIMESTAMP(timestamp '2001-01-01 00:00:00.999')))) THEN '=' ELSE (CONCAT('sqlEq failed',CASE WHEN 10 = 0 THEN '' ELSE CHR(10) END,'    Expected: seconds(@2001-01-01 00:00:00.999 to @2001-01-01 00:00:01) == 0',CASE WHEN 10 = 0 THEN '' ELSE CHR(10) END,'    Received: ',CAST((FLOOR(UNIX_TIMESTAMP(timestamp '2001-01-01 00:00:01')-UNIX_TIMESTAMP(timestamp '2001-01-01 00:00:00.999'))) AS string))) END as `calc`
        FROM (SELECT DATE '2021-02-24' as `t_date`, TIMESTAMP '2021-02-24 03:05:06' as `t_timestamp` ) as base

      60 |       const b = '@2001-01-01 00:00:00.999';
      61 |       expect(await sqlEq(`seconds(${a} to ${b})`, 0)).isSqlEq();
    > 62 |       expect(await sqlEq(`seconds(${b} to @2001-01-01 00:00:01)`, 0)).isSqlEq();
         |                                                                       ^
      63 |     });
      64 |
      65 |     test('minutes', async () => {


      at Object.<anonymous> (test/src/databases/all/time.spec.ts:62:71)

  ● databricks: tz literals › literal with zone name

    expect(received).toEqual(expected) // deep equality

    Expected: 1582178400000
    Received: 1582135200000

      663 |     const literal = result.data.path(0, 'literal_time').value as Date;
      664 |     const have = LuxonDateTime.fromJSDate(literal);
    > 665 |     expect(have.valueOf()).toEqual(zone_2020.valueOf());
          |                            ^
      666 |   });
      667 | });
      668 |

      at Object.<anonymous> (test/src/databases/all/time.spec.ts:665:28)

  ● databricks: query tz › literal timestamps

    expect(received).toEqual(expected) // deep equality

    Expected: 1582178400000
    Received: 1582135200000

      683 |     const literal = result.data.path(0, 'literal_time').value as Date;
      684 |     const have = LuxonDateTime.fromJSDate(literal);
    > 685 |     expect(have.valueOf()).toEqual(zone_2020.valueOf());
          |                            ^
      686 |   });
      687 |
      688 |   test('extract', async () => {

      at Object.<anonymous> (test/src/databases/all/time.spec.ts:685:28)

  ● databricks: query tz › extract

    SQL Generated:
      SELECT
         EXTRACT(hour FROM (from_utc_timestamp(timestamp'2020-02-20 00:00:00', 'UTC'))) as `mex_midnight`,
         EXTRACT(day FROM (from_utc_timestamp(timestamp'2020-02-20 00:00:00', 'UTC'))) as `mex_day`
      FROM (SELECT 1 as one) as base

    Expected {mex_midnight: 18} Got: 0
    Expected {mex_day: 19} Got: 20

      695 |           mex_day is day(utc_midnight)
      696 |       }`
    > 697 |     ).malloyResultMatches(runtime, {mex_midnight: 18, mex_day: 19});
          |       ^
      698 |   });
      699 |
      700 |   test.when(

      at Object.<anonymous> (test/src/databases/all/time.spec.ts:697:7)

  ● databricks: query tz › truncate day

    SQL Generated:
      SELECT
         DATE_TRUNC('day', from_utc_timestamp((from_utc_timestamp(timestamp'2020-02-20 00:00:00', 'UTC')), 'America/Mexico_City')) as `mex_day`
      FROM (SELECT 1 as x) as base

    Expected {mex_day: "2020-02-19T06:00:00.000Z"} Got: "2020-02-19T00:00:00.000Z"

      710 |         select: mex_day is utc_midnight.day
      711 |       }`
    > 712 |     ).malloyResultMatches(runtime, {mex_day: mex_19.toJSDate()});
          |       ^
      713 |   });
      714 |
      715 |   test.when(

      at Object.<anonymous> (test/src/databases/all/time.spec.ts:712:7)

  ● databricks: query tz › cast timestamp to date

    SQL Generated:
      SELECT
         EXTRACT(day FROM DATE((from_utc_timestamp(timestamp'2020-02-20 00:00:00', 'UTC')))) as `mex_day`
      FROM (SELECT 1 as x) as base

    Expected {mex_day: 19} Got: 20

      724 |         select: mex_day is day(utc_midnight::date)
      725 |       }`
    > 726 |     ).malloyResultMatches(runtime, {mex_day: 19});
          |       ^
      727 |   });
      728 |
      729 |   test.when(

      at Object.<anonymous> (test/src/databases/all/time.spec.ts:726:7)

  ● databricks: query tz › cast date to timestamp

    SQL Generated:
      SELECT
         TIMESTAMP(base.`mex_20`) as `mex_ts`
      FROM ( SELECT DATE '2020-02-20'  AS `mex_20` ) as base

    Expected {mex_ts: "2020-02-20T06:00:00.000Z"} Got: "2020-02-20T00:00:00.000Z"

      735 |         select: mex_ts is mex_20::timestamp
      736 |       }`
    > 737 |     ).malloyResultMatches(runtime, {mex_ts: zone_2020.toJSDate()});
          |       ^
      738 |   });
      739 | });
      740 |

      at Object.<anonymous> (test/src/databases/all/time.spec.ts:737:7)

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
PASS test/src/databases/all/lenses.spec.ts (29.175 s)
  ✓ named view plus named view - databricks (2568 ms)
  ✓ named view plus measure - databricks (620 ms)
  ✓ dimension plus named view - databricks (587 ms)
  ✓ where headed - databricks (625 ms)
  ✓ named view plus named view in source - databricks (606 ms)
  ✓ dimension plus named view in source - databricks (556 ms)
  ✓ named view plus dimension in source - databricks (627 ms)
  ✓ literal view plus named view - databricks (567 ms)
  ✓ literal view plus measure - databricks (606 ms)
  ✓ measure plus literal view - databricks (588 ms)
  ✓ literal view plus named view in source - databricks (618 ms)
  ✓ literal view plus measure in source - databricks (572 ms)
  ✓ named view plus literal view - databricks (641 ms)
  ✓ literal view plus literal view - databricks (611 ms)
  ✓ three named views - databricks (637 ms)
  ✓ nested no name - databricks
  ✓ nested with name - databricks (1 ms)
  ✓ nested no name with dimension head - databricks
  ✓ nest dimension only - databricks
  ✓ joined dimension in middle of refinements - databricks (1624 ms)
  ✓ nest joined dimension refined - databricks (1 ms)
  ✓ joined dimension refined - databricks (542 ms)
  ✓ nest joined dimension bare - databricks (1 ms)
  ✓ joined dimension bare - databricks (520 ms)
  ✓ joined dimension nest refinement - databricks (1 ms)
  ✓ nest dimension only in refinement - databricks (2 ms)
  ✓ view dimension only - databricks (476 ms)
  ✓ view join dimension only - databricks (541 ms)
  ✓ run dimension only - databricks (457 ms)
  ✓ copy of view with lens - databricks (561 ms)
  ✓ aggregate copy bug with only old refinement - databricks (941 ms)
  ✓ aggregate copy bug with only old old refinement - databricks (543 ms)
  ✓ but still need to be able to use as output field - databricks (716 ms)
  ✓ aggregate copy bug - databricks (635 ms)
  ○ skipped nest measure only in second stage - databricks
  ○ skipped second stage refinement chain - databricks
  ○ skipped second stage refinement chain in nest - databricks

  console.log
    Error in SQL:
     SELECT
       base.origin as Origin Code,
       COUNT(1) as flight_count
    FROM 'test/data/duckdb/flights/part.*.parquet' as base
    GROUP BY 1
    ORDER BY 2 desc NULLS LAST
    LIMIT 1

      at DuckDBTestConnection.runSQL (test/src/runtimes.ts:147:15)

FAIL test/src/render/drill.spec.ts (17.904 s)
  drill query
    ✓ can handle joined-in table fields (1149 ms)
    ✓ can handle expression fields (44 ms)
    ✕ can handle renamed and multi-word field names (35 ms)
    ✓ can handle queries with no filter (32 ms)

  ● drill query › can handle renamed and multi-word field names

    Parser Error: syntax error at or near "Code"



  console.log
    Error in SQL:
     SELECT
       base.1 as 1
    FROM (select 1) as base

      at DuckDBTestConnection.runSQL (test/src/runtimes.ts:147:15)

FAIL test/src/core/tags.spec.ts
  tagParse to Tag
    ✓ tag just_name (8 ms)
    ✓ tag name=bare_string (1 ms)
    ✓ tag name="quoted_string" (2 ms)
    ✓ tag name {prop1} (2 ms)
    ✓ tag name {prop1 prop2=value}
    ✓ tag name.prop (1 ms)
    ✓ tag name.prop=value (1 ms)
    ✓ tag name.prop.sub=value
    ✓ tag name{first3=[a, b, c]} (1 ms)
    ✓ tag name{first1=[a,]} (1 ms)
    ✓ tag name{first=[a {A}]}
    ✓ tag name{first=[{A}]}
    ✓ tag name=value {prop}
    ✓ tag name.prop={prop2}
    ✓ tag no yes -no (1 ms)
    ✓ tag x -x.y
    ✓ tag x={y} -x.y
    ✓ tag x={y z} -x.y (1 ms)
    ✓ tag x={y z} x {-y}
    ✓ tag x=1 x {xx=11} (1 ms)
    ✓ tag x.y=xx x=1 {...}
    ✓ tag a {b c} a=1 (1 ms)
    ✓ tag a=1 a=...{b}
    ✓ tag a=red { shade=dark } color=$(a) shade=$(a.shade) (1 ms)
    ✓ tag x=.01
    ✓ tag x=-7 (1 ms)
    ✓ tag x=7
    ✓ tag x=7.0
    ✓ tag x=.7
    ✓ tag x=.7e2 (1 ms)
    ✓ tag x=7E2
    ✓ tag `spacey name`=Zaphod (1 ms)
    ✓ tag image { alt=hello { field=department } } (1 ms)
    ✓ tag image image.alt=hello image.alt.field=department
    ✓ tag can remove.properties -... (1 ms)
    ✓ inherits can be over-ridden
    ○ skipped unskip to debug just one of the expressions
  Tag access
    ✓ just text (1 ms)
    ✓ tag path
    ✓ just array
    ✓ array as text
    ✓ text as array
    ✓ just numeric
    ✓ text as numeric (1 ms)
    ✓ array as numeric
    ✓ full text array
    ✓ filtered text array (4 ms)
    ✓ full numeric array
    ✓ filtered numeric array (1 ms)
    ✓ has
  ## top level
    ✓ top level tags are available in the model def (97 ms)
  tags in results
    ✓ nameless query (501 ms)
    ✓ named query (33 ms)
    ✓ turtle query (380 ms)
    ✓ field ref has tag (40 ms)
    ✓ atomic field model scope tag (7 ms)
    ✓ nested query has tag (72 ms)
    ✓ render usage test case (26 ms)
    ✓ User defined scopes nest properly (7 ms)
    ✕ inherited model tags override (17 ms)
    ✓ property access on existing tag (which does not yet have properties)
    ✓ nested fields of same field do not share tags (28 ms)

  ● tags in results › inherited model tags override

    Parser Error: syntax error at or near ".1"



PASS test/src/core/dependencies.spec.ts (14.487 s)
  dependencies
    ✓ typescript references should not be circular (2655 ms)
    ✓ javascript references should not be circular (11323 ms)
    ○ skipped malloy/src/lang typescript should not be circular
    ○ skipped malloy-render/src typescript should not be circular

{"level":"info","message":"Created DBSQLClient"}
{"level":"info","message":"DBSQLClient: initializing thrift client"}
PASS test/src/databases/all/problems.spec.ts (12.359 s)
  warnings
    ✓ can appear after errors - databricks (1306 ms)
    ✓ can appear before errors - databricks (26 ms)
    ✓ can appear alone - databricks (41 ms)

PASS packages/malloy/src/lang/test/expressions.spec.ts (6.411 s)
  expressions
    ✓ field name (3 ms)
    ✓ function call (2 ms)
    ✓ raw function call codegen (3 ms)
    ✓ filtered measure (307 ms)
    ✓ filtered ungrouped aggregate (43 ms)
    ✓ correctly flags filtered scalar (1 ms)
    ✓ correctly flags filtered analytic (32 ms)
    ✓ can use calculate with partition by in select (97 ms)
    ✓ paren and applied div (1 ms)
    ✓ Can compare field ats (type timestamp) to NULL (1 ms)
    ✓ Can compare field ad (type date) to NULL (3 ms)
    ✓ Can compare field ai (type number) to NULL (1 ms)
    ✓ Can compare field astr (type string) to NULL
    ✓ Can compare field abool (type boolean) to NULL (1 ms)
    timeframes
      ✓ timestamp truncate second (404 ms)
      ✓ date truncate week (3 ms)
      ✓ timestamp difference - second (10 ms)
      ✓ timestamp difference - second (2 ms)
    operators
      ✓ addition (10 ms)
      ✓ typecheck addition lhs (2 ms)
      ✓ typecheck addition rhs (9 ms)
      ✓ subtraction (2 ms)
      ✓ multiplication (1 ms)
      ✓ mod (2 ms)
      ✓ division (1 ms)
      ✓ unary negation (1 ms)
      ✓ equal (7 ms)
      ✓ not equal (2 ms)
      ✓ greater than (3 ms)
      ✓ greater than or equal (2 ms)
      ✓ less than or equal (2 ms)
      ✓ less than (1 ms)
      ✓ match (2 ms)
      ✓ not match (1 ms)
      ✓ regexp-match (2 ms)
      ✓ not regexp-match (1 ms)
      ✓ apply as equality (3 ms)
      ✓ not (6 ms)
      ✓ and (1 ms)
      ✓ or (6 ms)
      ✓ null-check (??) (6 ms)
      ✓ normal is-null (1 ms)
      ✓ normal is-not-null (4 ms)
      ✓ apply is-null (1 ms)
      ✓ apply is-not-null (1 ms)
      ✓ coalesce type mismatch (1 ms)
      ✓ disallow date OP number (1 ms)
      ✓ disallow date OP timestamp (1 ms)
      ✓ disallow interval from date to timestamp (2 ms)
      ✓ compare to truncation uses straight comparison (1 ms)
      ✓ compare to granular result expression uses straight comparison (2 ms)
      ✓ apply granular-truncation uses range (1 ms)
      ✓ apply granular-literal alternation uses all literals for range (1 ms)
      ✓ apply followed by another condition (1 ms)
      ✓ apply followed by another condition, with parenthesis (3 ms)
      ✓ apply or-tree granular-literal doesnt turn into IN (1 ms)
      ✓ comparison promotes date literal to timestamp (1 ms)
      ✓ can apply range to date (13 ms)
      ✓ disallow date delta second (10 ms)
      ✓ disallow date delta minute (9 ms)
      ✓ disallow date delta hour (9 ms)
      ✓ apply with parens (1 ms)
      sql friendly warnings
        ✓ = null with warning (2 ms)
        ✓ is not null with warning (2 ms)
        ✓ like with warning (7 ms)
        ✓ NOT LIKE with warning (4 ms)
        ✓ x is expr y is not null (26 ms)
        ✓ not null::number (2 ms)
        ✓ (not null)::number (1 ms)
    expr props
      ✓ aggregate order by not allowed without experiments enabled (26 ms)
      ✓ aggregate limit not allowed without experiments enabled (18 ms)
      ✓ aggregate order_by not allowed with different experiment enabled (9 ms)
      ✓ aggregate limit not allowed with different experiment enabled (4 ms)
      ✓ props not allowed on most expressions (19 ms)
      ✓ analytics can take parititon_by and order_by (13 ms)
      ✓ partition by works with scalar and aggregate (27 ms)
      ✓ partition by fails with analytic and ungrouped aggregate (6 ms)
      ✓ analytics order_by requires expression (11 ms)
      ✓ string_agg_distinct order by cannot specify expression (5 ms)
      ✓ string_agg_distinct order by can be just direction (4 ms)
      ✓ string_agg order by can be just direction (4 ms)
      ✓ can specify multiple partition_bys (35 ms)
      ✓ can specify multiple order_bys (67 ms)
      ✓ aggregate order by cannot be aggregate (5 ms)
      ✓ aggregate order by cannot be analytic (5 ms)
      ✓ analytic order by can be an aggregate (4 ms)
      ✓ analytic order by can be an output field (4 ms)
      ✓ analytic order by must be an output field (5 ms)
      ✓ can specify multiple wheres (9 ms)
      ✓ string_agg can take order_by (69 ms)
    aggregate forms
      ✓ one.column.min() (4 ms)
      ✓ one.min(one.column) (4 ms)
      ✓ min(one.column) (2 ms)
      ✓ min(many.column) (3 ms)
      ✓ min() (1 ms)
      ✓ source.min(column) (3 ms)
      ✓ many.column.max() (2 ms)
      ✓ max(many.column) (2 ms)
      ✓ max() (1 ms)
      ✓ source.max(many.column) (2 ms)
      ✓ many.column.count() (1 ms)
      ✓ count() (2 ms)
      ✓ count(many.column) (4 ms)
      ✓ source.count() (2 ms)
      ✓ many.count() (3 ms)
      ✓ sum() (1 ms)
      ✓ sum(column) (2 ms)
      ✓ sum(column * 2) (3 ms)
      ✓ column.sum() (2 ms)
      ✓ source.sum(column) (2 ms)
      ✓ sum(many.column) (2 ms)
      ✓ source.sum(many.column) (5 ms)
      ✓ many.column.sum() (2 ms)
      ✓ many.sum(many.column) (2 ms)
      ✓ sum(one.column) (3 ms)
      ✓ sum(many.constant) (2 ms)
      ✓ source.sum(many.constant) (3 ms)
      ✓ sum(nested.column) (2 ms)
      ✓ nested.column.sum() (2 ms)
      ✓ source.sum(nested.column) (3 ms)
      ✓ can aggregate field defined with no join usage (11 ms)
      ✓ sum(inline.column) (3 ms)
      ✓ inline.column.sum() (2 ms)
      ✓ source.sum(inline.column) (2 ms)
      ✓ sum(many.field) (2 ms)
      ✓ source.sum(many.field) (3 ms)
      ✓ many.field.sum() (2 ms)
      ✓ many.sum(many.field) (2 ms)
      ✓ sum(many.field + many.field) (15 ms)
      ✓ source.sum(many.field + many.field) (3 ms)
      ✓ many.field + many.field.sum() (3 ms)
      ✓ many.sum(many.field + many.field) (2 ms)
      ✓ sum(many_field) (2 ms)
      ✓ source.sum(many_field) (2 ms)
      ✓ many_field.sum() (2 ms)
      ✓ many.sum(many_field) (2 ms)
      ✓ sum(one.many_field) (2 ms)
      ✓ source.sum(one.many_field) (5 ms)
      ✓ one.many_field.sum() (2 ms)
      ✓ many.sum(one.many_field) (2 ms)
      ✓ sum(many.field + one.field) (3 ms)
      ✓ source.sum(many.field + one.field) (2 ms)
      ✓ many.sum(many.field + one.field) (3 ms)
      ✓ many_one_field.sum() (2 ms)
      ✓ sum(many_one_field) (3 ms)
      ✓ source.sum(many_one_field) (2 ms)
      ✓ many.sum(many_one_field) (6 ms)
      ✓ sum(many.one.field) (2 ms)
      ✓ sum(many.one.one.field) (3 ms)
      ✓ many.avg(field) (2 ms)
      ✓ one.avg(field) (2 ms)
      ✓ cross.avg(field) (2 ms)
      ✓ cross.avg(cross.field) (2 ms)
      ✓ one.column.sum() (3 ms)
      ✓ one.sum(one.column) (2 ms)
      ✓ source.sum(one.column) (5 ms)
      ✓ sum(one.column + one.column) (3 ms)
      ✓ one.sum(one.column + one.column) (2 ms)
      ✓ source.sum(one.column + one.column) (3 ms)
      ✓ lag(sum(output)) (2 ms)
    case statements
      ✓ full (5 ms)
      ✓ with value (1 ms)
      ✓ no else (2 ms)
      ✓ wrong then type (1 ms)
      ✓ wrong when type (4 ms)
      ✓ wrong else type (1 ms)
      ✓ null then type okay second (1 ms)
      ✓ null then type okay first (1 ms)
      ✓ null else type okay (1 ms)
      ✓ null then type before else okay (1 ms)
      ✓ non boolean when (1 ms)
      ✓ type of null then second (1 ms)
      ✓ type of null then first (1 ms)
      ✓ type of null else (1 ms)
      ✓ type of null then type before else (1 ms)
      ✓ replacement for full case
      ✓ replacement for case with no else (1 ms)
      ✓ replacement for case with value
      ✓ interaction with pick (17 ms)
    pick statements
      ✓ full (12 ms)
      ✓ applied (1 ms)
      ✓ filtering (2 ms)
      ✓ null branch with else (8 ms)
      ✓ null branch no else (1 ms)
      ✓ null branch no apply (1 ms)
      ✓ tiering (1 ms)
      ✓ transforming (2 ms)
      ✓ when single values (1 ms)
      ✓ n-ary without else (16 ms)
      ✓ n-ary with mismatch when clauses (12 ms)
      ✓ n-ary with mismatched else clause (7 ms)
      ✓ applied else mismatch (13 ms)
      ✓ applied default mismatch (6 ms)
      ✓ applied when mismatch (2 ms)
  alternations as in
    ✓ a=b|c (2 ms)
    ✓ a!=b|c (1 ms)
    ✓ a=(b|c)
    ✓ a?b|c (1 ms)
    ✓ a=(b)|c (1 ms)
    ✓ a=b|c|d (1 ms)
    ✓ a=(b|c)|d (1 ms)
    ✓ a=b|(c|d) (1 ms)
    ✓ a=b|c&d (1 ms)
    ✓ a=b|>d (2 ms)
    ✓ a ? (= (b | c)) (3 ms)
    ✓ legacy in (2 ms)
    ○ skipped a ? (( =1) | 2)
  sql native fields in schema
    ✓ sql native reference in result allowed (2 ms)
    ✓ sql native reference can be compared to NULL (21 ms)
    ✓ flag unsupported equality (12 ms)
    ✓ flag unsupported compare (2 ms)
    ✓ allow unsupported equality when raw types match (4 ms)
    ✓ flag not applied to unsupported (10 ms)
    ✓ allow unsupported to be cast (6 ms)
    ✓ negative numbers are not tokens (1 ms)
    sql functions
      ✓ can aggregate a sql_ function (2 ms)
      ✓ error when interpolating field that does not exist (2 ms)
      ✓ error when using sql_ function without experiment (1 ms)
    cast
      ✓ sql cast (4 ms)
      ✓ sql safe cast (3 ms)
      ✓ malloy cast (3 ms)
      ✓ malloy safe cast (1 ms)
      ✓ sql cast illegal type name (1 ms)

PASS packages/malloy/src/lang/test/parse.spec.ts
  ✓ non breaking space in source (3 ms)
  model statements
    ✓ errors on redefinition of query (58 ms)
    ✓ ##! experimental enables all experiments (2 ms)
    ✓ experimental explicit enable (3 ms)
    ✓ experiments do not bleed into one another (2 ms)
    ✓ experiment failures in parse are flagged (1 ms)
    ✓ experiment failures in second pass are flagged (2 ms)
    table method
      ✓ table method works (129 ms)
      ✓ table method works with quoted connection name (4 ms)
      ✓ table method fails when connection name is wrong (1 ms)
      ✓ table method fails when connection is not a connection (5 ms)
      ✓ cannot refine table (402 ms)
      ✓ table function is deprecated (4 ms)
      ✓ cannot run table (2 ms)
  error handling
    ✓ no close brace (35 ms)
    ✓ field and query with same name does not overflow (350 ms)
    ✓ redefine source (4 ms)
    ✓ query from undefined source (4 ms)
    ✓ query with expression from undefined source (18 ms)
    ✓ join reference before definition (38 ms)
    ✓ non-rename rename (7 ms)
    ✓ reference to field in its definition (36 ms)
    ✓ empty model (1 ms)
    ✓ one line model  (1 ms)
    ✓ query without fields (3 ms)
    ✓ refine cannot change query type (17 ms)
    ✓ undefined field ref in query (3 ms)
    ✓ query on source with errors (3 ms)
    ✓ detect duplicate output field names (30 ms)
    ✓ detect join tail overlap existing ref (13 ms)
    ✓ undefined in expression with regex compare (16 ms)
    ✓ detect output collision on join references (2 ms)
    ✓ rejoin a query is renamed (25 ms)
    ✓ popping out of embedding when not embedded
    ✓ bad sql in sql block (2 ms)
  translate imports
    ✓ import at (4 ms)
  translation need error locations
    ✓ import error location
    ✓ sql struct error location (4 ms)
    ✓ table struct error location (1 ms)
  error cascading
    ✓ errors can appear in multiple top level objects (8 ms)
    ✓ dependent errors do not cascade (696 ms)
    ✓ error type inference is good (289 ms)
    ✓ eval space of errors is preserved (218 ms)
  pipeline comprehension
    ✓ second query gets namespace from first (39 ms)
    ✓ second query doesn't have access to original fields (8 ms)
    ✓ new query can append ops to existing query (13 ms)
    ✓ new query can refine and append to exisiting query (14 ms)
    ✓ reference to a query can include a refinement (6 ms)
    ✓ Querying an sourcebased on a query (13 ms)
    ✓ new query appends to existing query (4 ms)
  raw function call with type specified
    ✓ timestamp_seconds (2 ms)
  sql expressions
    ✓ reference to sql expression in unextended source (3 ms)
    ✓ sql expression legal with single quote (1 ms)
    ✓ sql expression legal with double quote (2 ms)
    ✓ reference to sql expression in extended source (19 ms)
    ✓ reference to sql expression in named query (2 ms)
    ✓ reference to sql expression in unnamed query (2 ms)
    ✓ cannot refine sql query (2 ms)
    ✓ reference to sql expression in join (8 ms)
    ✓ reference to sql expression in run (1 ms)
    ✓ reference to sql expression in query def (2 ms)
    ✓ reference to sql expression in anonymous query (1 ms)
    ✓ cannot refine a SQL query saved as a query (14 ms)
    ✓ cannot refine a SQL query directly (4 ms)
  extend and refine
    extend and refine, new syntax
      ✓ query name with query refinements (2 ms)
      ✓ query name with source refinements (3 ms)
      ✓ source name with query refinements (1 ms)
      ✓ source name with source refinements (2 ms)
      ✓ query with source refinements (2 ms)
      ✓ query with extension then new stage (6 ms)
    extend and refine, old syntax
      ✓ query name with query refinements (2 ms)
      ✓ query name with source refinements (3 ms)
      ✓ source name with query refinements (1 ms)
      ✓ source name with source refinements (4 ms)
      query name with ambiguous refinements
        ✓ adding segment to ambuguously refined query (25 ms)
        ✓ automatically recognize this as a query refinement without new stage (8 ms)
        ✓ can extend a query into a source (3 ms)
        ✓ can also add an arrow to clarify that it is a query (89 ms)
    extend and refine fallout
      ✓ syntactically valid to run a source, but still illegal (1 ms)
      ✓ syntactically valid to refine a source, but illegal (1 ms)
    turtles
      ✓ explicit refine in turtle works (8 ms)
      ✓ implicit refine in turtle works (6 ms)
    nests
      ✓ explicit refine in nest (7 ms)
      ✓ refine in nest (7 ms)
  miscellaneous m4 warnings
    ✓ project is deprecated (4 ms)
    ✓ query leading arrow (3 ms)
  m3/m4 source query sentences
    ✓ M4 should error on these sq expressions (3 ms)
    ✓ legal sqexpressions (15 ms)
  sql_functions
    ✓ can aggregate sql function (9 ms)

PASS packages/malloy/src/lang/test/source.spec.ts
  source:
    ✓ table (127 ms)
    ✓ shorcut fitlered table (396 ms)
    ✓ fitlered table (5 ms)
    ✓ ref source with no refinement (4 ms)
    ✓ source from query (403 ms)
    ✓ refine source (20 ms)
    ✓ source refinement preserves original (10 ms)
    ✓ dates do not become timestamps (2 ms)
    source properties
      ✓ single dimension (2 ms)
      ✓ field def with null value (9 ms)
      ✓ multiple dimensions (24 ms)
      ✓ single declare ok b4 m4 (17 ms)
      ✓ multiple declare ok b4 m4 (14 ms)
      ✓ single measure (9 ms)
      ✓ multiple measures (42 ms)
      ✓ single where (8 ms)
      ✓ multiple where (31 ms)
      ✓ where clause can use the join namespace in source refined query (151 ms)
      ✓ primary_key (2 ms)
      ✓ rename (6 ms)
      ✓ accept single (4 ms)
      ✓ accept multi (11 ms)
      ✓ except single (5 ms)
      ✓ except multi (2 ms)
      ✓ turtle in a source can be called view (3 ms)
      ✓ turtle in source can be called query with m4 warning (8 ms)
      ✓ refined explore-query (22 ms)
      ✓ chained explore-query (21 ms)
      ✓ chained explore-query with refinement two steps (13 ms)
      ✓ pipelined explore-query with refinement (12 ms)
      ✓ pipelined explore-query with view chain (9 ms)
      ✓ multiple explore-query (13 ms)
      joins
        ✓ with (8 ms)
        ✓ with (9 ms)
        ✓ with dotted ref (3 ms)
        ✓ one on (3 ms)
        ✓ one is on (2 ms)
        ✓ many on (3 ms)
        ✓ many with (2 ms)
        ✓ many is on (3 ms)
        ✓ cross (6 ms)
        ✓ cross is (5 ms)
        ✓ cross on (3 ms)
        ✓ multiple joins (17 ms)
        ✓ with requires primary key (7 ms)
        ✓ can join a query without a rename (42 ms)
        ✓ can with join a single column query (14 ms)
      access modifiers and include
        ✓ private not accessible in query (385 ms)
        ✓ internal not accessible in query (3 ms)
        ✓ internal is accessible in source extension (2 ms)
        ✓ private is inaccessible in source extension (8 ms)
        ✓ internal is inaccessible in joining source on (4 ms)
        ✓ internal at definition time (10 ms)
        ✓ internal is inaccessible in joining source field (11 ms)
        ✓ internal is inaccessible in view reference (5 ms)
        ✓ private field used in view is accessible outside via view (4 ms)
        ✓ use internal field in query in extension (5 ms)
        ✓ cannot expand access from private (6 ms)
        ✓ can expand access from internal explicitly (5 ms)
        ✓ can expand access from internal with star (3 ms)
        ✓ star does not expand access (3 ms)
        ✓ access modifier * (2 ms)
        ✓ private things can be used in immediate extension (2 ms)
        ✓ private things cannot be used in later extension (2 ms)
        ✓ access modifier * except (50 ms)
        ✓ access modifier * nonconflicting use (3 ms)
        ✓ cannot override in same source (2 ms)
        ✓ rename in include (6 ms)
        ✓ commas optional in include (54 ms)
        ✓ include and except list (36 ms)
        ✓ except and include list (4 ms)
    composite sources
      ✓ basic composite source (5 ms)

PASS packages/malloy/src/lang/test/query.spec.ts
  query:
    basic query syntax
      ✓ run:anonymous query (544 ms)
      ✓ query:anonymous query m4 warning (17 ms)
      ✓ named query: (7 ms)
      ✓ run query ref (2 ms)
      ✓ query from query (4 ms)
      ✓ query with refinements from query (9 ms)
      ✓ chained query operations (44 ms)
      ✓ query output refined into another query (454 ms)
      ✓ query with shortcut filtered turtle (20 ms)
      ✓ query with filtered turtle (4 ms)
      ✓ nest: in group_by: (22 ms)
      ✓ reduce pipe project (42 ms)
      ✓ refine and extend query (3 ms)
      ✓ query refinement preserves original (3 ms)
      ✓ query composition preserves original (6 ms)
      ✓ all ungroup with args (13 ms)
      ✓ all ungroup checks args (8 ms)
      ✓ exclude ungroup with args (26 ms)
      ✓ exclude ungroup checks args (22 ms)
      ✓ exclude problem revealed by production models (81 ms)
      ✓ exclude output checking survives refinement (51 ms)
    query operation typechecking
      field declarations
        ✓ cannot use aggregate in group_by (2 ms)
        ✓ cannot use ungrouped_aggregate in group_by (1 ms)
        ✓ cannot use analytic in group_by (2 ms)
        ✓ cannot use aggregate in dimension (5 ms)
        ✓ cannot use ungrouped_aggregate in dimension (8 ms)
        ✓ cannot use analytic in dimension (6 ms)
        ✓ cannot use scalar in measure (5 ms)
        ✓ cannot use analytic in measure (6 ms)
        ✓ cannot use scalar in aggregate (2 ms)
        ✓ cannot use analytic in aggregate (1 ms)
        ✓ cannot use scalar in calculate (3 ms)
        ✓ cannot use aggregate in calculate (2 ms)
        ✓ cannot use aggregate in project (2 ms)
        ✓ cannot use analytic in project (1 ms)
        ✓ cannot use analytic in extended source (22 ms)
        ✓ cannot use aggregate in index (9 ms)
        ✓ can use aggregate in except (4 ms)
      field references
        ✓ cannot use aggregate in group_by (75 ms)
        ✓ cannot use query in group_by (4 ms)
        ✓ cannot use scalar in aggregate (2 ms)
        ✓ cannot use scalar in calculate (6 ms)
        ✓ cannot use aggregate in calculate (2 ms)
        ✓ cannot use query in project (4 ms)
        ✓ cannot use query in index (3 ms)
        ✓ cannot use query in calculate (5 ms)
        ✓ cannot use query in aggregate (3 ms)
        ✓ cannot use aggregate in calculate, preserved over refinement (3 ms)
        ✓ cannot use scalar in calculate, preserved over refinement (2 ms)
        ✓ cannot use analytic in group_by, preserved over refinement (6 ms)
        ✓ cannot use analytic in order_by, preserved over refinement (10 ms)
        ✓ cannot ungroup an ungrouped (3 ms)
        ✓ cannot aggregate an ungrouped (2 ms)
        ✓ cannot aggregate an aggregate (2 ms)
        ✓ can use field def in group_by, preserved over refinement (2 ms)
        ✓ can use field ref in group_by, preserved over refinement (2 ms)
    function typechecking
      ✓ use function correctly (2 ms)
      ✓ function incorrect case (2 ms)
      ✓ function no matching overload (2 ms)
      ✓ unknown function (1 ms)
      ✓ can select different overload (4 ms)
      ✓ can pass different expression types (9 ms)
      ✓ function return type correct (3 ms)
      ✓ function return type incorrect (9 ms)
      ✓ can use output value in calculate (2 ms)
      ✓ cannot use output value in group_by (3 ms)
      ✓ lag can check that other args are constant (2 ms)
      ✓ lag can check that other args are literal (2 ms)
      ✓ lag can check that other args are nonnull (3 ms)
      ✓ lag can use constant values for other args (6 ms)
      ✓ cannot name top level objects same as functions (2 ms)
      ✓ `now` is considered constant` (2 ms)
      ✓ cannot use a field which is a constant in a constant param (33 ms)
      ✓ cannot use struct in function arg (3 ms)
      ✓ cannot use stddev with no arguments (1 ms)
      ✓ can use stddev with postfix syntax (3 ms)
      ✓ can use stddev with postfix syntax on join (3 ms)
      ✓ can use calculate with a measure (3 ms)
      ✓ cannot use calculate with input fields (5 ms)
      ✓ can use calculate with aggregate field which is not in query (3 ms)
      ✓ cannot use agregate as argument to agg function (1 ms)
      ✓ cannot use calculate with no other fields (2 ms)
      ✓ today: cannot order by analytic function (2 ms)
      ✓ cannot use analytic in calculate -- and preserved over refinement (3 ms)
      ✓ cannot use aggregate analytic in project (2 ms)
      ✓ reference field in join (2 ms)
      ✓ reference field in double nested join inside nest (40 ms)
      ✓ can reference select: inline join.* field in calculate (3 ms)
      ✓ can reference select: join.* field in calculate (3 ms)
      ✓ can reference implied output entries in calculate (10 ms)
      ○ skipped cannot use float in round precision
      ○ skipped reference join as field
      dialect functions
        ✓ can use function enabled in this dialect (standardsql) (5 ms)
        ✓ cannot use function enabled in a different dialect (duckdb) (1 ms)
    qops
      ✓ group by single (1 ms)
      ✓ group_by x is x' (2 ms)
      ✓ group by multiple (5 ms)
      ✓ aggregate single (1 ms)
      ✓ calculate in reduce (3 ms)
      ✓ calculate in project (24 ms)
      ✓ aggregate reference (1 ms)
      ✓ timeunit reference (2 ms)
      ✓ aggregate multiple (2 ms)
      ✓ project ref (6 ms)
      ✓ expands star correctly (1 ms)
      ✓ expands join dot star correctly (1 ms)
      ✓ expands star with exclusions (22 ms)
      ✓ array in query is passed into fields (2 ms)
      ✓ star error checking (20 ms)
      ✓ regress check extend: and star (2 ms)
      ✓ project def (2 ms)
      ✓ project multiple (5 ms)
      ✓ index single
      ✓ regress check extend: and star (1 ms)
      ✓ project def (1 ms)
      ✓ project multiple (2 ms)
      ✓ index single (1 ms)
      ✓ index path (1 ms)
      ✓ index unique on path (18 ms)
      ✓ index join.* (2 ms)
      ✓ index multiple (5 ms)
      ✓ index by (1 ms)
      ✓ index sampled (3 ms)
      ✓ index unsampled (2 ms)
      ✓ index sample-percent (2 ms)
      ✓ index sample-rows (2 ms)
      ✓ top N (3 ms)
      ✓ limit N (5 ms)
      ✓ order by multiple (11 ms)
      ✓ agg cannot be used in where (7 ms)
      ✓ analytic cannot be used in where (3 ms)
      ✓ analytic cannot be used in having (4 ms)
      ✓ where single (2 ms)
      ✓ having single (2 ms)
      ✓ compound having still works (9 ms)
      ✓ compound aggregate still works (5 ms)
      ✓ where multiple (29 ms)
      ✓ filters preserve source formatting in code: (14 ms)
      ✓ field expressions preserve source formatting in code: (3 ms)
      ✓ nest single (10 ms)
      ✓ nest multiple (31 ms)
      ✓ nest ref (2 ms)
      ✓ refine query with extended source (8 ms)
      ✓ refine query source with field (3 ms)
      ✓ refine query source with join (6 ms)
      order by variations
        ✓ order by (2 ms)
        ✓ order by preserved over refinement (2 ms)
        ✓ order by must be in the output space (2 ms)
        ✓ order by asc (2 ms)
        ✓ order by desc (1 ms)
        ✓ order by N (2 ms)
        ✓ first aggregate used for default ordering (3 ms)
        ✓ first temporal used for default ordering (1 ms)
        ✓ first used for ordering when appropriate (6 ms)
      extend block
        ✓ works with dimension (2 ms)
        ✓ works with measure (2 ms)
        ✓ works with join_one (8 ms)
        ✓ works with join_many (3 ms)
        ✓ works with join_cross (3 ms)
        ✓ works with multiple in one block (2 ms)
        ✓ works with multiple blocks (6 ms)
      declare/query join warnings
        ✓ declare warning in query (9 ms)
        ✓ declare warning in source (9 ms)
        ✓ joins in query (16 ms)
    refinement location rules
      ✓ where clauses go into the first segment (4 ms)
      ✓ having clauses go into the last segment (10 ms)
      ✓ limit goes into the last segment (4 ms)
      ✓ order_by goes into the last segment (4 ms)
      ✓ group_by illegal in long pipes (2 ms)
      ✓ aggregate illegal in long pipes (3 ms)
      ✓ calcluate illegal in long pipes (3 ms)
      ✓ extend illegal in long pipes (2 ms)
      ✓ nest illegal in long pipes (7 ms)
      ✓ all single stage refinements are accepted (6 ms)

PASS packages/malloy/src/lang/test/annotation.spec.ts
  document annotation
    ✓ every source annotation point (145 ms)
    ✓ multi line source annotation (2 ms)
    ✓ inherited annotation source (360 ms)
    ✓ define full query annotation points (428 ms)
    ✓ run statement annotation points (7 ms)
    ✓ multi line query annotation (7 ms)
    ✓ inherited annotation query (60 ms)
    ✓ query from turtle inherits turtle annotation (27 ms)
    ✓ model annotations (2 ms)
    ✓ ignores objectless object annotations (2 ms)
    ✓ errors reported from compiler flags (6 ms)
    ✓ checking compiler flags (2 ms)
    ✓ extended models inherit model flags (2 ms)
  source definition annotations
    ✓ turtle block annotation (5 ms)
    ✓ refined turtle inherits annotation (8 ms)
    ✓ dimension block annotation (20 ms)
    ✓ measure block annotation (16 ms)
    ✓ join_one-with block annotation (41 ms)
    ✓ join_many-on block annotation (14 ms)
    ✓ ignores model annotation (8 ms)
  query operation annotations
    ✓ ignores model annotation (11 ms)
    ✓ project new definition annotation (31 ms)
    ✓ select: ref inherits annotation (9 ms)
    ✓ group_by def (43 ms)
    ✓ caculate def (68 ms)
    ✓ group_by ref inherits (7 ms)
    ✓ aggregate def (18 ms)
    ✓ aggregate ref inherits (9 ms)
    ✓ nest annotation (29 ms)
    ✓ nest from existing inherits annotation (6 ms)
    ✓ annotations preserved from path references (97 ms)
    ✓ a reference can have an annotation (3 ms)
    include annotations
      ✓ inherit: star (379 ms)
      ✓ new tags are inherited, not added (26 ms)
      ✓ modifier: star (12 ms)
      ✓ inherit: list (45 ms)
      ✓ modifier: list (20 ms)
      ✓ tags except: list (35 ms)
      ✓ tags except: star (12 ms)
      ✓ oprhaned annotation (26 ms)

PASS packages/malloy/src/lang/test/lenses.spec.ts
  lenses
    ✓ long lens patterns (1017 ms)
    ✓ lens parens patterns (98 ms)
    ✓ cannot have overlapping names (20 ms)
    ✓ cannot override limit (15 ms)
    ✓ cannot override ordering (20 ms)
    ✓ weird issue with order by constant group by (6 ms)
    ✓ can add a limit late (10 ms)
    ✓ cannot refine with incompatible view types (40 ms)
    ✓ can reference dimension at head of query when experiment is enabled (5 ms)
    ✓ can change refine precedence (30 ms)
    ✓ cannot refine with multi-stage (11 ms)
    ✓ cannot refine with literal multi-stage (17 ms)
    ✓ can reference dimension in refinement when experiment is enabled (7 ms)
    ✓ can reference join field when experiment is enabled (49 ms)
    ✓ can reference join field in refinement when experiment is enabled (8 ms)
    ✓ can reference join field in nest refinement when experiment is enabled (8 ms)
    ✓ can nest dimension when experiment is enabled (4 ms)
    ✓ cannot use join_name in refinement shortcut (9 ms)
    ✓ cannot use view from join as whole pipeline (20 ms)
    ✓ cannot use view from join in nest (13 ms)
    ✓ cannot use view from join as nest view head (13 ms)
    ✓ cannot use view from join as lens in query (11 ms)
    ✓ cannot use view from join as lens in nest (11 ms)
    ✓ can nest dimension with refinement when experiment is enabled (43 ms)
    ✓ cannot reference join (5 ms)
    ✓ cannot reference field in LHS of refinement in group_by (6 ms)
    ✓ cannot named-refine multi-stage query (9 ms)
    ○ skipped can split multi-stage refinement with plus
  partial views
    ✓ allow where-headed refinement chains (14 ms)
    ✓ order by tacked on the end should work (13 ms)
    ✓ name can be inferred with arrow (11 ms)
    ✓ nice error when nest has no name (4 ms)
    ✓ disallow chains that have no fields in view (13 ms)
    ✓ disallow chains that have no fields in multi-stage (15 ms)
    ✓ copy of view with refinement should work (9 ms)
    ○ skipped partial with index

PASS packages/malloy/src/lang/test/locations.spec.ts
  source locations
    ✓ renamed source location (330 ms)
    ✓ refined source location (189 ms)
    ✓ location of defined dimension (215 ms)
    ✓ location of defined measure (8 ms)
    ✓ location of defined view (413 ms)
    ✓ location of defined field inside a view (5 ms)
    ✓ location of filtered field inside a view (330 ms)
    ✓ location of field inherited from table (3 ms)
    ✓ location of field inherited from sql source (4 ms)
    ✓ location of fields inherited from a query (31 ms)
    ✓ location of named query (42 ms)
    ✓ location of field in named query (2 ms)
    ✓ location of renamed field (7 ms)
    ✓ location of join on (45 ms)
    ✓ location of join with (6 ms)
    ✓ location of field in join (14 ms)
    ✓ undefined query location (2 ms)
    ✓ undefined field reference (2 ms)
    ✓ bad query (6 ms)
    ○ skipped undefined field reference in top
    ○ skipped undefined field reference in order_by
    ✎ todo location of parameter
  source references
    ✓ reference to explore (2 ms)
    ✓ reference to query in query (8 ms)
    ✓ reference to query in query (version 2) (4 ms)
    ✓ reference to query (4 ms)
    ✓ reference to query in query head (3 ms)
    ✓ reference to query in refined query (7 ms)
    ✓ reference to field in expression (8 ms)
    ✓ reference to quoted field in expression (9 ms)
    ✓ reference to joined field in expression (21 ms)
    ✓ reference to joined join in expression (5 ms)
    ✓ reference to field not in expression (group by) (1 ms)
    ✓ reference to field not in expression (project) (1 ms)
    ✓ reference to field in aggregate (3 ms)
    ✓ reference to field in measure (9 ms)
    ✓ reference to field in filter (9 ms)
    ✓ reference to field in aggregate source (3 ms)
    ✓ reference to join in aggregate source (4 ms)
    ✓ reference to join in aggregate in expr (3 ms)
    ✓ reference to sourcein join (5 ms)
    ✓ reference to field in aggregate (in expr) (2 ms)
    ✓ reference to field in rename (1 ms)
    ✓ reference to field in join with (3 ms)
    ○ skipped reference to field in order by
    ○ skipped reference to field in order by (output space)
    ○ skipped reference to field in top
    ○ skipped reference to field in top (output space)

PASS packages/malloy/src/lang/test/composite-field-usage.spec.ts
  composite sources
    composite field usage
      ✓ looked up value (2 ms)
      ✓ multiple values (1 ms)
      ✓ value plus constant (9 ms)
      ✓ join usage (12 ms)
      ✓ join usage complex (1 ms)
      ✓ measure defined in composite source (1 ms)
      ✓ measure with filter defined in composite source (1 ms)
    composite source resolution and validation
      ✓ compose fails on group_by that is relevant (439 ms)
      ✓ compose fails on filter that is relevant (16 ms)
      ✓ compose fails in case where second field has overlap with first (15 ms)
      ✓ compose resolution succeeds nested (45 ms)
      ✓ good composite field usage works (3 ms)
      ✓ index on composite translates (12 ms)
      ✓ raw run of composite source fails (2 ms)
      ✓ composite source with parameter (19 ms)
      ✓ composite source does not include private field (4 ms)
      ✓ composite source does not resolve to private field (7 ms)
      ✓ composite source does include internal field (15 ms)
      ✓ access level mismatch in composite (before) (3 ms)
      ✓ access level mismatch in composite (after) (3 ms)
      ✓ array.each is okay (20 ms)
      ✓ timevalue extract okay (8 ms)

PASS packages/malloy/src/lang/test/parameters.spec.ts
  parameters
    ✓ can declare parameter with no default value (130 ms)
    ✓ can declare parameter with default value literal (10 ms)
    ✓ can declare parameter with default value constant (18 ms)
    ✓ cannot specify default value with incompatible type (2 ms)
    ✓ error if paramter has no type or value (4 ms)
    ✓ error if paramter type is null (2 ms)
    ✓ allowed to write null::string (2 ms)
    ✓ allowed to write ::string is null (2 ms)
    ✓ can use param in null equality expression (812 ms)
    ✓ error if paramter type is range (8 ms)
    ✓ no additional error if default value type is error (9 ms)
    ✓ can declare parameter with inferred type (1 ms)
    ✓ can pass parameter into extended base source (7 ms)
    ✓ can pass parameter to override default value with constant (2 ms)
    ✓ can pass parameter to override default value with param value (2 ms)
    ✓ can pass parameter into named base source (4 ms)
    ✓ can pass differently-named parameter into extended base source (3 ms)
    ✓ can pass differently-named parameter into named base source (1 ms)
    ✓ can pass parameter into base source longhand (2 ms)
    ✓ can pass parameter into base source shorthand (1 ms)
    ✓ can use declared parameter in dimension (25 ms)
    ✓ can use declared parameter in sql function (16 ms)
    ✓ can use declared parameter in nest extending other (61 ms)
    ✓ can use declared parameter in source extension in view (82 ms)
    ✓ can use declared parameter in nest with table (17 ms)
    ✓ can pass argument for param (2 ms)
    ✓ can not pass argument for default-valued param (2 ms)
    ✓ can pass zero args for source with default-valued param (2 ms)
    ✓ can pass non-literal argument for param (3 ms)
    ✓ parameter not included in wildcard (7 ms)
    ✓ cannot reference renamed param in query against source (4 ms)
    ✓ cannot reference param in query against source (2 ms)
    ✓ cannot reference param in source extension (6 ms)
    ✓ cannot reference param in in-query source extension (2 ms)
    ✓ can reference field in source in argument (2 ms)
    ✓ can pass through parameter to joined source (shorthand) (96 ms)
    ✓ can pass through parameter to joined source (longhand) (19 ms)
    ✓ can reference param in query against source (1 ms)
    ✓ can reference param in view in source (3 ms)
    ✓ can declare dimension which is just the parameter (2 ms)
    ✓ cannot reference param in expression in query against source (2 ms)
    ✓ error when declaring parameter twice (1 ms)
    ✓ error when declaring parameter with same name as field (extended) (22 ms)
    ✓ can shadow field that is excepted (5 ms)
    ✓ error when declaring parameter with same name as field (not extended) (2 ms)
    ✓ do not inherit parameters from base source (2 ms)
    ✓ error when declaring field with same name as parameter (5 ms)
    ✓ error when declaring parameter without experiment enabled
    ✓ cannot except parameter from extended source (1 ms)
    ✓ cannot except parameter in direct extend (2 ms)
    ✓ cannot accept parameter (2 ms)
    ✓ error when using parameter without experiment enabled (1 ms)
    ✓ parameters cannot reference themselves (5 ms)
    ✓ error when circularly referencing mutually recursive parameters in argument (2 ms)
    ✓ error when passing param with no name (2 ms)
    ✓ error when passing param with incorrect name (2 ms)
    ✓ error when passing param multiple times (2 ms)
    ✓ error when not specifying argument for param with parentheses (2 ms)
    ✓ error when not specifying argument for param without parentheses (1 ms)
    ✓ error when not specifying argument for param second time (3 ms)
    ✓ error when referencing parameter that does not exist in join definition (2 ms)
    ✓ error when referencing identifier in default param value (1 ms)
    ✓ can not pass parameter into source of query yet (2 ms)
    ✓ source arguments from query propagate as arguments not parameters (20 ms)
    ✓ source arguments carry over from previous invocation (2 ms)
    ○ skipped can pass parameter into source of query
    ○ skipped can pass through parameter to source in joined query
    ○ skipped can pass through parameter to view in joined query
    ○ skipped can pass through parameter to source in query in SQL source
    ○ skipped can pass through parameter to view in query in SQL source
    ○ skipped can pass through parameter to source in query in joined SQL source
    ○ skipped can use param in multi-stage query
    ○ skipped can add an annotation to a param

PASS packages/malloy/src/lang/test/sql-block.spec.ts
  connection sql()
    ✓ source from sql (942 ms)
    ✓ source from imported sql-based-source (424 ms)
    ✓ simple turducken (177 ms)
    ✓ turduckenzilla (254 ms)
    ✓ source from extended sql-based-source (5 ms)

PASS packages/malloy/src/lang/test/imports.spec.ts
  import:
    ✓ simple source (130 ms)
    ✓ simple source with importBaseURL (3 ms)
    ✓ simple query (442 ms)
    ✓ query based source with named structref (405 ms)
    ✓ missing import (1 ms)
    ✓ chained imports (4 ms)
    ✓ relative imports (9 ms)
    ✓ relative imports with errors (21 ms)
    ✓ source references expanded when not exported (31 ms)
    ✓ selective import of source (141 ms)
    ✓ renaming import of source (2 ms)
    ✓ selective import of source, not found (2 ms)
    ✓ selective renamed import of source, not found (3 ms)
    ✓ selective import of source, no-redefinition (2 ms)

PASS packages/malloy/src/lang/test/document-symbol-walker.spec.ts
  ✓ source symbols are included (123 ms)
  ✓ query symbols are included (32 ms)
  ✓ run (def) symbols are included (1 ms)
  ✓ run (ref) symbols are included (1 ms)
  ✓ expression field defs are included (373 ms)
  ✓ renamed fields are included (6 ms)
  ✓ name only fields are included (12 ms)
  ✓ turtle fields are included (416 ms)
  ✓ turtle children fields are included (3 ms)
  ✓ turtle children turtles are included (20 ms)
  ✓ refinement chain gets name correctly (22 ms)
  ✓ arrow in nest infers name correctly (10 ms)
  ✓ join withs are included (32 ms)
  ✓ join ons are included (4 ms)
  ✓ source lenses go before block annotations when one source (3 ms)
  ✓ source lenses go before individual annotations when more than one source (11 ms)
  ✓ query lenses go before block annotations when one source (2 ms)
  ✓ query lenses go before individual annotations when more than one source (17 ms)
  ✓ anonymous query lenses go before block annotations (1 ms)
  ✓ run lenses go before block annotations (2 ms)
  ✓ multiline unnamed queries include last line (4 ms)
  ✓ multiline named queries include last line (1 ms)
  ✓ (regression) query does not use source block range (34 ms)

PASS packages/malloy/src/lang/test/document-help-context-walker.spec.ts
  ✓ Supports model properties (971 ms)
  ✓ Supports source properties (13 ms)
  ✓ Supports query properties (11 ms)

PASS test/src/core/sql_source.spec.ts
  turducken
    ✓ malloy source code is wrapped in parens (747 ms)
    ✓ malloy source code not double-wrapped in parens (8 ms)

PASS packages/malloy/src/lang/test/literals.spec.ts
  literals
    ✓ integer (46 ms)
    ✓ string (2 ms)
    ✓ string with quoted quote (6 ms)
    ✓ string with quoted backslash (1 ms)
    ✓ @1960 (3 ms)
    ✓ @1960-Q2 (1 ms)
    ✓ @1960-06 (2 ms)
    ✓ @1960-06-26-WK (2 ms)
    ✓ @1960-06-30 (1 ms)
    ✓ @1960-06-30 10 (2 ms)
    ✓ @1960-06-30 10:30 (1 ms)
    ✓ @1960-06-30 10:30:00 (2 ms)
    ✓ @1960-06-30 10:30:00.123 (1 ms)
    ✓ @1960-06-30T10:30:00 (5 ms)
    ✓ @1960-06-30 10:30:00[America/Los_Angeles] (2 ms)
    ✓ morphic value for @1960 is 1960-01-01 00:00:00 (1 ms)
    ✓ morphic value for @1960-Q2 is 1960-04-01 00:00:00 (1 ms)
    ✓ morphic value for @1960-06 is 1960-06-01 00:00:00 (1 ms)
    ✓ morphic value for @1960-06-26-Wk is 1960-06-26 00:00:00 (2 ms)
    ✓ morphic value for @1960-06-30 is 1960-06-30 00:00:00 (1 ms)
    ✓ morphic value for @1960-06-30 00:00 is undefined (1 ms)
    ✓ minute+locale (1 ms)
    ✓ second 8601 (1 ms)
    ✓ null (1 ms)
    ✓ now (1 ms)
    ✓ true (1 ms)
    ✓ false (1 ms)
    ✓ regex (2 ms)
    quote comprehension inside strings
      ✓ \b (2 ms)
      ✓ \f
      ✓ \n
      ✓ \r
      ✓ \t
      ✓ unicode ?
      ✓ normal stuff
      ✓ stuff & nonsense
      ✓ one thing\nnext thing
      ✓ quote stripping works
    string parsing in language
      ✓ multi-line indent increasing (3 ms)
      ✓ multi-line indent decreasing (1 ms)
      ✓ multi-line indent keep (1 ms)
      ✓ timezone single quote (519 ms)
      ✓ timezone double quote (7 ms)
      ✓ timezone triple quote (7 ms)
      ✓ timezone with illegal query (154 ms)
      ✓ table single quote (11 ms)
      ✓ table double quote
      ✓ table triple quote (1 ms)
      ✓ sql single quote (1 ms)
      ✓ sql double quote (1 ms)
      ✓ sql triple quote (2 ms)
      ✓ import single quote
      ✓ import double quote
      ✓ import triple quote
      ✓ literal single quote (1 ms)
      ✓ literal double quote (1 ms)
      ✓ literal triple quote (1 ms)
      ✓ a string containing a tab (1 ms)
    compound literals
      ✓ simple record literal (4 ms)
      ✓ record literal with path (15 ms)
      ✓ array of records with same schema (3 ms)
      ✓ array of records with head schema (1 ms)

PASS packages/malloy/src/lang/test/find-table-path-walker.spec.ts
  ✓ Table path can be retrieved (933 ms)
  ✓ Table path can not be retrieved (1 ms)
  ✓ Table path can not be retrieved for non string path (144 ms)

PASS packages/malloy/src/lang/test/field-symbols.spec.ts
  structdef comprehension
    ✓ import string field
    ✓ import float field
    ✓ import integer field
    ✓ import boolean field
    ✓ import unsupported field
    ✓ import repeated record
    ✓ import inline field
    ✓ import join field
    ✓ import query stage field
    ✓ import struct with parameters

PASS packages/malloy/src/lang/test/pretranslate.spec.ts
  pretranslated models
    ✓ import of pretranslated (108 ms)

PASS packages/malloy/src/lang/test/model-annotation-walker.spec.ts
  ✓ model annotations can be retrieved (101 ms)
  ✓ does not explode if bad parse (2 ms)

PASS packages/malloy-malloy-sql/src/grammar/test/parse.spec.ts
  MalloySQL parse
    Should parse inital comments
      ✓ initial single-line forward-slash comment (1 ms)
      ✓ initial single-line double-dash comment (1 ms)
      ✓ initial multi-line comment
      ✓ initial comments mixed
    Should parse control statement
      ✓ Should parse immediate delimiter (1 ms)
      ✓ Should parse initial comments and delimiter (1 ms)
      ✓ Should parse multiple empty control statements (1 ms)
    Should parse statement
      ✓ Should parse statement with comments
      ✓ Should parse statements
    connection: config
      ✓ Should not allow connection in >>>malloy line
      ✓ Should not allow anything besides comments in >>>malloy line
      ✓ Should handle a connection in a delimiter (1 ms)
      ✓ Should handle a connection in a comment
      ✓ Should mark a connection as inherited
    Embedded Malloy
      ✓ Parenthesized embedded malloy can handle space between ( and {%
      ✓ Non-parenthesized embedded malloy
    Parse output
      ✓ Should provide correct output for single statement (3 ms)
      ✓ Should provide correct output for multiple statements (1 ms)
      ✓ Should provide correct output for mulitple statements with embedded malloy
      ✓ Should provide correct output for embedded >>> (1 ms)
      ✓ Should provide correct output for cells that contain only comments

PASS packages/malloy-db-trino/src/trino_connection.spec.ts
  Trino connection
    schema parser
      ✓ parses arrays
      ✓ parses inline (1 ms)
      ✓ parses nested
      ✓ parses a simple type
      ✓ parses a decimal integer type
      ✓ parses a decimal float type
      ✓ parses row with timestamp(3)
      ✓ parses deep nesting

PASS packages/malloy-syntax-highlight/grammars/malloy/malloy.spec.ts
  malloy
    ✓ correctly tokenizes
	"// / ' " """ // unable to break out of /* line comments"
	with correct colors (1 ms)
    ✓ correctly tokenizes
	" -- a different -- line comment"
	with correct colors
    ✓ correctly tokenizes
	"    /* *** / * // " " ' \'"
	"   """ multi-line * /*"
	"" */  -- escaped block"
	with correct colors
    ✓ correctly tokenizes
	"  sample: true"
	with correct colors
    ✓ correctly tokenizes
	"fl1ght_y34r is `Year of Flight 256/* */`  -- escapes identifier"
	with correct colors
    ✓ correctly tokenizes
	"`Year"
	"  -- escapes quoted identifier at newline"
	with correct colors (1 ms)
    ✓ correctly tokenizes
	"`Disposable Income` is (0.88 * b1) + 84 / 100.00 * b2 + (.79 * `b3`)  "
	with correct colors
    ✓ correctly tokenizes
	"(123E4, 1E-27, E4, 0E+1)"
	with correct colors
    ✓ correctly tokenizes
	"avg(count(distinct session_id))"
	with correct colors
    ✓ correctly tokenizes
	"`year` is year(dep_time)::string  // interpret year as 'categorical'"
	with correct colors
    ✓ correctly tokenizes
	"is hash!number(us3r_n4me)  -- SQL function usage"
	with correct colors (1 ms)
    ✓ correctly tokenizes
	"(@2001-02-03 04:05:06.001[America/Mexico_City], @2005-01-28 12:12:12.999, @1961-02-14 09:30:15, @2017-10-03 07:23) "
	with correct colors
    ✓ correctly tokenizes
	"event_time ~ @2003-Q1 for 6 quarters"
	with correct colors
    ✓ correctly tokenizes
	"(@2021, @2022-06, @2022-09-09, @2023-06-25-WK)"
	with correct colors
    ✓ correctly tokenizes
	"'a string with \escapes\u0FF1 \'more\"
	with correct colors
    ✓ correctly tokenizes
	"state ? """ multiple " " \u "" \u2001 ' /* -- // " \"
	" lines "
	" """  -- exited"
	with correct colors (1 ms)
    ✓ correctly tokenizes
	"/'regexp string /*-- \escapes\uFFFF \'more\"
	with correct colors
    ✓ correctly tokenizes
	""/* -- \e\uFFFF \'\"
	with correct colors
    ✓ correctly tokenizes
	"state ~ 'CA' | r'M.' | "CO" | /'O.'  -- end"
	with correct colors (1 ms)
    ✓ correctly tokenizes
	"run: duckdb.sql(""""
	"  SELECT 1"
	"""")"
	with correct colors

PASS packages/malloy/src/lang/test/model_serialization.spec.ts
  serializeModel
    ✓ Stringify on an `explore` with no parent nor source explore
    ✓ No parent nor source explore
    ✓ Having parent and source explores (1 ms)

PASS packages/malloy/src/model/utils.spec.ts
  model/utils
    ✓ should generate deterministic hashes (1 ms)
    ✓ should generate unique hashes

Summary of all failing tests
FAIL test/src/databases/all/nomodel.spec.ts (79.41 s)
  ● all with parameters - basic  - databricks

    query.run failed: [MISSING_AGGREGATION] The non-aggregating expression "popular_name" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(popular_name)" if you do not care which of the values within a group is returned. SQLSTATE: 42803
    SQL: WITH __stage0 AS (
      SELECT
        group_set,
        CASE WHEN group_set IN (2,1) THEN
          base.`popular_name`
          END as `popular_name__2`,
        CASE WHEN group_set=2 THEN
          base.`state`
          END as `state__2`,
        CASE WHEN group_set=2 THEN
          COALESCE(SUM(base.`births`),0)
          END as `total_births__2`,
        MAX((CASE WHEN group_set=0 THEN
          COALESCE(SUM(base.`births`),0)
          END)) OVER () as `all_births__2`,
        MAX((CASE WHEN group_set=1 THEN
          COALESCE(SUM(base.`births`),0)
          END)) OVER (PARTITION BY CASE WHEN group_set IN (2,1) THEN
          base.`popular_name`
          END) as `all_name__2`
      FROM malloytest.state_facts as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3
    )
    SELECT
      `popular_name__2` as `popular_name`,
      `state__2` as `state`,
      GET((ARRAY_AGG(`total_births__2`) FILTER (WHERE group_set=2 AND `total_births__2` IS NOT NULL)),0) as `total_births`,
      GET((ARRAY_AGG(`all_births__2`) FILTER (WHERE group_set=2 AND `all_births__2` IS NOT NULL)),0) as `all_births`,
      GET((ARRAY_AGG(`all_name__2`) FILTER (WHERE group_set=2 AND `all_name__2` IS NOT NULL)),0) as `all_name`
    FROM __stage0
    WHERE group_set NOT IN (0,1)
    GROUP BY 1,2
    ORDER BY 3 desc NULLS LAST

    Error: [MISSING_AGGREGATION] The non-aggregating expression "popular_name" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(popular_name)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      841 |           all_name is exclude(total_births, state)
      842 |       }
    > 843 |     `).malloyResultMatches(runtime, {
          |        ^
      844 |       all_births: 295727065,
      845 |       all_name: 197260594,
      846 |     });

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/nomodel.spec.ts:843:8)

FAIL test/src/databases/all/functions.spec.ts (122.273 s)
  ● concat › works - databricks

    expect(received).toBe(expected) // Object.is equality

    Expected: "foo2003-01-01 00:00:00"
    Received: "foo2003-01-01 12:00:00"

      119 |       // console.log(databaseName, result.sql);
      120 |       // console.log(result.data);
    > 121 |       expect(result.data.path(0, `f${i}`).value).toBe(testCase[1]);
          |                                                  ^
      122 |     });
      123 |   };
      124 |

      at test/src/databases/all/functions.spec.ts:121:50
          at Array.forEach (<anonymous>)
      at funcTestMultiple (test/src/databases/all/functions.spec.ts:118:15)
      at async Object.<anonymous> (test/src/databases/all/functions.spec.ts:137:7)

  ● row_number › works inside nest - databricks

    [MISSING_AGGREGATION] The non-aggregating expression "county" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(county)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● rank › works ordered by dimension - databricks

    [MISSING_AGGREGATION] The non-aggregating expression "births" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(births)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● rank › properly isolated nested calculations - databricks

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `TO_JSONB` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 38 pos 4
    SQL: WITH __stage0 AS (
      SELECT
        group_set,
        base.`faa_region` as `faa_region__0`,
        CASE WHEN group_set=0 THEN
          COUNT(1)
          END as `airport_count__0`,
        CASE WHEN group_set=0 THEN ROW_NUMBER() OVER(PARTITION BY group_set  ORDER BY  CASE WHEN group_set=0 THEN
          COUNT(1)
          END desc NULLS LAST ) END as `id__0`,
        CASE WHEN group_set IN (1,2) THEN
          base.`fac_type`
          END as `fac_type__1`,
        CASE WHEN group_set=1 THEN
          COUNT(1)
          END as `airport_count__1`,
        CASE WHEN group_set=1 THEN ROW_NUMBER() OVER(PARTITION BY group_set, base.`faa_region`  ORDER BY  CASE WHEN group_set=1 THEN
          COUNT(1)
          END desc NULLS LAST ) END as `id2__1`,
        CASE WHEN group_set=2 THEN
          AVG(base.`elevation`)
          END as `avg_elevation__2`
      FROM malloytest.airports as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,5
    )
    , __stage1 AS (
      SELECT
        CASE WHEN group_set=2 THEN 1 ELSE group_set END as group_set,
        `faa_region__0` as `faa_region__0`,
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count__0`,
        GET((ARRAY_AGG(`id__0`) FILTER (WHERE group_set=0 AND `id__0` IS NOT NULL)),0) as `id__0`,
        CASE WHEN group_set IN (1,2) THEN
          `fac_type__1`
          END as `fac_type__1`,
        GET((ARRAY_AGG(`airport_count__1`) FILTER (WHERE group_set=1 AND `airport_count__1` IS NOT NULL)),0) as `airport_count__1`,
        GET((ARRAY_AGG(`id2__1`) FILTER (WHERE group_set=1 AND `id2__1` IS NOT NULL)),0) as `id2__1`,
        TO_JSONB((ARRAY_AGG((SELECT __x FROM (SELECT
          `avg_elevation__2`::BIGINT as `avg_elevation`) as __x)) FILTER (WHERE group_set=2))[1]) as `elevation__1`
      FROM __stage0
      GROUP BY 1,2,5
    )
    , __stage2 AS (
      SELECT
        `faa_region__0` as `faa_region`,
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count`,
        GET((ARRAY_AGG(`id__0`) FILTER (WHERE group_set=0 AND `id__0` IS NOT NULL)),0) as `id`,
        SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=1 THEN STRUCT(
          `airport_count__1`::BIGINT as `airport_count`,
          `fac_type__1` as `fac_type`,
          `id2__1`::BIGINT as `id2`,
          `elevation__1` as `elevation`) END), ARRAY()), false), 1, 2) as `by_fac_type`
      FROM __stage1
      GROUP BY 1
    )
    SELECT
       CAST(get_json_object(by_fac_type_0, '$.id2') AS DOUBLE) as `id2`
    FROM __stage2 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`by_fac_type`)) as value) as by_fac_type_0 ON true
    GROUP BY 1
    ORDER BY 1 desc NULLS LAST

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `TO_JSONB` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 38 pos 4

      502 |             order_by: id2 desc
      503 |           }
    > 504 |       `).malloyResultMatches(expressionModel, {
          |          ^
      505 |         id2: 2,
      506 |       });
      507 |     });

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:504:10)

  ● lag › works with expression field - databricks

    [MISSING_AGGREGATION] The non-aggregating expression "state" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(state)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● lag › works with field, ordering by expression field - databricks

    [MISSING_AGGREGATION] The non-aggregating expression "state" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(state)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● trunc › works - databricks

    [WRONG_NUM_ARGS.WITHOUT_SUGGESTION] The `trunc` requires 2 parameters but the actual number is 1. Please, refer to 'https://spark.apache.org/docs/latest/sql-ref-functions.html' for a fix. SQLSTATE: 42605; line 2 pos 3

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● is_inf › works - databricks


    [UNSUPPORTED_TYPED_LITERAL] Literals of the type "DOUBLE" are not supported. Supported types are "DATE", "TIMESTAMP_NTZ", "TIMESTAMP_LTZ", "TIMESTAMP", "INTERVAL", "X". SQLSTATE: 0A000
    == SQL (line 2, position 38) ==
    ...ALESCE(CAST('+inf' AS double) = DOUBLE 'Infinity' OR CAST('+inf' AS double) = DOU...
                                       ^^^^^^^^^^^^^^^^^

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● is_nan › works - databricks


    [UNSUPPORTED_TYPED_LITERAL] Literals of the type "NUMERIC" are not supported. Supported types are "DATE", "TIMESTAMP_NTZ", "TIMESTAMP_LTZ", "TIMESTAMP", "INTERVAL", "X". SQLSTATE: 0A000
    == SQL (line 2, position 37) ==
    ...OALESCE(CAST('NaN' AS double) = NUMERIC 'NaN', false) as `f0`,
                                       ^^^^^^^^^^^^^

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● greatest › works - databricks

    [UNRESOLVED_ROUTINE] Cannot resolve routine `NUM_NULLS` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 13

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● least › works - databricks

    [UNRESOLVED_ROUTINE] Cannot resolve routine `NUM_NULLS` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 13

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● strpos › works - databricks

    [UNRESOLVED_ROUTINE] Cannot resolve routine `STRPOS` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● starts_with › works - databricks

    [UNRESOLVED_ROUTINE] Cannot resolve routine `STARTS_WITH` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 12

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● trim › trim works - databricks

    expect(received).toBe(expected) // Object.is equality

    Expected: "keep_this"
    Received: ""

      119 |       // console.log(databaseName, result.sql);
      120 |       // console.log(result.data);
    > 121 |       expect(result.data.path(0, `f${i}`).value).toBe(testCase[1]);
          |                                                  ^
      122 |     });
      123 |   };
      124 |

      at test/src/databases/all/functions.spec.ts:121:50
          at Array.forEach (<anonymous>)
      at funcTestMultiple (test/src/databases/all/functions.spec.ts:118:15)
      at async Object.<anonymous> (test/src/databases/all/functions.spec.ts:947:7)

  ● ltrim › ltrim works - databricks

    expect(received).toBe(expected) // Object.is equality

    Expected: "keep_this -> __"
    Received: ""

      119 |       // console.log(databaseName, result.sql);
      120 |       // console.log(result.data);
    > 121 |       expect(result.data.path(0, `f${i}`).value).toBe(testCase[1]);
          |                                                  ^
      122 |     });
      123 |   };
      124 |

      at test/src/databases/all/functions.spec.ts:121:50
          at Array.forEach (<anonymous>)
      at funcTestMultiple (test/src/databases/all/functions.spec.ts:118:15)
      at async Object.<anonymous> (test/src/databases/all/functions.spec.ts:959:7)

  ● rtrim › rtrim works - databricks

    expect(received).toBe(expected) // Object.is equality

    Expected: "__ <- keep_this"
    Received: ""

      119 |       // console.log(databaseName, result.sql);
      120 |       // console.log(result.data);
    > 121 |       expect(result.data.path(0, `f${i}`).value).toBe(testCase[1]);
          |                                                  ^
      122 |     });
      123 |   };
      124 |

      at test/src/databases/all/functions.spec.ts:121:50
          at Array.forEach (<anonymous>)
      at funcTestMultiple (test/src/databases/all/functions.spec.ts:118:15)
      at async Object.<anonymous> (test/src/databases/all/functions.spec.ts:971:7)

  ● databricks › string_agg › works with multiple order_bys - databricks

    SQL Generated:
      SELECT
         ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST(base.`name`)), ',') as `f`
      FROM malloytest.aircraft as base
      WHERE base.`name` RLIKE '.*RUTHERFORD.*'

    Expected {f: "RUTHERFORD PAT R JR,RUTHERFORD JAMES C"} Got: "RUTHERFORD JAMES C,RUTHERFORD PAT R JR"

      1425 |           order_by: city, name
      1426 |         }
    > 1427 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1428 |         f: 'RUTHERFORD PAT R JR,RUTHERFORD JAMES C',
      1429 |       });
      1430 |     });

      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1427:11)

  ● databricks › string_agg › works with order by expression - databricks

    SQL Generated:
      WITH __stage0 AS (
        SELECT
           base.`name` as `name`
        FROM malloytest.aircraft as base
        WHERE base.`name` RLIKE '.*FLY.*'
        GROUP BY 1
        ORDER BY 1 desc NULLS LAST
        LIMIT 3
      )
      SELECT
         ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST(base.`name`)), ',') as `f`
      FROM __stage0 as base

    Expected {f: "YANKEE FLYING CLUB INC,WESTCHESTER FLYING CLUB,WILSON FLYING SERVICE INC"} Got: "WESTCHESTER FLYING CLUB,WILSON FLYING SERVICE INC,YANKEE FLYING CLUB INC"

      1441 |           order_by: length(name)
      1442 |         }
    > 1443 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1444 |         f: 'YANKEE FLYING CLUB INC,WESTCHESTER FLYING CLUB,WILSON FLYING SERVICE INC',
      1445 |       });
      1446 |     });

      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1443:11)

  ● databricks › string_agg › works with order by join expression - databricks

    SQL Generated:
      SELECT
         ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST(base.`name`)), ',') as `f`
      FROM malloytest.aircraft as base
       LEFT JOIN malloytest.aircraft_models AS aircraft_models_0
        ON aircraft_models_0.`aircraft_model_code`=base.`aircraft_model_code`
      WHERE base.`name` RLIKE '.*ADVENTURE.*'

    Expected {f: "ADVENTURE INC,SEA PLANE ADVENTURE INC,A BALLOON ADVENTURES ALOFT,A AERONAUTICAL ADVENTURE INC"} Got: "A AERONAUTICAL ADVENTURE INC,A BALLOON ADVENTURES ALOFT,ADVENTURE INC,SEA PLANE ADVENTURE INC"

      1451 |         where: name ~ r'.*ADVENTURE.*'
      1452 |         aggregate: f is string_agg(name, ',') { order_by: aircraft_models.model }
    > 1453 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1454 |         f: 'ADVENTURE INC,SEA PLANE ADVENTURE INC,A BALLOON ADVENTURES ALOFT,A AERONAUTICAL ADVENTURE INC',
      1455 |       });
      1456 |     });

      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1453:11)

  ● databricks › string_agg › works with order desc - databricks

    SQL Generated:
      WITH __stage0 AS (
        SELECT
           base.`name` as `name`
        FROM malloytest.aircraft as base
        WHERE base.`name` RLIKE '.*FLY.*'
        GROUP BY 1
        ORDER BY 1 desc NULLS LAST
        LIMIT 3
      )
      SELECT
         ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST(base.`name`)), ',') as `f`
      FROM __stage0 as base

    Expected {f: "YANKEE FLYING CLUB INC,WILSON FLYING SERVICE INC,WESTCHESTER FLYING CLUB"} Got: "WESTCHESTER FLYING CLUB,WILSON FLYING SERVICE INC,YANKEE FLYING CLUB INC"

      1479 |       } -> {
      1480 |         aggregate: f is string_agg(name, ',') { order_by: name desc }
    > 1481 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1482 |         f: 'YANKEE FLYING CLUB INC,WILSON FLYING SERVICE INC,WESTCHESTER FLYING CLUB',
      1483 |       });
      1484 |     });

      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1481:11)

  ● databricks › string_agg › works with fanout and order_by - databricks

    query.run failed:
    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,base.`state`,base.`popular_name`,base.`state`))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

    SQL: SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,base.`state`,base.`popular_name`,base.`state`))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,base.`state`,base.`popular_name`,base.`state`))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

      1501 |           order_by: popular_name, state
      1502 |         }
    > 1503 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1504 |         s: 'IA,LA,MN,AL,AR,IN,ME,MT,NC,AZ,CA,CO,CT,FL,GA,HI,IL,KS,KY,MA,MO,NJ,NM,NV,NY,OH,OK,PA,RI,TN,TX,WV,WY,DC,MS,SC,ID,NE,UT,VA,AK,DE,MD,MI,ND,NH,OR,SD,VT,WA,WI',
      1505 |         c: 51,
      1506 |       });

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1503:11)

  ● databricks › string_agg › works with fanout - databricks

    query.run failed:
    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o'))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

    SQL: SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o'))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), ', ') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o'))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

      1517 |         aggregate: c is state_facts2.count()
      1518 |         aggregate: s is string_agg('o')
    > 1519 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1520 |         s: 'o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o,o',
      1521 |         c: 51,
      1522 |       });

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1519:11)

  ● databricks › string_agg › works with fanout and separator - databricks

    query.run failed:
    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), '') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o',''))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

    SQL: SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), '') as value
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o',''))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

    [PARSE_SYNTAX_ERROR] Syntax error at or near '->'. SQLSTATE: 42601 (line 4, pos 56)

    == SQL ==
    SELECT
       COUNT(DISTINCT state_facts2_0.`__distinct_key`) as `c`,
       (
          SELECT ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST((a::json->>'f2'))), '') as value
    --------------------------------------------------------^^^
          FROM (
            SELECT UNNEST(array_agg(distinct row_to_json(row(base.`__distinct_key`,'o',''))::text)) a
          ) a
        ) as `s`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
     LEFT JOIN (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) AS state_facts2_0
      ON state_facts2_0.`state`=base.`state`

      1533 |         aggregate: c is state_facts2.count()
      1534 |         aggregate: s is string_agg('o', '')
    > 1535 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1536 |         s: 'ooooooooooooooooooooooooooooooooooooooooooooooooooo',
      1537 |         c: 51,
      1538 |       });

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1535:11)

  ● databricks › string_agg_distinct › actually distincts - databricks

    SQL Generated:
      SELECT
         ARRAY_JOIN(ARRAY_SORT(COLLECT_SET(aircraft_0.`name`)), ', ') as `f_dist`,
         ARRAY_JOIN(ARRAY_SORT(COLLECT_LIST(aircraft_0.`name`)), ', ') as `f_all`
      FROM malloytest.aircraft_models as base
       LEFT JOIN malloytest.aircraft AS aircraft_0
        ON base.`aircraft_model_code`=aircraft_0.`aircraft_model_code`
      WHERE aircraft_0.`name` IN ('RAYTHEON AIRCRAFT COMPANY','FOWLER IRA R DBA')

    Expected {f_dist: "FOWLER IRA R DBA,RAYTHEON AIRCRAFT COMPANY"} Got: "FOWLER IRA R DBA, RAYTHEON AIRCRAFT COMPANY"
    Expected {f_all: "FOWLER IRA R DBA,FOWLER IRA R DBA,RAYTHEON AIRCRAFT COMPANY,RAYTHEON AIRCRAFT COMPANY"} Got: "FOWLER IRA R DBA, FOWLER IRA R DBA, RAYTHEON AIRCRAFT COMPANY, RAYTHEON AIRCRAFT COMPANY"

      1580 |           aggregate: f_dist is aircraft.name.string_agg_distinct() { order_by: asc }
      1581 |           aggregate: f_all is aircraft.name.string_agg() { order_by: aircraft.name }
    > 1582 |       }`).malloyResultMatches(runtime, {
           |           ^
      1583 |         f_dist: 'FOWLER IRA R DBA,RAYTHEON AIRCRAFT COMPANY',
      1584 |         f_all:
      1585 |           'FOWLER IRA R DBA,FOWLER IRA R DBA,RAYTHEON AIRCRAFT COMPANY,RAYTHEON AIRCRAFT COMPANY',

      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1582:11)

  ● databricks › string_agg_distinct › works with order desc - databricks

    SQL Generated:
      WITH __stage0 AS (
        SELECT
           base.`name` as `name`
        FROM malloytest.aircraft as base
        WHERE base.`name` RLIKE '.*FLY.*'
        GROUP BY 1
        ORDER BY 1 desc NULLS LAST
        LIMIT 3
      )
      SELECT
         ARRAY_JOIN(ARRAY_SORT(COLLECT_SET(base.`name`)), ',') as `f`
      FROM __stage0 as base

    Expected {f: "YANKEE FLYING CLUB INC,WILSON FLYING SERVICE INC,WESTCHESTER FLYING CLUB"} Got: "WESTCHESTER FLYING CLUB,WILSON FLYING SERVICE INC,YANKEE FLYING CLUB INC"

      1640 |       } -> {
      1641 |         aggregate: f is string_agg_distinct(name, ',') { order_by: desc }
    > 1642 |       }`).malloyResultMatches(expressionModel, {
           |           ^
      1643 |         f: 'YANKEE FLYING CLUB INC,WILSON FLYING SERVICE INC,WESTCHESTER FLYING CLUB',
      1644 |       });
      1645 |     });

      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1642:11)

  ● databricks › partition_by › works - databricks

    query.run failed: [MISSING_AGGREGATION] The non-aggregating expression "dep_time" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(dep_time)" if you do not care which of the values within a group is returned. SQLSTATE: 42803
    SQL: SELECT
       EXTRACT(year FROM base.`dep_time`) as `yr`,
       EXTRACT(quarter FROM base.`dep_time`) as `qtr`,
       COUNT(1) as `qtr_flights`,
       LAG((COUNT(1))) OVER(PARTITION BY (EXTRACT(quarter FROM base.`dep_time`)) ORDER BY (EXTRACT(year FROM base.`dep_time`)) ASC ) as `last_yr_qtr_flights`
    FROM malloytest.flights as base
    WHERE base.`dep_time`<timestamp '2002-01-01 00:00:00'
    GROUP BY 1,2
    ORDER BY 1 ASC NULLS LAST,2 ASC NULLS LAST

    Error: [MISSING_AGGREGATION] The non-aggregating expression "dep_time" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(dep_time)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      1688 |         order_by: yr, qtr
      1689 |         where: dep_time < @2002
    > 1690 |       }`).malloyResultMatches(expressionModel, [
           |           ^
      1691 |         {yr: 2000, qtr: 1, qtr_flights: 12148, last_yr_qtr_flights: null},
      1692 |         {yr: 2000, qtr: 2, qtr_flights: 11599, last_yr_qtr_flights: null},
      1693 |         {yr: 2000, qtr: 3, qtr_flights: 12075, last_yr_qtr_flights: null},

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1690:11)

  ● databricks › partition_by › works with aggregate - databricks

    query.run failed: [MISSING_AGGREGATION] The non-aggregating expression "state" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(state)" if you do not care which of the values within a group is returned. SQLSTATE: 42803
    SQL: SELECT
       COUNT(1) as `c`,
       SUBSTR(base.`state`, CASE WHEN 1 < 0 THEN LENGTH(base.`state`) + 1 + 1 ELSE 1 END, 1) as `l`,
       LAG((SUBSTR(base.`state`, CASE WHEN 1 < 0 THEN LENGTH(base.`state`) + 1 + 1 ELSE 1 END, 1))) OVER(PARTITION BY (COUNT(1))  ORDER BY  SUBSTR(base.`state`, CASE WHEN 1 < 0 THEN LENGTH(base.`state`) + 1 + 1 ELSE 1 END, 1) ASC NULLS LAST ) as `prev`
    FROM malloytest.state_facts as base
    GROUP BY 2
    ORDER BY 2 ASC NULLS LAST
    LIMIT 5

    Error: [MISSING_AGGREGATION] The non-aggregating expression "state" is based on columns which are not participating in the GROUP BY clause.
    Add the columns or the expression to the GROUP BY, aggregate the expression, or use "any_value(state)" if you do not care which of the values within a group is returned. SQLSTATE: 42803

      1712 |         order_by: l
      1713 |         limit: 5
    > 1714 |       }`).malloyResultMatches(expressionModel, [
           |           ^
      1715 |         {l: 'A', c: 4, prev: null},
      1716 |         {l: 'C', c: 3, prev: null},
      1717 |         {l: 'D', c: 2, prev: null},

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/functions.spec.ts:1714:11)

FAIL test/src/databases/all/expr.spec.ts (54.917 s)
  ● databricks › double turtle

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `TO_JSONB` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 37 pos 4
    SQL: WITH __stage0 AS (
      SELECT
        group_set,
        CASE WHEN group_set=0 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__0`,
        CASE WHEN group_set IN (1,2,3) THEN
          base.`popular_name`
          END as `popular_name__1`,
        CASE WHEN group_set=1 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__1`,
        CASE WHEN group_set=2 THEN
          base.`state`
          END as `state__2`,
        CASE WHEN group_set=2 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__2`,
        CASE WHEN group_set=3 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `inline_sum__3`
      FROM malloytest.state_facts as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,3,1)) as group_set)
      GROUP BY 1,3,5
    )
    , __stage1 AS (
      SELECT
        CASE WHEN group_set=2 THEN 1 WHEN group_set=3 THEN 1 ELSE group_set END as group_set,
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count__0`,
        CASE WHEN group_set IN (1,2,3) THEN
          `popular_name__1`
          END as `popular_name__1`,
        GET((ARRAY_AGG(`airport_count__1`) FILTER (WHERE group_set=1 AND `airport_count__1` IS NOT NULL)),0) as `airport_count__1`,
        SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=2 THEN STRUCT(
          `airport_count__2`::BIGINT as `airport_count`,
          `state__2` as `state`) END), ARRAY()), false), 1, 2) as `by_state__1`,
        TO_JSONB((ARRAY_AGG((SELECT __x FROM (SELECT
          `inline_sum__3`::BIGINT as `inline_sum`) as __x)) FILTER (WHERE group_set=3))[1]) as `inline__1`
      FROM __stage0
      GROUP BY 1,3
    )
    SELECT
      GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count`,
      SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=1 THEN STRUCT(
        `airport_count__1`::BIGINT as `airport_count`,
        `popular_name__1` as `popular_name`,
        `by_state__1` as `by_state`,
        `inline__1` as `inline`) END), ARRAY()), false), 1, 3) as `o`
    FROM __stage1

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `TO_JSONB` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 37 pos 4

      169 |         }
      170 |       }
    > 171 |     `).malloyResultMatches(expressionModel, {
          |        ^
      172 |       'o.by_state.state': 'TX',
      173 |       'o.by_state.airport_count': 1845,
      174 |       'o.airport_count': 11146,

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/expr.spec.ts:171:8)

  ● databricks › double turtle - pipeline

    query.run failed: [DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve "explode(to_json(outer(base.o)))" due to data type mismatch: The first parameter requires the ("ARRAY" or "MAP") type, however "to_json(outer(base.o))" has the type "STRING". SQLSTATE: 42K09; line 49 pos 37
    SQL: WITH __stage0 AS (
      SELECT
        group_set,
        CASE WHEN group_set=0 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__0`,
        CASE WHEN group_set IN (1,2) THEN
          base.`popular_name`
          END as `popular_name__1`,
        CASE WHEN group_set=1 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__1`,
        CASE WHEN group_set=2 THEN
          base.`state`
          END as `state__2`,
        CASE WHEN group_set=2 THEN
          COALESCE(SUM(base.`airport_count`),0)
          END as `airport_count__2`
      FROM malloytest.state_facts as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,3,5
    )
    , __stage1 AS (
      SELECT
        CASE WHEN group_set=2 THEN 1 ELSE group_set END as group_set,
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count__0`,
        CASE WHEN group_set IN (1,2) THEN
          `popular_name__1`
          END as `popular_name__1`,
        GET((ARRAY_AGG(`airport_count__1`) FILTER (WHERE group_set=1 AND `airport_count__1` IS NOT NULL)),0) as `airport_count__1`,
        SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=2 THEN STRUCT(
          `airport_count__2`::BIGINT as `airport_count`,
          `state__2` as `state`) END), ARRAY()), false), 1, 2) as `by_state__1`
      FROM __stage0
      GROUP BY 1,3
    )
    , __stage2 AS (
      SELECT
        GET((ARRAY_AGG(`airport_count__0`) FILTER (WHERE group_set=0 AND `airport_count__0` IS NOT NULL)),0) as `airport_count`,
        SLICE(SORT_ARRAY(COALESCE(ARRAY_AGG(CASE WHEN group_set=1 THEN STRUCT(
          `airport_count__1`::BIGINT as `airport_count`,
          `popular_name__1` as `popular_name`,
          `by_state__1` as `by_state`) END), ARRAY()), false), 1, 3) as `o`
      FROM __stage1
    )
    SELECT
       COALESCE(SUM(CAST(get_json_object(by_state_0, '$.airport_count') AS DOUBLE)),0) as `airport_count`
    FROM __stage2 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`o`)) as value) as o_0 ON true
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(to_json(o_0.by_state))) as value) as by_state_0 ON true

    Error: [DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve "explode(to_json(outer(base.o)))" due to data type mismatch: The first parameter requires the ("ARRAY" or "MAP") type, however "to_json(outer(base.o))" has the type "STRING". SQLSTATE: 42K09; line 49 pos 37

      195 |         aggregate: o.by_state.airport_count.sum()
      196 |       }
    > 197 |     `).malloyResultMatches(expressionModel, {
          |        ^
      198 |       'airport_count': 5023,
      199 |     });
      200 |   });

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/expr.spec.ts:197:8)

FAIL test/src/databases/all/composite_sources.spec.ts (34.808 s)
  ● databricks › composite with each

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 6 pos 45
    SQL: SELECT
       COALESCE((SUM(DISTINCT (CAST(conv(substring(md5(concat(base.`__distinct_key`, '')), 1, 16), 16, 10) AS DECIMAL(38,0)) * 4294967296 + CAST(conv(substring(md5(concat(base.`__distinct_key`, '')), 16, 8), 16, 10) AS DECIMAL(38,0))) + COALESCE(0, 0)) - SUM(DISTINCT (CAST(conv(substring(md5(concat(base.`__distinct_key`, '')), 1, 16), 16, 10) AS DECIMAL(38,0)) * 4294967296 + CAST(conv(substring(md5(concat(base.`__distinct_key`, '')), 16, 8), 16, 10) AS DECIMAL(38,0))))),0) as `foo`,
       1 as `bar`,
       CAST(get_json_object(arr_0, '$.value') AS DOUBLE) as `each`
    FROM (SELECT uuid() as `__distinct_key`, x.*  FROM malloytest.state_facts as x) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(JSONB_BUILD_ARRAY(1,2,3)) as value) as arr_0 ON true
    GROUP BY 2,3
    ORDER BY 1 desc NULLS LAST

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 6 pos 45

      283 |       }
      284 |       run: x -> { aggregate: foo; group_by: bar, arr.each }
    > 285 |     `).malloyResultMatches(runtime, {foo: 0});
          |        ^
      286 |   });
      287 |   it('complex nesting composite without join', async () => {
      288 |     await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/composite_sources.spec.ts:285:8)

FAIL test/src/databases/all/db_index.spec.ts (22.04 s)
  ● basic index  - databricks


    [PARSE_SYNTAX_ERROR] Syntax error at or near 'SYSTEM_ROWS': missing ')'. SQLSTATE: 42601 (line 2, pos 63)

    == SQL ==
    CREATE TEMPORARY TABLE IF NOT EXISTS tt3ad65bcab16b5342b4b7de06835adfe4 AS (WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.airports TABLESAMPLE SYSTEM_ROWS(50000)) as x limit 100000 )
    ---------------------------------------------------------------^^^
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'act_date'
          WHEN 1 THEN 'aero_cht'
          WHEN 2 THEN 'c_ldg_rts'
          WHEN 3 THEN 'cbd_dir'
          WHEN 4 THEN 'cbd_dist'
          WHEN 5 THEN 'cert'
          WHEN 6 THEN 'city'
          WHEN 7 THEN 'cntl_twr'
          WHEN 8 THEN 'code'
          WHEN 9 THEN 'county'
          WHEN 10 THEN 'cust_intl'
          WHEN 11 THEN 'elevation'
          WHEN 12 THEN 'faa_dist'
          WHEN 13 THEN 'faa_region'
          WHEN 14 THEN 'fac_type'
          WHEN 15 THEN 'fac_use'
          WHEN 16 THEN 'fed_agree'
          WHEN 17 THEN 'full_name'
          WHEN 18 THEN 'id'
          WHEN 19 THEN 'joint_use'
          WHEN 20 THEN 'latitude'
          WHEN 21 THEN 'longitude'
          WHEN 22 THEN 'major'
          WHEN 23 THEN 'mil_rts'
          WHEN 24 THEN 'own_type'
          WHEN 25 THEN 'site_number'
          WHEN 26 THEN 'state'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'act_date'
          WHEN 1 THEN 'aero_cht'
          WHEN 2 THEN 'c_ldg_rts'
          WHEN 3 THEN 'cbd_dir'
          WHEN 4 THEN 'cbd_dist'
          WHEN 5 THEN 'cert'
          WHEN 6 THEN 'city'
          WHEN 7 THEN 'cntl_twr'
          WHEN 8 THEN 'code'
          WHEN 9 THEN 'county'
          WHEN 10 THEN 'cust_intl'
          WHEN 11 THEN 'elevation'
          WHEN 12 THEN 'faa_dist'
          WHEN 13 THEN 'faa_region'
          WHEN 14 THEN 'fac_type'
          WHEN 15 THEN 'fac_use'
          WHEN 16 THEN 'fed_agree'
          WHEN 17 THEN 'full_name'
          WHEN 18 THEN 'id'
          WHEN 19 THEN 'joint_use'
          WHEN 20 THEN 'latitude'
          WHEN 21 THEN 'longitude'
          WHEN 22 THEN 'major'
          WHEN 23 THEN 'mil_rts'
          WHEN 24 THEN 'own_type'
          WHEN 25 THEN 'site_number'
          WHEN 26 THEN 'state'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
          WHEN 2 THEN 'string'
          WHEN 3 THEN 'string'
          WHEN 4 THEN 'number'
          WHEN 5 THEN 'string'
          WHEN 6 THEN 'string'
          WHEN 7 THEN 'string'
          WHEN 8 THEN 'string'
          WHEN 9 THEN 'string'
          WHEN 10 THEN 'string'
          WHEN 11 THEN 'number'
          WHEN 12 THEN 'string'
          WHEN 13 THEN 'string'
          WHEN 14 THEN 'string'
          WHEN 15 THEN 'string'
          WHEN 16 THEN 'string'
          WHEN 17 THEN 'string'
          WHEN 18 THEN 'number'
          WHEN 19 THEN 'string'
          WHEN 20 THEN 'number'
          WHEN 21 THEN 'number'
          WHEN 22 THEN 'string'
          WHEN 23 THEN 'string'
          WHEN 24 THEN 'string'
          WHEN 25 THEN 'string'
          WHEN 26 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN base.`act_date`
          WHEN 1 THEN base.`aero_cht`
          WHEN 2 THEN base.`c_ldg_rts`
          WHEN 3 THEN base.`cbd_dir`
          WHEN 5 THEN base.`cert`
          WHEN 6 THEN base.`city`
          WHEN 7 THEN base.`cntl_twr`
          WHEN 8 THEN base.`code`
          WHEN 9 THEN base.`county`
          WHEN 10 THEN base.`cust_intl`
          WHEN 12 THEN base.`faa_dist`
          WHEN 13 THEN base.`faa_region`
          WHEN 14 THEN base.`fac_type`
          WHEN 15 THEN base.`fac_use`
          WHEN 16 THEN base.`fed_agree`
          WHEN 17 THEN base.`full_name`
          WHEN 19 THEN base.`joint_use`
          WHEN 22 THEN base.`major`
          WHEN 23 THEN base.`mil_rts`
          WHEN 24 THEN base.`own_type`
          WHEN 25 THEN base.`site_number`
          WHEN 26 THEN base.`state`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''    WHEN 4 THEN CONCAT(MIN(CAST(base.`cbd_dist` as STRING)),' to ',CAST(MAX(base.`cbd_dist`) as STRING))
          WHEN 11 THEN CONCAT(MIN(CAST(base.`elevation` as STRING)),' to ',CAST(MAX(base.`elevation`) as STRING))
          WHEN 18 THEN CONCAT(MIN(CAST(base.`id` as STRING)),' to ',CAST(MAX(base.`id`) as STRING))
          WHEN 20 THEN CONCAT(MIN(CAST(base.`latitude` as STRING)),' to ',CAST(MAX(base.`latitude`) as STRING))
          WHEN 21 THEN CONCAT(MIN(CAST(base.`longitude` as STRING)),' to ',CAST(MAX(base.`longitude`) as STRING))
        END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,27,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    SELECT
      `fieldName`,
      `fieldPath`,
      `fieldType`,
      COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
      `weight`
    FROM __stage1
    )

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● index value map  - databricks

    expect(received).toBe(expected) // Object.is equality

    Expected: "WASHINGTON"
    Received: "--PUERTO RICO"

      83 |     expect(result).toBeDefined();
      84 |     if (result !== undefined) {
    > 85 |       expect(result[4].values[0].fieldValue).toBe('WASHINGTON');
         |                                              ^
      86 |       expect(result[4].values[0].weight).toBe(214);
      87 |     }
      88 |   });

      at Object.<anonymous> (test/src/databases/all/db_index.spec.ts:85:46)

  ● index rows count - databricks

    query.run failed:
    [PARSE_SYNTAX_ERROR] Syntax error at or near 'SYSTEM_ROWS'. SQLSTATE: 42601 (line 2, pos 66)

    == SQL ==
    WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.state_facts TABLESAMPLE SYSTEM_ROWS(10)) as x limit 100000 )
    ------------------------------------------------------------------^^^
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`state`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

    SQL: WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.state_facts TABLESAMPLE SYSTEM_ROWS(10)) as x limit 100000 )
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`state`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

    [PARSE_SYNTAX_ERROR] Syntax error at or near 'SYSTEM_ROWS'. SQLSTATE: 42601 (line 2, pos 66)

    == SQL ==
    WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.state_facts TABLESAMPLE SYSTEM_ROWS(10)) as x limit 100000 )
    ------------------------------------------------------------------^^^
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'state'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`state`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

      108 |         } -> {index:one, state; sample: 10 }
      109 |             -> {select: fieldName, weight, fieldValue; order_by: 2 desc; where: fieldName = 'one'}
    > 110 |       `).malloyResultMatches(runtime, {fieldName: 'one', weight: 10});
          |          ^
      111 |   });
      112 |
      113 |   it.when(databaseName !== 'trino' && databaseName !== 'presto')(

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/db_index.spec.ts:110:10)

  ● index rows count - databricks

    query.run failed:
    [PARSE_SYNTAX_ERROR] Syntax error at or near 'SYSTEM'. SQLSTATE: 42601 (line 2, pos 62)

    == SQL ==
    WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.flights TABLESAMPLE SYSTEM (50)) as x limit 100000 )
    --------------------------------------------------------------^^^
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`tail_num`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

    SQL: WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.flights TABLESAMPLE SYSTEM (50)) as x limit 100000 )
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`tail_num`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

    [PARSE_SYNTAX_ERROR] Syntax error at or near 'SYSTEM'. SQLSTATE: 42601 (line 2, pos 62)

    == SQL ==
    WITH __stage0 AS (
      SELECT * from (SELECT * FROM malloytest.flights TABLESAMPLE SYSTEM (50)) as x limit 100000 )
    --------------------------------------------------------------^^^
    , __stage1 AS (
      SELECT
        group_set,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldName`,
        CASE group_set
          WHEN 0 THEN 'one'
          WHEN 1 THEN 'tail_num'
        END as `fieldPath`,
        CASE group_set
          WHEN 0 THEN 'string'
          WHEN 1 THEN 'string'
        END as `fieldType`,  CASE group_set WHEN 99999 THEN CAST(NULL as STRING)
          WHEN 0 THEN 'one'
          WHEN 1 THEN base.`tail_num`
        END as `fieldValue`,
       COUNT(*) as `weight`,
        CASE group_set
          WHEN 99999 THEN ''  END as `fieldRange`
      FROM __stage0 as base
      CROSS JOIN (SELECT EXPLODE(SEQUENCE(0,2,1)) as group_set)
      GROUP BY 1,2,3,4,5
    )
    , __stage2 AS (
      SELECT
        `fieldName`,
        `fieldPath`,
        `fieldType`,
        COALESCE(`fieldValue`, `fieldRange`) as `fieldValue`,
        `weight`
      FROM __stage1
    )
    SELECT
       base.`fieldName` as `fieldName`,
       base.`weight` as `weight`,
       base.`fieldValue` as `fieldValue`
    FROM __stage2 as base
    WHERE base.`fieldName`='one'
    ORDER BY 2 desc NULLS LAST

      119 |       } -> {index:one, tail_num; sample: 50% }
      120 |         -> {select: fieldName, weight, fieldValue; order_by: 2 desc; where: fieldName = 'one'}
    > 121 |     `).malloyResultMatches(runtime, {fieldName: 'one'});
          |        ^
      122 |       // Hard to get consistent results here so just check that we get a value back.
      123 |     }
      124 |   );

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/db_index.spec.ts:121:8)

FAIL test/src/databases/all/compound-atomic.spec.ts (38.722 s)
  ● compound atomic datatypes databricks › simple arrays › array literal dialect function

    Could not prepare query to run: Error(s) compiling model:
    FILE: internal://internal.malloy
    line 2: Invalid SQL, BRIAN SELECT Error fetching schema for
              SELECT JSONB_BUILD_ARRAY(2,4,6,8) AS `evens`
            : Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 13
      |           run: databricks.sql("""
      |                               ^

      94 |       test('array literal dialect function', async () => {
      95 |         await expect(`
    > 96 |           run: ${evens}`).malloyResultMatches(runtime, {
         |                           ^
      97 |           evens: evensObj,
      98 |         });
      99 |       });

      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:96:27)

  ● compound atomic datatypes databricks › simple arrays › select array

    Could not prepare query to run: Error(s) compiling model:
    FILE: internal://internal.malloy
    line 3: Invalid SQL, BRIAN SELECT Error fetching schema for
              SELECT JSONB_BUILD_ARRAY(2,4,6,8) AS `evens`
            : Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 13
      |           run: databricks.sql("""
      |                               ^
    line 5: 'evens' is not defined
      |     """)->{select: nn is evens}
      |                          ^

      102 |           # test.verbose
      103 |           run: ${evens}->{select: nn is evens}
    > 104 |           `).malloyResultMatches(runtime, {nn: evensObj});
          |              ^
      105 |       });
      106 |       test.when(canReadCompoundSchema)(
      107 |         'schema read allows array-un-nest on each',

      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:104:14)

  ● compound atomic datatypes databricks › simple arrays › array can be passed to !function

    expect(received).not.toEqual(expected) // deep equality

    Expected: not "Dialect 'databricks' missing array length function in nameOfArrayLenFunction"

      129 |         const missing = `Dialect '${dialect}' missing array length function in nameOfArrayLenFunction`;
      130 |         const fn = nameOfArrayLenFunction[dialect] ?? missing;
    > 131 |         expect(fn).not.toEqual(missing);
          |                        ^
      132 |         await expect(
      133 |           `run: ${evens}->{ select: nby2 is ${fn}!number(evens); } `
      134 |         ).malloyResultMatches(runtime, {nby2: evensObj.length});

      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:131:24)

  ● compound atomic datatypes databricks › simple arrays › array.each in source

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45
    SQL: SELECT
       (CAST(get_json_object(d4_0, '$.value') AS DOUBLE)) as `die_roll`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(JSONB_BUILD_ARRAY(1,2,3,4)) as value) as d4_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45

      139 |           extend { dimension: d4 is [1,2,3,4] }
      140 |           -> { select: die_roll is d4.each }
    > 141 |         `).malloyResultMatches(runtime, [
          |            ^
      142 |           {die_roll: 1},
      143 |           {die_roll: 2},
      144 |           {die_roll: 3},

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:141:12)

  ● compound atomic datatypes databricks › simple arrays › array.each in extend block

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45
    SQL: SELECT
       (CAST(get_json_object(d4_0, '$.value') AS DOUBLE)) as `die_roll`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(JSONB_BUILD_ARRAY(1,2,3,4)) as value) as d4_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45

      152 |             select: die_roll is d4.each
      153 |           }
    > 154 |         `).malloyResultMatches(runtime, [
          |            ^
      155 |           {die_roll: 1},
      156 |           {die_roll: 2},
      157 |           {die_roll: 3},

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:154:12)

  ● compound atomic datatypes databricks › simple arrays › array stored field with special chars in name

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_ARRAY(1) as `_'_`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       (CAST(get_json_object(__o___0, '$.value') AS DOUBLE)) as `num`
    FROM __stage0 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(base.`_'_`) as value) as __o___0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      190 |             ->{ select: ${qname} is [1]}
      191 |             -> { select: num is ${qname}.each }`;
    > 192 |             await expect(malloySrc).malloyResultMatches(runtime, {});
          |                                     ^
      193 |             const result = await runtime.loadQuery(malloySrc).run();
      194 |             const ok =
      195 |               result.data.path(0, 'num').value === 1

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:192:37)

  ● compound atomic datatypes databricks › simple arrays › bare array of array

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3
    SQL: SELECT
       JSONB_BUILD_ARRAY((JSONB_BUILD_ARRAY(1,2))) as `aoa`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      241 |         await expect(`
      242 |           run: ${empty} -> { select: aoa is [[1,2]] }
    > 243 |         `).malloyResultMatches(runtime, {aoa: [[1, 2]]});
          |            ^
      244 |       });
      245 |       test.when(supportsNestedArrays)('each.each array of array', async () => {
      246 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:243:12)

  ● compound atomic datatypes databricks › simple arrays › each.each array of array

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45
    SQL: SELECT
       CAST(get_json_object(each_0, '$.value') AS DOUBLE) as `each`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(JSONB_BUILD_ARRAY((JSONB_BUILD_ARRAY(1,2)))) as value) as aoa_0 ON true
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(aoa_0.value)) as value) as each_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 45

      246 |         await expect(`
      247 |           run: ${empty} extend { dimension: aoa is [[1,2]] } -> { select: aoa.each.each }
    > 248 |         `).malloyResultMatches(runtime, [{each: 1}, {each: 2}]);
          |            ^
      249 |       });
      250 |     });
      251 |     describe('record', () => {

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:248:12)

  ● compound atomic datatypes databricks › record › record literal object

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3
    SQL: SELECT
       JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
    FROM (select 0 as o) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      263 |           run: ${conName}.sql("select 0 as o")
      264 |           -> { select: ${malloySizes}}
    > 265 |         `).malloyResultMatches(runtime, rec_eq());
          |            ^
      266 |       });
      267 |       // can't use special chars in column names in bq
      268 |       test.when(conName !== 'bigquery')(

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:265:12)

  ● compound atomic datatypes databricks › record › special character in record property name


    [PARSE_SYNTAX_ERROR] Syntax error at or near '_'. SQLSTATE: 42601 (line 2, pos 14)

    == SQL ==
    SELECT
       'ok' as `_`_`
    --------------^^^
    FROM (SELECT 0 as z) as base

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● compound atomic datatypes databricks › record › record stored in field with special chars in name

    [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)

  ● compound atomic datatypes databricks › record › simple record.property access

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
      FROM (SELECT 0 AS O) as base
    )
    SELECT
       CAST(get_json_object(base.`sizes`, '$.s') AS DOUBLE) as `small`
    FROM __stage0 as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      315 |       test('simple record.property access', async () => {
      316 |         await expect(`
    > 317 |           run: ${sizes} -> { select: small is sizes.s }`).malloyResultMatches(
          |                                                           ^
      318 |           runtime,
      319 |           {small: 0}
      320 |         );

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:317:59)

  ● compound atomic datatypes databricks › record › record can be selected

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
      FROM (SELECT 0 AS O) as base
    )
    SELECT
       base.`sizes` as `sizes`
    FROM __stage0 as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      339 |           `
      340 |           run: ${sizes} -> { select: sizes }`
    > 341 |         ).malloyResultMatches(runtime, rec_eq());
          |           ^
      342 |       });
      343 |       test('record literal can be selected', async () => {
      344 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:341:11)

  ● compound atomic datatypes databricks › record › record literal can be selected

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
      FROM (SELECT 0 AS O) as base
    )
    SELECT
       base.`sizes` as `record`
    FROM __stage0 as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      344 |         await expect(`
      345 |           run: ${sizes} -> { select: record is sizes }
    > 346 |         `).malloyResultMatches(runtime, rec_eq('record'));
          |            ^
      347 |       });
      348 |       test('select record literal from a source', async () => {
      349 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:346:12)

  ● compound atomic datatypes databricks › record › select record literal from a source

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3
    SQL: SELECT
       JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3) as `sizes`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      352 |             select: sizes
      353 |           }
    > 354 |         `).malloyResultMatches(runtime, rec_eq());
          |            ^
      355 |       });
      356 |       test('computed record.property from a source', async () => {
      357 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:354:12)

  ● compound atomic datatypes databricks › record › computed record.property from a source

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 24
    SQL: SELECT
       CAST(get_json_object(JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3), '$.s') AS DOUBLE) as `small`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 24

      359 |             extend { dimension: record is {s is 0, m is 1, l is 2, xl is 3} }
      360 |             -> { select: small is record.s }
    > 361 |         `).malloyResultMatches(runtime, {small: 0});
          |            ^
      362 |       });
      363 |       test('record.property from an extend block', async () => {
      364 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:361:12)

  ● compound atomic datatypes databricks › record › record.property from an extend block

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 24
    SQL: SELECT
       CAST(get_json_object(JSONB_BUILD_OBJECT('s',0, 'm',1, 'l',2, 'xl',3), '$.s') AS DOUBLE) as `small`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 24

      367 |             select: small is record.s
      368 |           }
    > 369 |         `).malloyResultMatches(runtime, {small: 0});
          |            ^
      370 |       });
      371 |       test('simple each on array property inside record', async () => {
      372 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:369:12)

  ● compound atomic datatypes databricks › record › simple each on array property inside record

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('odds',(JSONB_BUILD_ARRAY(1,3)), 'evens',(JSONB_BUILD_ARRAY(2,4))) as `nums`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       CAST(get_json_object(odds_0, '$.value') AS DOUBLE) as `odd`
    FROM __stage0 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`nums`.odds)) as value) as odds_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      373 |           run: ${empty} -> { select: nums is { odds is [1,3], evens is [2,4]} }
      374 |           -> { select: odd is nums.odds.value }
    > 375 |         `).malloyResultMatches(runtime, [{odd: 1}, {odd: 3}]);
          |            ^
      376 |       });
      377 |       test('each on array property inside record from source', async () => {
      378 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:375:12)

  ● compound atomic datatypes databricks › record › each on array property inside record from source

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 53
    SQL: SELECT
       (CAST(get_json_object(odds_0, '$.value') AS DOUBLE)) as `odd`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(JSONB_BUILD_OBJECT('odds',(JSONB_BUILD_ARRAY(1,3)), 'evens',(JSONB_BUILD_ARRAY(2,4))).odds)) as value) as odds_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 53

      379 |           run: ${empty} extend { dimension: nums is { odds is [1,3], evens is [2,4]} }
      380 |           -> { select: odd is nums.odds.each }
    > 381 |         `).malloyResultMatches(runtime, [{odd: 1}, {odd: 3}]);
          |            ^
      382 |       });
      383 |       const abc = "rec is {a is 'a', bc is {b is 'b', c is 'c'}}";
      384 |       test('record with a record property', async () => {

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:381:12)

  ● compound atomic datatypes databricks › record › record with a record property

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))) as `rec`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       get_json_object(base.`rec`, '$.a') as `a`,
       get_json_object(to_json(base.`rec`.bc), '$.b') as `b`,
       get_json_object(to_json(base.`rec`.bc), '$.c') as `c`
    FROM __stage0 as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      386 |           run: ${empty} -> { select: ${abc} }
      387 |           -> { select: rec.a, rec.bc.b, rec.bc.c }
    > 388 |         `).malloyResultMatches(runtime, {a: 'a', b: 'b', c: 'c'});
          |            ^
      389 |       });
      390 |       test('record in source with a record property', async () => {
      391 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:388:12)

  ● compound atomic datatypes databricks › record › record in source with a record property

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 19
    SQL: SELECT
       get_json_object(JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))), '$.a') as `a`,
       get_json_object(to_json(JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))).bc), '$.b') as `b`,
       get_json_object(to_json(JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))).bc), '$.c') as `c`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 19

      392 |           run: ${empty} extend { dimension: ${abc} }
      393 |           -> { select: rec.a, rec.bc.b, rec.bc.c }
    > 394 |         `).malloyResultMatches(runtime, {a: 'a', b: 'b', c: 'c'});
          |            ^
      395 |       });
      396 |       test('record dref in source with a record property', async () => {
      397 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:394:12)

  ● compound atomic datatypes databricks › record › record dref in source with a record property

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 47
    SQL: SELECT
       CASE WHEN true THEN get_json_object(to_json(JSONB_BUILD_OBJECT('a','a', 'bc',(JSONB_BUILD_OBJECT('b','b', 'c','c'))).bc), '$.b') ELSE 'b' END as `b`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_OBJECT` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 47

      398 |           run: ${empty} extend { dimension: ${abc} }
      399 |           -> { select: b is pick rec.bc.b when true else 'b' }
    > 400 |         `).malloyResultMatches(runtime, {b: 'b'});
          |            ^
      401 |       });
      402 |       test.todo('array or record where first entries are null');
      403 |     });

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:400:12)

  ● compound atomic datatypes databricks › repeated record › select repeated record from literal dialect functions

    Could not prepare query to run: Error(s) compiling model:
    FILE: internal://internal.malloy
    line 2: Invalid SQL, BRIAN SELECT Error fetching schema for  SELECT JSONB_BUILD_ARRAY(JSONB_BUILD_OBJECT('a',10, 'b',11),JSONB_BUILD_OBJECT('a',20, 'b',21)) AS `ab` : Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 14
      |           run: databricks.sql(""" SELECT JSONB_BUILD_ARRAY(JSONB_BUILD_OBJECT('a',10, 'b',11),JSONB_BUILD_OBJECT('a',20, 'b',21)) AS `ab` """)
      |                               ^

      444 |         await expect(`
      445 |           run: ${conName}.sql(""" ${selectAB('ab')} """)
    > 446 |         `).malloyResultMatches(runtime, {ab: ab_eq});
          |            ^
      447 |       });
      448 |       test('repeat record from malloy literal', async () => {
      449 |         await expect(`

      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:446:12)

  ● compound atomic datatypes databricks › repeated record › repeat record from malloy literal

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3
    SQL: SELECT
       JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21))) as `ab`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 3

      450 |           run: ${empty}
      451 |           -> { select: ab is ${abMalloy} }
    > 452 |         `).malloyResultMatches(runtime, {ab: ab_eq});
          |            ^
      453 |       });
      454 |       test('repeated record can be selected and renamed', async () => {
      455 |         const src = `

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:452:12)

  ● compound atomic datatypes databricks › repeated record › repeated record can be selected and renamed

    Could not prepare query to run: Error(s) compiling model:
    FILE: internal://internal.malloy
    line 2: Invalid SQL, BRIAN SELECT Error fetching schema for
                    SELECT JSONB_BUILD_ARRAY(JSONB_BUILD_OBJECT('a',10, 'b',11),JSONB_BUILD_OBJECT('a',20, 'b',21)) AS `sqlAB`
                  : Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 19
      |           run: databricks.sql("""
      |                               ^
    line 4: 'sqlAB' is not defined
      |           """) -> { select: ab is sqlAB }
      |                                   ^

      458 |           """) -> { select: ab is sqlAB }
      459 |       `;
    > 460 |         await expect(src).malloyResultMatches(runtime, {ab: ab_eq});
          |                           ^
      461 |       });
      462 |       test('select repeated record passed down pipeline', async () => {
      463 |         await expect(`

      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:460:27)

  ● compound atomic datatypes databricks › repeated record › select repeated record passed down pipeline

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21))) as `pipeAb`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       base.`pipeAb` as `ab`
    FROM __stage0 as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      465 |           -> { select: pipeAb is ${abMalloy} }
      466 |           -> { select: ab is pipeAb }
    > 467 |         `).malloyResultMatches(runtime, {ab: ab_eq});
          |            ^
      468 |       });
      469 |       test('deref repeat record passed down pipeline', async () => {
      470 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:467:12)

  ● compound atomic datatypes databricks › repeated record › deref repeat record passed down pipeline

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21))) as `pipeAb`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       CAST(get_json_object(pipeAb_0, '$.a') AS DOUBLE) as `a`,
       CAST(get_json_object(pipeAb_0, '$.b') AS DOUBLE) as `b`
    FROM __stage0 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`pipeAb`)) as value) as pipeAb_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      472 |           -> { select: pipeAb is ${abMalloy} }
      473 |           -> { select: pipeAb.a, pipeAb.b }
    > 474 |         `).malloyResultMatches(runtime, ab_eq);
          |            ^
      475 |       });
      476 |       test('select array of records from source', async () => {
      477 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:474:12)

  ● compound atomic datatypes databricks › repeated record › select array of records from source

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 4
    SQL: SELECT
       (JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21)))) as `ab`
    FROM (SELECT 0 as z) as base

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 2 pos 4

      479 |           extend { dimension: abSrc is ${abMalloy} }
      480 |           -> { select: ab is abSrc }
    > 481 |         `).malloyResultMatches(runtime, {ab: ab_eq});
          |            ^
      482 |       });
      483 |       test('deref array of records from source', async () => {
      484 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:481:12)

  ● compound atomic datatypes databricks › repeated record › deref array of records from source

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 5 pos 53
    SQL: SELECT
       CAST(get_json_object(ab_0, '$.a') AS DOUBLE) as `a`,
       CAST(get_json_object(ab_0, '$.b') AS DOUBLE) as `b`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('a',10, 'b',11)),(JSONB_BUILD_OBJECT('a',20, 'b',21))))) as value) as ab_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 5 pos 53

      486 |           extend { dimension: ab is ${abMalloy} }
      487 |           -> { select: ab.a, ab.b }
    > 488 |         `).malloyResultMatches(runtime, ab_eq);
          |            ^
      489 |       });
      490 |       test('repeated record in source wth record property', async () => {
      491 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:488:12)

  ● compound atomic datatypes databricks › repeated record › repeated record in source wth record property

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 53
    SQL: SELECT
       get_json_object(to_json(rec_0.bc), '$.b') as `b`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('bc',(JSONB_BUILD_OBJECT('b','b'))))))) as value) as rec_0 ON true

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 4 pos 53

      492 |           run: ${empty} extend { dimension: rec is [ {bc is  {b is 'b'}} ] }
      493 |           -> { select: rec.bc.b }
    > 494 |         `).malloyResultMatches(runtime, {b: 'b'});
          |            ^
      495 |       });
      496 |       test('piped repeated record containing an array', async () => {
      497 |         await expect(`

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:494:12)

  ● compound atomic datatypes databricks › repeated record › piped repeated record containing an array

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5
    SQL: WITH __stage0 AS (
      SELECT
         JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('val',1, 'names',(JSONB_BUILD_ARRAY('uno','one')))),(JSONB_BUILD_OBJECT('val',2, 'names',(JSONB_BUILD_ARRAY('due','two'))))) as `rrec`
      FROM (SELECT 0 as z) as base
    )
    SELECT
       CAST(get_json_object(rrec_0, '$.val') AS DOUBLE) as `val`,
       (get_json_object(names_0, '$.value')) as `name`
    FROM __stage0 as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(base.`rrec`)) as value) as rrec_0 ON true
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(rrec_0.names)) as value) as names_0 ON true
    ORDER BY 1 desc NULLS LAST,2 asc NULLS LAST

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 3 pos 5

      505 |             order_by: val desc, name asc
      506 |           }
    > 507 |         `).malloyResultMatches(runtime, [
          |            ^
      508 |           {val: 2, name: 'due'},
      509 |           {val: 2, name: 'two'},
      510 |           {val: 1, name: 'one'},

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:507:12)

  ● compound atomic datatypes databricks › repeated record › source repeated record containing an array

    query.run failed: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 5 pos 53
    SQL: SELECT
       CAST(get_json_object(rrec_0, '$.val') AS DOUBLE) as `val`,
       (get_json_object(names_0, '$.value')) as `name`
    FROM (SELECT 0 as z) as base
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(JSONB_BUILD_ARRAY((JSONB_BUILD_OBJECT('val',1, 'names',(JSONB_BUILD_ARRAY('uno','one')))),(JSONB_BUILD_OBJECT('val',2, 'names',(JSONB_BUILD_ARRAY('due','two'))))))) as value) as rrec_0 ON true
    LEFT JOIN LATERAL (SELECT value FROM EXPLODE(to_json(rrec_0.names)) as value) as names_0 ON true
    ORDER BY 1 desc NULLS LAST,2 asc NULLS LAST

    Error: [UNRESOLVED_ROUTINE] Cannot resolve routine `JSONB_BUILD_ARRAY` on search path [`system`.`builtin`, `system`.`session`, `workspace`.`default`]. SQLSTATE: 42883; line 5 pos 53

      523 |             order_by: val desc, name asc
      524 |           }
    > 525 |         `).malloyResultMatches(runtime, [
          |            ^
      526 |           {val: 2, name: 'due'},
      527 |           {val: 2, name: 'two'},
      528 |           {val: 1, name: 'one'},

      at DBSQLOperation.waitUntilReady (node_modules/@databricks/sql/lib/DBSQLOperation.ts:369:17)
      at async DBSQLOperation.fetchChunk (node_modules/@databricks/sql/lib/DBSQLOperation.ts:173:5)
      at async DBSQLOperation.fetchAll (node_modules/@databricks/sql/lib/DBSQLOperation.ts:149:21)
      at Object.<anonymous> (test/src/databases/all/compound-atomic.spec.ts:525:12)

FAIL test/src/databases/all/time.spec.ts (68.17 s)
  ● databricks date and time › interval measurement › seconds

    Got 'sqlEq failed
        Expected: seconds(@2001-01-01 00:00:00.999 to @2001-01-01 00:00:01) == 0
        Received: 1' [object String] instead of '='
    SQL:
        SELECT
           CASE WHEN ((0)=(FLOOR(UNIX_TIMESTAMP(timestamp '2001-01-01 00:00:01')-UNIX_TIMESTAMP(timestamp '2001-01-01 00:00:00.999')))) THEN '=' ELSE (CONCAT('sqlEq failed',CASE WHEN 10 = 0 THEN '' ELSE CHR(10) END,'    Expected: seconds(@2001-01-01 00:00:00.999 to @2001-01-01 00:00:01) == 0',CASE WHEN 10 = 0 THEN '' ELSE CHR(10) END,'    Received: ',CAST((FLOOR(UNIX_TIMESTAMP(timestamp '2001-01-01 00:00:01')-UNIX_TIMESTAMP(timestamp '2001-01-01 00:00:00.999'))) AS string))) END as `calc`
        FROM (SELECT DATE '2021-02-24' as `t_date`, TIMESTAMP '2021-02-24 03:05:06' as `t_timestamp` ) as base

      60 |       const b = '@2001-01-01 00:00:00.999';
      61 |       expect(await sqlEq(`seconds(${a} to ${b})`, 0)).isSqlEq();
    > 62 |       expect(await sqlEq(`seconds(${b} to @2001-01-01 00:00:01)`, 0)).isSqlEq();
         |                                                                       ^
      63 |     });
      64 |
      65 |     test('minutes', async () => {


      at Object.<anonymous> (test/src/databases/all/time.spec.ts:62:71)

  ● databricks: tz literals › literal with zone name

    expect(received).toEqual(expected) // deep equality

    Expected: 1582178400000
    Received: 1582135200000

      663 |     const literal = result.data.path(0, 'literal_time').value as Date;
      664 |     const have = LuxonDateTime.fromJSDate(literal);
    > 665 |     expect(have.valueOf()).toEqual(zone_2020.valueOf());
          |                            ^
      666 |   });
      667 | });
      668 |

      at Object.<anonymous> (test/src/databases/all/time.spec.ts:665:28)

  ● databricks: query tz › literal timestamps

    expect(received).toEqual(expected) // deep equality

    Expected: 1582178400000
    Received: 1582135200000

      683 |     const literal = result.data.path(0, 'literal_time').value as Date;
      684 |     const have = LuxonDateTime.fromJSDate(literal);
    > 685 |     expect(have.valueOf()).toEqual(zone_2020.valueOf());
          |                            ^
      686 |   });
      687 |
      688 |   test('extract', async () => {

      at Object.<anonymous> (test/src/databases/all/time.spec.ts:685:28)

  ● databricks: query tz › extract

    SQL Generated:
      SELECT
         EXTRACT(hour FROM (from_utc_timestamp(timestamp'2020-02-20 00:00:00', 'UTC'))) as `mex_midnight`,
         EXTRACT(day FROM (from_utc_timestamp(timestamp'2020-02-20 00:00:00', 'UTC'))) as `mex_day`
      FROM (SELECT 1 as one) as base

    Expected {mex_midnight: 18} Got: 0
    Expected {mex_day: 19} Got: 20

      695 |           mex_day is day(utc_midnight)
      696 |       }`
    > 697 |     ).malloyResultMatches(runtime, {mex_midnight: 18, mex_day: 19});
          |       ^
      698 |   });
      699 |
      700 |   test.when(

      at Object.<anonymous> (test/src/databases/all/time.spec.ts:697:7)

  ● databricks: query tz › truncate day

    SQL Generated:
      SELECT
         DATE_TRUNC('day', from_utc_timestamp((from_utc_timestamp(timestamp'2020-02-20 00:00:00', 'UTC')), 'America/Mexico_City')) as `mex_day`
      FROM (SELECT 1 as x) as base

    Expected {mex_day: "2020-02-19T06:00:00.000Z"} Got: "2020-02-19T00:00:00.000Z"

      710 |         select: mex_day is utc_midnight.day
      711 |       }`
    > 712 |     ).malloyResultMatches(runtime, {mex_day: mex_19.toJSDate()});
          |       ^
      713 |   });
      714 |
      715 |   test.when(

      at Object.<anonymous> (test/src/databases/all/time.spec.ts:712:7)

  ● databricks: query tz › cast timestamp to date

    SQL Generated:
      SELECT
         EXTRACT(day FROM DATE((from_utc_timestamp(timestamp'2020-02-20 00:00:00', 'UTC')))) as `mex_day`
      FROM (SELECT 1 as x) as base

    Expected {mex_day: 19} Got: 20

      724 |         select: mex_day is day(utc_midnight::date)
      725 |       }`
    > 726 |     ).malloyResultMatches(runtime, {mex_day: 19});
          |       ^
      727 |   });
      728 |
      729 |   test.when(

      at Object.<anonymous> (test/src/databases/all/time.spec.ts:726:7)

  ● databricks: query tz › cast date to timestamp

    SQL Generated:
      SELECT
         TIMESTAMP(base.`mex_20`) as `mex_ts`
      FROM ( SELECT DATE '2020-02-20'  AS `mex_20` ) as base

    Expected {mex_ts: "2020-02-20T06:00:00.000Z"} Got: "2020-02-20T00:00:00.000Z"

      735 |         select: mex_ts is mex_20::timestamp
      736 |       }`
    > 737 |     ).malloyResultMatches(runtime, {mex_ts: zone_2020.toJSDate()});
          |       ^
      738 |   });
      739 | });
      740 |

      at Object.<anonymous> (test/src/databases/all/time.spec.ts:737:7)

FAIL test/src/render/drill.spec.ts (17.904 s)
  ● drill query › can handle renamed and multi-word field names

    Parser Error: syntax error at or near "Code"



FAIL test/src/core/tags.spec.ts
  ● tags in results › inherited model tags override

    Parser Error: syntax error at or near ".1"




Test Suites: 9 failed, 32 skipped, 31 passed, 40 of 72 total
Tests:       76 failed, 296 skipped, 2 todo, 1349 passed, 1723 total
Snapshots:   0 total
Time:        641.755 s
Ran all test suites.
